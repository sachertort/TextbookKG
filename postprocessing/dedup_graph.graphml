<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d0" for="edge" attr.name="weight" attr.type="double" />
  <graph edgedefault="undirected">
    <node id="SPEECH AND LANGUAGE PROCESSING" />
    <node id="NATURAL LANGUAGE PROCESSING (NLP)" />
    <node id="COMPUTATIONAL LINGUISTICS" />
    <node id="SPEECH RECOGNITION" />
    <node id="DANIEL JURAFSKY" />
    <node id="JAMES H. MARTIN" />
    <node id="MACHINE TRANSLATION (MT)" />
    <node id="QUESTION ANSWERING" />
    <node id="DEPENDENCY PARSING" />
    <node id="INFORMATION EXTRACTION" />
    <node id="SEMANTIC ROLE LABELING" />
    <node id="DISCOURSE COHERENCE" />
    <node id="CORPORA" />
    <node id="AUTOMATIC SPEECH RECOGNITION (ASR)" />
    <node id="TEXT-TO-SPEECH (TTS)" />
    <node id="LANGUAGE MODEL" />
    <node id="N-GRAM LANGUAGE MODEL" />
    <node id="NAIVE BAYES" />
    <node id="LARGE LANGUAGE MODELS" />
    <node id="MASKED LANGUAGE MODEL" />
    <node id="SMOOTHING" />
    <node id="INTERPOLATION" />
    <node id="BACKOFF" />
    <node id="PRECISION" />
    <node id="RECALL" />
    <node id="F-MEASURE" />
    <node id="CROSS-VALIDATION" />
    <node id="STATISTICAL SIGNIFICANCE TESTING" />
    <node id="NEURAL NETWORK" />
    <node id="RNNS AND LSTMS" />
    <node id="THE TRANSFORMER" />
    <node id="CHATBOTS" />
    <node id="DIALOGUE SYSTEM" />
    <node id="SEQUENCE LABELING" />
    <node id="PARTS OF SPEECH" />
    <node id="NAMED ENTITY" />
    <node id="CONTEXT-FREE GRAMMAR (CFG)" />
    <node id="CONSTITUENCY PARSING" />
    <node id="LEXICON" />
    <node id="SENTIMENT" />
    <node id="COREFERENCE RESOLUTION" />
    <node id="ENTITY LINKING" />
    <node id="TOKENIZATION" />
    <node id="EDIT DISTANCE" />
    <node id="REGULAR EXPRESSION" />
    <node id="WORD NORMALIZATION" />
    <node id="SENTENCE SEGMENTATION" />
    <node id="LOGISTIC REGRESSION" />
    <node id="SIGMOID FUNCTION" />
    <node id="CROSS-ENTROPY LOSS FUNCTION" />
    <node id="GRADIENT DESCENT" />
    <node id="REGULARIZATION" />
    <node id="VECTOR SEMANTICS" />
    <node id="TF-IDF" />
    <node id="WORD2VEC" />
    <node id="COSINE SIMILARITY" />
    <node id="VISUALIZING EMBEDDINGS" />
    <node id="SEMANTIC PROPERTIES OF EMBEDDINGS" />
    <node id="BIAS AND EMBEDDINGS" />
    <node id="EVALUATING VECTOR MODELS" />
    <node id="FEEDFORWARD NEURAL NETWORKS" />
    <node id="RECURRENT NEURAL NETWORKS (RNNS)" />
    <node id="XOR PROBLEM" />
    <node id="LONG SHORT-TERM MEMORY (LSTM)" />
    <node id="STACKED AND BIDIRECTIONAL RNN ARCHITECTURES" />
    <node id="ENCODER-DECODER MODEL WITH RNNS" />
    <node id="TRANSFORMER" />
    <node id="ATTENTION" />
    <node id="PARALLELIZING COMPUTATION USING A SINGLE MATRIX X" />
    <node id="INPUT EMBEDDINGS FOR TOKEN AND POSITION" />
    <node id="MODEL ALIGNMENT" />
    <node id="SAMPLING FOR LLM GENERATION" />
    <node id="PRETRAINING LARGE LANGUAGE MODELS" />
    <node id="DEALING WITH SCALE" />
    <node id="POTENTIAL HARMS FROM LANGUAGE MODELS" />
    <node id="BIDIRECTIONAL TRANSFORMER ENCODER" />
    <node id="TRAINING BIDIRECTIONAL ENCODERS" />
    <node id="CONTEXTUAL EMBEDDING" />
    <node id="FINE-TUNING FOR CLASSIFICATION" />
    <node id="FINE-TUNING FOR SEQUENCE LABELLING" />
    <node id="PROMPTING" />
    <node id="POST-TRAINING AND MODEL ALIGNMENT" />
    <node id="IN-CONTEXT LEARNING" />
    <node id="RLHF" />
    <node id="DIRECT POLICY OPTIMIZATION (DPO)" />
    <node id="INSTRUCTION TUNING" />
    <node id="POST-TRAINING" />
    <node id="HUMAN PREFERENCES" />
    <node id="CHAIN-OF-THOUGHT PROMPTING" />
    <node id="AUTOMATIC PROMPT OPTIMIZATION" />
    <node id="EVALUATING PROMPTED LANGUAGE MODELS" />
    <node id="ENCODER-DECODER" />
    <node id="BEAM SEARCH" />
    <node id="LOW-RESOURCE TRANSLATION" />
    <node id="MT EVALUATION" />
    <node id="LANGUAGE DIVERGENCES" />
    <node id="TYPOLOGY" />
    <node id="BIAS AND ETHICAL ISSUES" />
    <node id="INFORMATION RETRIEVAL (IR)" />
    <node id="DENSE VECTORS" />
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)" />
    <node id="FRAME-BASED DIALOGUE SYSTEM" />
    <node id="DIALOGUE ACTS" />
    <node id="DIALOGUE STATE" />
    <node id="FEATURE EXTRACTION" />
    <node id="LOG MEL SPECTRUM" />
    <node id="SPEECH RECOGNITION ARCHITECTURE" />
    <node id="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" />
    <node id="WORD ERROR RATE (WER)" />
    <node id="NAMED-ENTITY TAGGING" />
    <node id="HMM PART-OF-SPEECH TAGGING" />
    <node id="CONDITIONAL RANDOM FIELDS" />
    <node id="TREEBANK" />
    <node id="GRAMMAR EQUIVALENCE" />
    <node id="NORMAL FORM" />
    <node id="AMBIGUITY" />
    <node id="CKY PARSING" />
    <node id="SPAN-BASED NEURAL CONSTITUENCY PARSING" />
    <node id="HEADS AND HEAD-FINDING" />
    <node id="DEPENDENCY RELATION" />
    <node id="TRANSITION-BASED DEPENDENCY PARSING" />
    <node id="GRAPH-BASED DEPENDENCY PARSING" />
    <node id="RELATION EXTRACTION" />
    <node id="EVENT EXTRACTION" />
    <node id="TIME REPRESENTATION" />
    <node id="SENTIMENT LEXICONS" />
    <node id="SENTIMENT ANALYSIS" />
    <node id="COREFFERENCE RESOLUTION" />
    <node id="FEEDFORWARD NETWORK" />
    <node id="RECURRENT NETWORKS" />
    <node id="EMBEDDING" />
    <node id="ELIZA" />
    <node id="ROGERIAN PSYCHOTHERAPIST" />
    <node id="PATTERN MATCHING" />
    <node id="USER" />
    <node id="CONVERSATIONAL AGENTS" />
    <node id="STRING" />
    <node id="CORPUS" />
    <node id="CONCATENATION" />
    <node id="OPTIONALITY" />
    <node id="TEXT NORMALIZATION" />
    <node id="LEMMATIZATION" />
    <node id="STEMMING" />
    <node id="KLEENE STAR" />
    <node id="KLEENE PLUS" />
    <node id="WILDCARD" />
    <node id="ANCHOR" />
    <node id="DISJUNCTION" />
    <node id="PARENTHESES" />
    <node id="OPERATOR PRECEDENCE" />
    <node id="GREEDY MATCHING" />
    <node id="NON-GREEDY MATCHING" />
    <node id="WORD BOUNDARY" />
    <node id="CARET" />
    <node id="DOLLAR SIGN" />
    <node id="WORD" />
    <node id="FALSE POSITIVE" />
    <node id="FALSE NEGATIVE" />
    <node id="CAPTURE GROUP" />
    <node id="SUBSTITUTION" />
    <node id="OPERATORS" />
    <node id="ALIAS" />
    <node id="COUNTING" />
    <node id="ESCAPED CHARACTERS" />
    <node id="LOOKAHEAD ASSERTIONS" />
    <node id="ELIZA ARCHITECTURE" />
    <node id="NEGATIVE LOOKAHEAD" />
    <node id="BROWN CORPUS" />
    <node id="SWITCHBOARD CORPUS" />
    <node id="DISFLUENCIES" />
    <node id="SPEAKER IDENTIFICATION" />
    <node id="WORD TYPES" />
    <node id="WORD INSTANCES" />
    <node id="HERDAN'S LAW" />
    <node id="LEMMA" />
    <node id="WORDFORM" />
    <node id="NLP ALGORITHMS" />
    <node id="BPE ALGORITHM" />
    <node id="AFRICAN AMERICAN ENGLISH (AAE)" />
    <node id="EXERCISE 2.3" />
    <node id="CHAPTER 15" />
    <node id="PUNCTUATION" />
    <node id="PART-OF-SPEECH TAGGING" />
    <node id="SPEECH SYNTHESIS" />
    <node id="MAINSTREAM AMERICAN ENGLISH (MAE)" />
    <node id="AFRICAN AMERICAN VERNACULAR ENGLISH" />
    <node id="CODE SWITCHING" />
    <node id="TWITTER POSTS" />
    <node id="GENRE" />
    <node id="DEMOGRAPHIC CHARACTERISTICS" />
    <node id="LANGUAGE CHANGE" />
    <node id="DATASHEET" />
    <node id="UNIX TOOLS" />
    <node id="PENN TREEBANK TOKENIZATION" />
    <node id="MULTIWORD EXPRESSIONS" />
    <node id="NAMED ENTITY RECOGNITION (NER)" />
    <node id="FINITE STATE AUTOMATA" />
    <node id="NATURAL LANGUAGE TOOLKIT (NLTK)" />
    <node id="DETERMINISTIC ALGORITHMS" />
    <node id="WORD TOKENIZATION" />
    <node id="CHINESE WORD SEGMENTATION" />
    <node id="HANZI" />
    <node id="BYTE-PAIR ENCODING (BPE)" />
    <node id="SUBWORD TOKENIZATION" />
    <node id="SENTENCEPIECE" />
    <node id="TOKEN LEARNER" />
    <node id="TOKEN SEGMENTER" />
    <node id="MORPHEME" />
    <node id="UNIGRAM LANGUAGE MODELING" />
    <node id="UNKNOWN WORD PROBLEM" />
    <node id="PORTER STEMMER" />
    <node id="CORENLP TOOLKIT" />
    <node id="MINIMUM EDIT DISTANCE" />
    <node id="STRING SIMILARITY" />
    <node id="TRAINING DATA" />
    <node id="TEST DATA" />
    <node id="MORPHOLOGICAL PARSER" />
    <node id="STEM" />
    <node id="AFFIX" />
    <node id="LEVENSHTEIN DISTANCE" />
    <node id="DYNAMIC PROGRAMMING" />
    <node id="OPERATION LIST" />
    <node id="MINIMUM EDIT DISTANCE ALGORITHM" />
    <node id="COST" />
    <node id="TABLE-DRIVEN METHOD" />
    <node id="VITERBI ALGORITHM" />
    <node id="CKY ALGORITHM" />
    <node id="ALIGNMENT" />
    <node id="SEARCH TASK" />
    <node id="ALIGNMENT PATH" />
    <node id="STRING COMPARISON" />
    <node id="BACKPOINTER" />
    <node id="BACKTRACE" />
    <node id="DYNAMIC PROGRAMMING MATRIX" />
    <node id="PROBABILITY ALIGNMENT" />
    <node id="FINITE AUTOMATON" />
    <node id="TEXT SEARCHING" />
    <node id="SPELLING CORRECTION" />
    <node id="TEXT PREPROCESSING" />
    <node id="TEXT SEGMENTATION" />
    <node id="PORTER ALGORITHM" />
    <node id="AFFIX-STRIPPING" />
    <node id="CORPUS INTERFACES" />
    <node id="N-GRAM" />
    <node id="AUGMENTATIVE AND ALTERNATIVE COMMUNICATION (AAC)" />
    <node id="WORD PREDICTION" />
    <node id="GRAMMAR CORRECTION" />
    <node id="TRAINING SET" />
    <node id="TEST SET" />
    <node id="PERPLEXITY" />
    <node id="SAMPLING" />
    <node id="BIGRAM" />
    <node id="TRIGRAM" />
    <node id="MARKOV ASSUMPTION" />
    <node id="MAXIMUM LIKELIHOOD ESTIMATION (MLE)" />
    <node id="PROBABILITY" />
    <node id="CHAIN RULE" />
    <node id="NEURAL LARGE LANGUAGE MODELS" />
    <node id="TRANSFORMER ARCHITECTURE" />
    <node id="BIGRAM PROBABILITIES" />
    <node id="N-GRAM MODELS" />
    <node id="BERKELEY RESTAURANT PROJECT" />
    <node id="BIGRAM COUNTS" />
    <node id="UNIGRAM COUNTS" />
    <node id="RELATIVE FREQUENCY" />
    <node id="LOG PROBABILITY" />
    <node id="TRIGRAM MODELS" />
    <node id="SUFFIX ARRAYS" />
    <node id="QUANTIZATION" />
    <node id="REVERSE TRIES" />
    <node id="CORPUS OF CONTEMPORARY AMERICAN ENGLISH (COCA)" />
    <node id="GOOGLE WEB 5-GRAM CORPUS" />
    <node id="GOOGLE BOOKS NGRAMS" />
    <node id="INFINI-GRAM (¥-GRAM) PROJECT" />
    <node id="KENLM" />
    <node id="ENTROPY" />
    <node id="MERGE SORTS" />
    <node id="EXTRINSIC EVALUATION" />
    <node id="INTRINSIC EVALUATION" />
    <node id="CROSS-ENTROPY RATE" />
    <node id="DEVELOPMENT SET" />
    <node id="UNIGRAM" />
    <node id="WALL STREET JOURNAL (WSJ)" />
    <node id="OVERFITTING" />
    <node id="SHAKESPEARE" />
    <node id="BRANCHING FACTOR" />
    <node id="TRAINING CORPUS" />
    <node id="NIGERIAN PIDGIN" />
    <node id="LAPLACE SMOOTHING" />
    <node id="DISCOUNTING" />
    <node id="ZERO PROBABILITY" />
    <node id="PSEUDO-SHAKESPEARE" />
    <node id="MAXIMUM LIKELIHOOD ESTIMATE (MLE)" />
    <node id="ADD-ONE SMOOTHING" />
    <node id="STUPID BACKOFF" />
    <node id="ADD-K SMOOTHING" />
    <node id="HELD-OUT CORPUS" />
    <node id="EM ALGORITHM" />
    <node id="DISCOUNT" />
    <node id="CROSS-ENTROPY" />
    <node id="SHANNON-MCMILLAN-BREIMAN THEOREM" />
    <node id="PROBABILITY FUNCTION" />
    <node id="RANDOM VARIABLE" />
    <node id="INFORMATION THEORY" />
    <node id="STATIONARY" />
    <node id="EROGDIC" />
    <node id="MARKOV MODELS" />
    <node id="STOCHASTIC PROCESS" />
    <node id="SMOOTHING ALGORITHMS" />
    <node id="ADD-1 SMOOTHING" />
    <node id="GOOD-TURING DISCOUNTING" />
    <node id="WITTEN-BELL DISCOUNTING" />
    <node id="MODIFIED INTERPOLATED KNESER-NEY" />
    <node id="MARKOV CHAIN" />
    <node id="CLASS-BASED N-GRAM MODELS" />
    <node id="SRILM" />
    <node id="NEURAL LANGUAGE MODELS" />
    <node id="MARKOV" />
    <node id="SHANNON" />
    <node id="JELINEK" />
    <node id="BAKER" />
    <node id="LAPLACE" />
    <node id="JEFFREYS" />
    <node id="GALE AND CHURCH" />
    <node id="KATZ" />
    <node id="CHEN AND GOODMAN" />
    <node id="TRANSFORMER-BASED LARGE LANGUAGE MODELS" />
    <node id="FEEDFORWARD LANGUAGE MODELS" />
    <node id="RECURRENT LANGUAGE MODELS" />
    <node id="BENGIO" />
    <node id="SCHWENK" />
    <node id="MIKOLOV" />
    <node id="TEXT CATEGORIZATION" />
    <node id="CHOMSKY" />
    <node id="TEXT CLASSIFICATION" />
    <node id="BINARY CLASSIFICATION" />
    <node id="SPAM DETECTION" />
    <node id="LANGUAGE ID" />
    <node id="AUTHORSHIP ATTRIBUTION" />
    <node id="SUPERVISED MACHINE LEARNING" />
    <node id="NAIVE BAYES CLASSIFIER" />
    <node id="DISCRIMINATIVE CLASSIFIER" />
    <node id="BAG-OF-WORDS" />
    <node id="BAYESIAN INFERENCE" />
    <node id="PROBABILISTIC CLASSIFIER" />
    <node id="GENERATIVE MODEL" />
    <node id="CLASSIFICATION" />
    <node id="STOP WORDS" />
    <node id="PRIOR PROBABILITY" />
    <node id="LIKELIHOOD" />
    <node id="DOCUMENT" />
    <node id="FEATURES" />
    <node id="BAG-OF-WORDS ASSUMPTION" />
    <node id="NAIVE BAYES ASSUMPTION" />
    <node id="LINEAR CLASSIFIER" />
    <node id="WORD COUNTS" />
    <node id="VOCABULARY" />
    <node id="UNKNOWN WORD" />
    <node id="NEGATION HANDLING" />
    <node id="BINARY NAIVE BAYES" />
    <node id="SPAMASSASSIN" />
    <node id="CHARACTER N-GRAMS" />
    <node id="FEATURE SELECTION" />
    <node id="MULTILINGUAL TEXT" />
    <node id="TWITTER TEXT" />
    <node id="URBAN DICTIONARY" />
    <node id="UNIGRAM LANGUAGE MODEL" />
    <node id="BAYES MODEL" />
    <node id="NAIVE BAYES MODEL" />
    <node id="PRIOR" />
    <node id="POSITIVE CLASS" />
    <node id="NEGATIVE CLASS" />
    <node id="TRUE POSITIVE" />
    <node id="CONFUSION MATRIX" />
    <node id="GOLD LABELS" />
    <node id="MULTI-CLASS CLASSIFICATION" />
    <node id="MICROAVERAGING" />
    <node id="MACROAVERAGING" />
    <node id="TRUE NEGATIVE" />
    <node id="ACCURACY" />
    <node id="10-FOLD CROSS-VALIDATION" />
    <node id="FOLDS" />
    <node id="DEVSET" />
    <node id="NULL HYPOTHESIS" />
    <node id="P-VALUE" />
    <node id="APPROXIMATE RANDOMIZATION" />
    <node id="BOOTSTRAP TEST" />
    <node id="EFFECT SIZE" />
    <node id="BOOTSTRAP" />
    <node id="CLASSIFIER A" />
    <node id="CLASSIFIER B" />
    <node id="REPRESENTATIONAL HARM" />
    <node id="TOXICITY DETECTION" />
    <node id="MODEL CARD" />
    <node id="CONDITIONAL INDEPENDENCE ASSUMPTION" />
    <node id="VIRTUAL TEST SET" />
    <node id="SAMPLING DISTRIBUTION" />
    <node id="CONDITIONAL INDEPENDENCE" />
    <node id="STATISTICAL SIGNIFICANCE TESTS" />
    <node id="MULTINOMIAL NAIVE BAYES" />
    <node id="BINARY MULTINOMIAL NAIVE BAYES" />
    <node id="MULTIVARIATE BERNOULLI NAIVE BAYES" />
    <node id="GENERATIVE CLASSIFIER" />
    <node id="CHI-SQUARED (Χ²)" />
    <node id="POINTWISE MUTUAL INFORMATION (PMI)" />
    <node id="GINI INDEX" />
    <node id="DISCRIMINATIVE MODEL" />
    <node id="FEATURE REPRESENTATION" />
    <node id="CLASSIFICATION FUNCTION" />
    <node id="OBJECTIVE FUNCTION" />
    <node id="STOCHASTIC GRADIENT DESCENT" />
    <node id="CROSS-ENTROPY LOSS" />
    <node id="DECISION BOUNDARY" />
    <node id="SENTIMENT CLASSIFICATION" />
    <node id="LOGIT" />
    <node id="BINARY LOGISTIC REGRESSION" />
    <node id="WEIGHT" />
    <node id="BIAS TERM" />
    <node id="DOT PRODUCT" />
    <node id="MOVIE REVIEW" />
    <node id="POSITIVE SENTIMENT" />
    <node id="NEGATIVE SENTIMENT" />
    <node id="FEATURE" />
    <node id="MATRIX ARITHMETIC" />
    <node id="PERIOD DISAMBIGUATION" />
    <node id="REPRESENTATION LEARNING" />
    <node id="SCALING" />
    <node id="FEATURE INTERACTIONS" />
    <node id="FEATURE TEMPLATE" />
    <node id="POSITIVE LEXICON WORDS" />
    <node id="NEGATIVE LEXICON WORDS" />
    <node id="SENTIMENT DECISION" />
    <node id="EOS (END-OF-SENTENCE)" />
    <node id="NOT-EOS" />
    <node id="STANDARDIZE" />
    <node id="NORMALIZE" />
    <node id="Z-SCORE" />
    <node id="WEIGHT VECTOR" />
    <node id="CORRELATED FEATURES" />
    <node id="MULTINOMIAL LOGISTIC REGRESSION" />
    <node id="SOFTMAX FUNCTION" />
    <node id="ONE-HOT VECTOR" />
    <node id="WEIGHT MATRIX" />
    <node id="HARD CLASSIFICATION" />
    <node id="LOSS FUNCTION" />
    <node id="COST FUNCTION" />
    <node id="CONDITIONAL MAXIMUM LIKELIHOOD ESTIMATION" />
    <node id="NEGATIVE LOG LIKELIHOOD LOSS" />
    <node id="CONVEX FUNCTION" />
    <node id="OPTIMIZATION ALGORITHM" />
    <node id="SLOPE" />
    <node id="LEARNING RATE" />
    <node id="BERNOULLI DISTRIBUTION" />
    <node id="PARAMETERS" />
    <node id="GRADIENT" />
    <node id="PARAMETER VECTOR" />
    <node id="PARTIAL DERIVATIVE" />
    <node id="FEATURE VECTOR" />
    <node id="HYPERPARAMETER" />
    <node id="MINI-BATCH TRAINING" />
    <node id="BIAS" />
    <node id="BATCH TRAINING" />
    <node id="VECTORIZE" />
    <node id="L2 REGULARIZATION" />
    <node id="L1 REGULARIZATION" />
    <node id="RIDGE REGRESSION" />
    <node id="GAUSSIAN DISTRIBUTION" />
    <node id="LASSO REGRESSION" />
    <node id="LAPLACE PRIOR" />
    <node id="ARGMAX" />
    <node id="CONVEX OPTIMIZATION" />
    <node id="SOFTMAX REGRESSION" />
    <node id="INTERPRETABILITY" />
    <node id="MAXIMUM ENTROPY MODELING" />
    <node id="DERIVATIVE" />
    <node id="SPEECH PROCESSING" />
    <node id="SMILODON" />
    <node id="THYLACOSMILUS" />
    <node id="PARALLEL OR CONVERGENT EVOLUTION" />
    <node id="GOULD" />
    <node id="DISTRIBUTIONAL HYPOTHESIS" />
    <node id="JOOS" />
    <node id="HARRIS" />
    <node id="FIRTH" />
    <node id="BERT" />
    <node id="BENGIO ET AL." />
    <node id="FEATURE ENGINEERING" />
    <node id="LEXICAL SEMANTICS" />
    <node id="WORD SENSE" />
    <node id="SYNONYMY" />
    <node id="WORD SIMILARITY" />
    <node id="WORD RELATEDNESS" />
    <node id="SEMANTIC FIELD" />
    <node id="SEMANTIC FRAME" />
    <node id="WORDNET" />
    <node id="WORD SENSE DISAMBIGUATION" />
    <node id="POLYSEMY" />
    <node id="PRINCIPLE OF CONTRAST" />
    <node id="SIMLEX-999" />
    <node id="BUDANITSKY AND HIRST" />
    <node id="TOPIC MODELS" />
    <node id="LATENT DIRICHLET ALLOCATION (LDA)" />
    <node id="PLEISTOCENE EPOCH" />
    <node id="ICE AGES" />
    <node id="CONNOTATION" />
    <node id="AFFECTIVE MEANING" />
    <node id="VALENCE" />
    <node id="AROUSAL" />
    <node id="DOMINANCE" />
    <node id="TERM-DOCUMENT MATRIX" />
    <node id="ANTONYMY" />
    <node id="PARAPHRASE" />
    <node id="MERONYMY" />
    <node id="SEMANTIC ROLES" />
    <node id="HYPERNYMY" />
    <node id="VECTOR SPACE" />
    <node id="VECTOR" />
    <node id="TERM-TERM MATRIX" />
    <node id="WORD VECTOR" />
    <node id="JULIUS CAESAR" />
    <node id="AS YOU LIKE IT" />
    <node id="TWELFTH NIGHT" />
    <node id="HENRY V" />
    <node id="BATTLE" />
    <node id="FOOL" />
    <node id="GOOD" />
    <node id="WIT" />
    <node id="VECTOR LENGTH" />
    <node id="UNIT VECTOR" />
    <node id="TERM FREQUENCY (TF)" />
    <node id="INVERSE DOCUMENT FREQUENCY (IDF)" />
    <node id="CO-OCCURRENCE MATRIX" />
    <node id="RAW FREQUENCY" />
    <node id="DOCUMENT FREQUENCY" />
    <node id="COLLECTION FREQUENCY" />
    <node id="SHAKESPEARE PLAYS" />
    <node id="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)" />
    <node id="WORD ASSOCIATION" />
    <node id="SKIP-GRAM" />
    <node id="NEGATIVE SAMPLING" />
    <node id="VECTOR SEMANTICS MODEL" />
    <node id="DOCUMENT SIMILARITY" />
    <node id="SPARSE VECTORS" />
    <node id="SELF-SUPERVISION" />
    <node id="STATIC EMBEDDINGS" />
    <node id="CENTROID" />
    <node id="FASTTEXT" />
    <node id="GLOVE" />
    <node id="TARGET WORD" />
    <node id="CONTEXT WORD" />
    <node id="NOISE WORD" />
    <node id="UNIGRAM FREQUENCY" />
    <node id="LOGISTIC FUNCTION" />
    <node id="WEIGHTING PARAMETER" />
    <node id="SKIPGRAM EMBEDDING" />
    <node id="PARALLELOGRAM MODEL" />
    <node id="VECTOR SPACE MODEL" />
    <node id="MULTIDIMENSIONAL SCALING" />
    <node id="HIERARCHICAL CLUSTERING" />
    <node id="T-SNE" />
    <node id="CONTEXT WINDOW" />
    <node id="FIRST-ORDER CO-OCCURRENCE" />
    <node id="SECOND-ORDER CO-OCCURRENCE" />
    <node id="ANALOGY" />
    <node id="HISTORICAL SEMANTICS" />
    <node id="GOOGLE N-GRAMS" />
    <node id="CORPUS OF HISTORICAL AMERICAN ENGLISH" />
    <node id="SGNS VECTORS" />
    <node id="SEMANTIC CHANGE" />
    <node id="DYNAMIC SOCIAL REPRESENTATIONS" />
    <node id="HISTORICAL EMBEDDINGS" />
    <node id="LATENT SEMANTIC ANALYSIS (LSA)" />
    <node id="CO-OCCURRENCE VECTORS" />
    <node id="TEMPORAL TOPIC MODELS" />
    <node id="POINT-WISE MUTUAL INFORMATION-BASED EMBEDDINGS" />
    <node id="NEURAL WORD-EMBEDDING METHODS" />
    <node id="WORD EMBEDDING" />
    <node id="GENDER BIAS" />
    <node id="DEBIASING" />
    <node id="ALLOCATION HARM" />
    <node id="VECTOR MODELS" />
    <node id="TOEFL DATASET" />
    <node id="STANFORD CONTEXTUAL WORD SIMILARITY" />
    <node id="WORD-IN-CONTEXT DATASET" />
    <node id="SEMANTIC TEXTUAL SIMILARITY TASK" />
    <node id="IMPLICIT ASSOCIATION TEST" />
    <node id="GLOVE VECTORS" />
    <node id="ANALOGY TASK" />
    <node id="HUMAN-LABELED SIMILARITY SCORES" />
    <node id="MORPHOLOGY" />
    <node id="LEXICOGRAPHIC RELATIONS" />
    <node id="ENCYCLOPEDIA RELATIONS" />
    <node id="SEMEVAL-2012 TASK 2 DATASET" />
    <node id="EMBEDDING ALGORITHMS" />
    <node id="NON-NEGATIVE MATRIX FACTORIZATION (NMF)" />
    <node id="BOOTSTRAP SAMPLING" />
    <node id="SPARSE VECTOR MODELS" />
    <node id="DENSE VECTOR MODELS" />
    <node id="MUTUAL INFORMATION" />
    <node id="MULTIDIMENSIONAL SEMANTIC SPACE" />
    <node id="SEMANTIC FEATURES" />
    <node id="TF-IDF WEIGHTING" />
    <node id="SINGULAR VALUE DECOMPOSITION (SVD)" />
    <node id="LATENT SEMANTIC ANALYSIS (LSA) EMBEDDING" />
    <node id="PROBABILISTIC LATENT SEMANTIC INDEXING (PLSI)" />
    <node id="LATENT SEMANTIC INDEXING (LSI)" />
    <node id="SINGULAR VALUE DECOMPOSITION (SVD) EMBEDDING" />
    <node id="MECHANICAL INDEXING" />
    <node id="DEEP LEARNING" />
    <node id="NEURAL UNIT" />
    <node id="WEIGHTED SUM" />
    <node id="ACTIVATION FUNCTION" />
    <node id="TANH FUNCTION" />
    <node id="RELU FUNCTION" />
    <node id="ACTIVATION VALUE" />
    <node id="SATURATED" />
    <node id="LATENT SPACE" />
    <node id="CBOW (CONTINUOUS BAG OF WORDS)" />
    <node id="RELU" />
    <node id="VANISHING GRADIENT PROBLEM" />
    <node id="RECTIFIED LINEAR TRANSFORMATION" />
    <node id="TANH" />
    <node id="SIGMOID" />
    <node id="PERCEPTRON" />
    <node id="HYPERPLANE" />
    <node id="ERROR BACKPROPAGATION" />
    <node id="HIDDEN LAYER" />
    <node id="MULTI-LAYER PERCEPTRONS (MLP)" />
    <node id="HIDDEN UNIT" />
    <node id="INPUT LAYER" />
    <node id="OUTPUT LAYER" />
    <node id="BIAS VECTOR" />
    <node id="PROBABILITY DISTRIBUTION" />
    <node id="MULTINOMIAL CLASSIFICATION" />
    <node id="MULTILAYER NETWORK" />
    <node id="SINGLE LAYER NETWORK" />
    <node id="BIAS UNIT" />
    <node id="DUMMY NODE" />
    <node id="NEURAL LANGUAGE MODELING" />
    <node id="HAND-DESIGNED FEATURES" />
    <node id="POOLING" />
    <node id="PRETRAINING" />
    <node id="SOFTMAX" />
    <node id="COMPUTATION GRAPH" />
    <node id="BACKWARD PASS" />
    <node id="FORWARD PASS" />
    <node id="MULTINOMIAL REGRESSION" />
    <node id="DROPOUT" />
    <node id="FEEDFORWARD NEURAL LANGUAGE MODEL" />
    <node id="PYTORCH" />
    <node id="TENSORFLOW" />
    <node id="MODEL ARCHITECTURE" />
    <node id="OPTIMIZATION" />
    <node id="MINI-BATCH GRADIENT DESCENT" />
    <node id="ADAM OPTIMIZER" />
    <node id="NEURAL NET LANGUAGE MODELS" />
    <node id="SELF-TRAINING" />
    <node id="FORWARD INFERENCE" />
    <node id="EMBEDDING MATRIX" />
    <node id="FREEZING" />
    <node id="OPTIMIZATION ALGORITHMS" />
    <node id="CONNECTIONIST MODELS" />
    <node id="DISTRIBUTED REPRESENTATIONS" />
    <node id="WORD PREDICTOR" />
    <node id="SEQUENCE MODELING" />
    <node id="RECURRENT NEURAL NETWORKS (RNN)" />
    <node id="BACKPROPAGATION THROUGH TIME" />
    <node id="TEMPORAL DIMENSION" />
    <node id="INFERENCE" />
    <node id="WEIGHT MATRIX U" />
    <node id="WEIGHT MATRIX W" />
    <node id="WEIGHT MATRIX V" />
    <node id="HIDDEN DIMENSION" />
    <node id="MODEL DIMENSION" />
    <node id="SCORE" />
    <node id="TRAINING" />
    <node id="SEQUENCE PROBABILITY" />
    <node id="TEACHER FORCING" />
    <node id="WEIGHT TYING" />
    <node id="SEQUENCE CLASSIFICATION" />
    <node id="SOFTMAX LAYER" />
    <node id="END-TO-END TRAINING" />
    <node id="SELF-SUPERVISED LEARNING" />
    <node id="TEXT GENERATION" />
    <node id="AUTOREGRESSIVE GENERATION" />
    <node id="GENERATIVE AI" />
    <node id="SUMMARIZATION" />
    <node id="STACKED RNN" />
    <node id="BIDIRECTIONAL RNN" />
    <node id="VANISHING GRADIENTS" />
    <node id="FORGET GATE" />
    <node id="ADD GATE" />
    <node id="OUTPUT GATE" />
    <node id="SIGMOID ACTIVATION FUNCTION" />
    <node id="HADAMARD PRODUCT" />
    <node id="ENCODER-DECODER MODEL" />
    <node id="CONTEXT VECTOR" />
    <node id="GATED RECURRENT UNIT (GRU)" />
    <node id="LANGUAGE MODELING" />
    <node id="DECODER" />
    <node id="ENCODER" />
    <node id="HIDDEN STATE" />
    <node id="EMBEDDING LAYER" />
    <node id="SENTENCE SEPARATOR TOKEN" />
    <node id="BILSTM" />
    <node id="ENCODER-DECODER APPROACH" />
    <node id="ATTENTION MECHANISM" />
    <node id="SOFTMAX OUTPUT" />
    <node id="LOSS" />
    <node id="DOT-PRODUCT ATTENTION" />
    <node id="SELF-ATTENTION" />
    <node id="BILINEAR MODEL" />
    <node id="SCORE FUNCTION" />
    <node id="BACKPROPAGATION THROUGH TIME (BPTT)" />
    <node id="BPTT" />
    <node id="PROBABILISTIC LANGUAGE MODELING" />
    <node id="AUTO-REGRESSIVE GENERATION" />
    <node id="ENCODER-DECODER ARCHITECTURE" />
    <node id="PARALLEL DISTRIBUTED PROCESSING" />
    <node id="ELMAN NETWORK" />
    <node id="JORDAN NETWORK" />
    <node id="CONVOLUTIONAL NETWORKS" />
    <node id="CONFERENCE ON NATURAL LANGUAGE LEARNING (CONLL)" />
    <node id="SEMEVAL" />
    <node id="ONTONOTES" />
    <node id="PROPBANK" />
    <node id="PHONEME RECOGNITION" />
    <node id="HANDWRITING RECOGNITION" />
    <node id="SYNTACTIC CHUNKING" />
    <node id="OPINION MINING" />
    <node id="AMR PARSING" />
    <node id="CNN ENCODER" />
    <node id="RNN DECODER" />
    <node id="TIMIT" />
    <node id="GENERATIVE DECODER" />
    <node id="SOFT WEIGHTING" />
    <node id="MULTI-HEAD ATTENTION" />
    <node id="LANGUAGE MODELING HEAD" />
    <node id="UNEMBEDDING MATRIX" />
    <node id="CAUSAL SELF-ATTENTION" />
    <node id="QUERY" />
    <node id="KEY" />
    <node id="VALUE" />
    <node id="ATTENTION HEAD" />
    <node id="ROAD" />
    <node id="CHICKEN" />
    <node id="TOKEN" />
    <node id="LAYER" />
    <node id="KEY VECTOR" />
    <node id="QUERY VECTOR" />
    <node id="WEIGHT MATRIX WK" />
    <node id="VALUE VECTOR" />
    <node id="WEIGHT MATRIX WQ" />
    <node id="WEIGHT MATRIX WV" />
    <node id="TRANSFORMER BLOCK" />
    <node id="WEIGHT MATRIX WO" />
    <node id="RESIDUAL CONNECTIONS" />
    <node id="LAYER NORM" />
    <node id="FEEDFORWARD" />
    <node id="RESIDUAL STREAM" />
    <node id="DIMENSIONALITY DK" />
    <node id="MODEL DIMENSIONALITY" />
    <node id="DIMENSIONALITY DV" />
    <node id="MASKING" />
    <node id="QUERY, KEY, VALUE MATRICES" />
    <node id="STACKING" />
    <node id="PARALLELIZATION" />
    <node id="GPT-3" />
    <node id="T5" />
    <node id="MATRIX X" />
    <node id="LAYER NORMALIZATION" />
    <node id="FEEDFORWARD NETWORK (FFN)" />
    <node id="TOKEN EMBEDDING" />
    <node id="POSITIONAL EMBEDDING" />
    <node id="ABSOLUTE POSITION EMBEDDING" />
    <node id="RELATIVE POSITION EMBEDDING" />
    <node id="DECODER-ONLY MODEL" />
    <node id="FEEDFORWARD LAYER" />
    <node id="POSITIONAL ENCODING" />
    <node id="STACKED TRANSFORMER BLOCKS" />
    <node id="MEMORY NETWORKS" />
    <node id="UNEMBEDDING LAYER" />
    <node id="LOGIT LENS" />
    <node id="CAUSAL LANGUAGE MODEL" />
    <node id="CONDITIONAL GENERATION" />
    <node id="TEXT COMPLETION" />
    <node id="PROMPT" />
    <node id="TEXT SUMMARIZATION" />
    <node id="GREEDY DECODING" />
    <node id="POSITIVE" />
    <node id="NEGATIVE" />
    <node id="CNN/DAILY MAIL SUMMARIZATION CORPUS" />
    <node id="SAMPLING METHODS" />
    <node id="RANDOM SAMPLING" />
    <node id="TOP-K SAMPLING" />
    <node id="TOP-P SAMPLING" />
    <node id="TEMPERATURE SAMPLING" />
    <node id="END-OF-SEQUENCE TOKEN" />
    <node id="SELF-SUPERVISED TRAINING" />
    <node id="TRANSFORMER LANGUAGE MODEL" />
    <node id="CE LOSS" />
    <node id="BATCH SIZE" />
    <node id="COMMON CRAWL" />
    <node id="C4" />
    <node id="WIKIPEDIA" />
    <node id="THE PILE" />
    <node id="DOLMA" />
    <node id="FAQ LISTS" />
    <node id="TRANSLATION" />
    <node id="SUMMARIES" />
    <node id="TRAINING SEQUENCE" />
    <node id="LLAMA 3" />
    <node id="PRETRAINING DATA" />
    <node id="QUALITY FILTERING" />
    <node id="SAFETY FILTERING" />
    <node id="COPYRIGHT" />
    <node id="DATA CONSENT" />
    <node id="PRIVACY" />
    <node id="FINETUNING" />
    <node id="INTERNET" />
    <node id="PROSE" />
    <node id="DIALOGUE" />
    <node id="DE-DUPLICATION" />
    <node id="FAIR USE DOCTRINE" />
    <node id="ROBOTS.TXT" />
    <node id="PARAMETER-EFFICIENT FINETUNING" />
    <node id="SUPERVISED FINETUNING" />
    <node id="MODEL SIZE" />
    <node id="ENERGY USAGE" />
    <node id="MEMORY CONSTRAINTS" />
    <node id="KV CACHE" />
    <node id="FAIRNESS" />
    <node id="STEREOSET" />
    <node id="REALTOXICITYPROMPTS" />
    <node id="BBQ" />
    <node id="RAWLSIAN FAIRNESS" />
    <node id="DYNABENCH" />
    <node id="HELM" />
    <node id="LLAMA 3.1 405B INSTRUCT" />
    <node id="SCALING LAWS" />
    <node id="LORA" />
    <node id="COMPUTE BUDGET" />
    <node id="DATASET SIZE" />
    <node id="ATTENTION VECTOR" />
    <node id="PARAMETER-EFFICIENT FINE TUNING" />
    <node id="LOW-RANK ADAPTATION" />
    <node id="MATRIX MULTIPLICATION" />
    <node id="HALLUCINATION" />
    <node id="TOXIC LANGUAGE" />
    <node id="MISINFORMATION" />
    <node id="PRIVACY VIOLATIONS" />
    <node id="DATASETS" />
    <node id="NLP TASKS" />
    <node id="SAMPLING ALGORITHM" />
    <node id="CV CACHE" />
    <node id="MASKED LANGUAGE MODELING (MLM)" />
    <node id="GPT2" />
    <node id="FOUNDATION MODEL" />
    <node id="CAUSAL TRANSFORMERS" />
    <node id="AUTOREGRESSIVE LANGUAGE MODEL" />
    <node id="ZERO-SHOT LEARNING" />
    <node id="VISION" />
    <node id="SPEECH" />
    <node id="GENETICS" />
    <node id="WORDPIECE" />
    <node id="SPANBERT" />
    <node id="ROBERTA" />
    <node id="TRANSFER LEARNING" />
    <node id="NATURAL LANGUAGE INFERENCE (NLI)" />
    <node id="XLM-ROBERTA" />
    <node id="SENTENCEPIECE UNIGRAM LM" />
    <node id="MULTIHEAD ATTENTION" />
    <node id="CLOZE TASK" />
    <node id="DENOISING" />
    <node id="BIDIRECTIONAL ENCODERS" />
    <node id="NEXT SENTENCE PREDICTION (NSP)" />
    <node id="POSITIVE PAIRS" />
    <node id="RANDOM PAIRS" />
    <node id="BOOKSCORPUS" />
    <node id="MULTILINGUAL MODELS" />
    <node id="XLM-R" />
    <node id="UMAP" />
    <node id="CONTEXTUAL EMBEDDINGS AND WORD SENSE" />
    <node id="CURSE OF MULTILINGUALITY" />
    <node id="FINE-TUNING" />
    <node id="ELMO" />
    <node id="NEAREST-NEIGHBOR CLASSIFIER" />
    <node id="SEMANTIC CLUSTERS" />
    <node id="ANISOTROPY" />
    <node id="SEMCORE" />
    <node id="SENSEEVAL" />
    <node id="NSP OBJECTIVE" />
    <node id="MULTI-GENRE NATURAL LANGUAGE INFERENCE (MULTINLI)" />
    <node id="BIO TAGGING" />
    <node id="GEO-POLITICAL ENTITY (GPE)" />
    <node id="TEMPORAL EXPRESSION" />
    <node id="NUMERICAL EXPRESSIONS" />
    <node id="SUPERVISED TRAINING DATA" />
    <node id="CLASSIFIER HEAD" />
    <node id="CLS TOKEN" />
    <node id="LOGISTIC CLASSIFIER" />
    <node id="PREMISE" />
    <node id="HYPOTHESIS" />
    <node id="BIOES TAGGING" />
    <node id="CONDITIONAL RANDOM FIELD (CRF)" />
    <node id="WORDPIECE TOKENIZATION" />
    <node id="PREFERENCE ALIGNMENT" />
    <node id="F1 MEASURE" />
    <node id="SAFETY TRAINING" />
    <node id="RLHF (REINFORCEMENT LEARNING FROM HUMAN FEEDBACK)" />
    <node id="DPO (DIRECT POLICY OPTIMIZATION)" />
    <node id="LLM (LARGE LANGUAGE MODEL)" />
    <node id="PROMPT ENGINEERING" />
    <node id="TEMPLATE" />
    <node id="CHAIN-OF-THOUGHT (COT)" />
    <node id="DEMONSTRATIONS" />
    <node id="FEW-SHOT PROMPTING" />
    <node id="ZERO-SHOT PROMPTING" />
    <node id="SENTIMENT PROMPT" />
    <node id="DANGEROUSLY IN LOVE" />
    <node id="BEYONCÉ" />
    <node id="GRAMMY AWARDS" />
    <node id="BILLBOARD HOT 100" />
    <node id="SQUAD 2.0 DATASET" />
    <node id="NATURAL INSTRUCTIONS DATASET" />
    <node id="ZERO-SHOT SETTING" />
    <node id="DSPY" />
    <node id="TASK PERFORMANCE" />
    <node id="INDUCTION HEADS" />
    <node id="LLAMA-3-8B" />
    <node id="INTERNLM2-20B" />
    <node id="NEEDLE-IN-THE-HAYSTACK TASK" />
    <node id="MULTIPLE-CHOICE QUESTION ANSWERING" />
    <node id="ROUGE" />
    <node id="CHRF" />
    <node id="PREFIX MATCHING MECHANISM" />
    <node id="COPYING MECHANISM" />
    <node id="FUZZY PATTERN COMPLETION RULE" />
    <node id="ABLATION" />
    <node id="LARGE LANGUAGE MODELS (LLMS)" />
    <node id="GEHMAN ET AL. (2020)" />
    <node id="CHENG ET AL. (2023)" />
    <node id="BROWN ET AL. (2020)" />
    <node id="SHENG ET AL. (2019)" />
    <node id="SUPERVISED FINE TUNING (SFT)" />
    <node id="AYA" />
    <node id="SUPERNATURAL INSTRUCTIONS" />
    <node id="FLAN 2022" />
    <node id="OPT-IML" />
    <node id="BASE MODEL" />
    <node id="TASK-BASED FINE TUNING" />
    <node id="OLSSON ET AL. (2022)" />
    <node id="CROSBIE AND SHUTOVA (2022)" />
    <node id="ANNOTATOR SKEW" />
    <node id="AYA DATASET" />
    <node id="MALAGASY" />
    <node id="KURDISH" />
    <node id="SINDHI" />
    <node id="SQUAD DATASET" />
    <node id="SUPER NATURAL INSTRUCTIONS" />
    <node id="FEW-SHOT LEARNING" />
    <node id="EXTRACTIVE QUESTION ANSWERING" />
    <node id="ANNOTATORS" />
    <node id="INSTRUCTION-TUNING DATA" />
    <node id="TASK TEMPLATES" />
    <node id="SAFETY INSTRUCTIONS" />
    <node id="REASONING TASKS" />
    <node id="TASK CLUSTERS" />
    <node id="INSTRUCTION-TUNING DATASET" />
    <node id="CROWDWORKER ANNOTATION GUIDELINE" />
    <node id="LEAVE-ONE-OUT APPROACH" />
    <node id="CHAIN-OF-THOUGHT (COT) PROMPTING" />
    <node id="ANSWER-ONLY PROMPTING" />
    <node id="TEMPORAL SEQUENCES" />
    <node id="FEW-SHOT EXEMPLARS" />
    <node id="MODEL SCALE" />
    <node id="CODEX" />
    <node id="INSTRUCTGPT" />
    <node id="PARSING AS LANGUAGE MODELING (PALM)" />
    <node id="EXACT MATCH (EM)" />
    <node id="BBH" />
    <node id="HUMAN-RATER BASELINES" />
    <node id="PROMPT OPTIMIZATION" />
    <node id="CANDIDATE SCORING" />
    <node id="PROMPT EXPANSION" />
    <node id="ITERATIVE IMPROVEMENT SEARCH" />
    <node id="PRIORITY QUEUE" />
    <node id="EXECUTION ACCURACY" />
    <node id="PARAPHRASING" />
    <node id="UNINFORMED SEARCH" />
    <node id="CRITIQUE" />
    <node id="MULTIPLE-CHOICE TASKS" />
    <node id="TASK DESCRIPTIONS" />
    <node id="OPTIONS" />
    <node id="EARLY STOPPING" />
    <node id="MMLU" />
    <node id="ENCODER-DECODER NETWORK" />
    <node id="DIGITAL DIVIDE" />
    <node id="POST-EDITING" />
    <node id="COMPUTER-AIDED TRANSLATION (CAT)" />
    <node id="INCREMENTAL TRANSLATION" />
    <node id="IMAGE-CENTRIC TRANSLATION" />
    <node id="LOCALIZATION" />
    <node id="LINGUISTIC TYPOLOGY" />
    <node id="WORD ORDER TYPOLOGY" />
    <node id="WORLD ATLAS OF LANGUAGE STRUCTURES (WALS)" />
    <node id="SVO" />
    <node id="SOV" />
    <node id="VSO" />
    <node id="STRUCTURAL REORDERINGS" />
    <node id="LEXICAL DIVERGENCES" />
    <node id="LEXICAL GAP" />
    <node id="VERB-FRAMED LANGUAGES" />
    <node id="SATELLITE-FRAMED LANGUAGES" />
    <node id="MORPHOLOGICAL TYPOLOGY" />
    <node id="ISOLATING LANGUAGES" />
    <node id="POLYSYNTHETIC LANGUAGE" />
    <node id="AGGLUTINATIVE LANGUAGES" />
    <node id="FUSION LANGUAGES" />
    <node id="SUBWORD MODELS" />
    <node id="REFERENTIAL DENSITY" />
    <node id="PRO-DROP LANGUAGE" />
    <node id="COLD LANGUAGES" />
    <node id="HOT LANGUAGES" />
    <node id="HOT MEDIA" />
    <node id="COLD MEDIA" />
    <node id="NON-PRO-DROP LANGUAGE" />
    <node id="WORDPIECE ALGORITHM" />
    <node id="UNIGRAM TOKENIZATION" />
    <node id="PARALLEL CORPUS" />
    <node id="SENTENCE ALIGNMENT" />
    <node id="EUROPARL CORPUS" />
    <node id="UNITED NATIONS PARALLEL CORPUS" />
    <node id="OPENSUBTITLES CORPUS" />
    <node id="PARACRAWL CORPUS" />
    <node id="ALIGNMENT ALGORITHM" />
    <node id="MULTILINGUAL EMBEDDING SPACE" />
    <node id="CORPUS CLEANUP" />
    <node id="CROSS-ATTENTION" />
    <node id="SEARCH TREE" />
    <node id="SOURCE LANGUAGE" />
    <node id="TARGET LANGUAGE" />
    <node id="BEAM WIDTH" />
    <node id="EOS (END OF SEQUENCE)" />
    <node id="LENGTH NORMALIZATION" />
    <node id="FRONTIER" />
    <node id="CHAIN RULE OF PROBABILITY" />
    <node id="MINIMUM BAYES RISK DECODING" />
    <node id="EVALUATION METRICS" />
    <node id="CANDIDATE TRANSLATIONS" />
    <node id="BLEU" />
    <node id="NEWSTATE" />
    <node id="ADDTOBEAM" />
    <node id="BACKTRANSLATION" />
    <node id="PARALLEL CORPORA" />
    <node id="BITEXT" />
    <node id="DATA AUGMENTATION" />
    <node id="MONOLINGUAL CORPUS" />
    <node id="GREEDY INFERENCE" />
    <node id="LOW-RESOURCE LANGUAGES" />
    <node id="SOCIO-TECHNICAL ISSUES" />
    <node id="PARTICIPATORY DESIGN" />
    <node id="ADEQUACY" />
    <node id="FLUENCY" />
    <node id="HUMAN RATERS" />
    <node id="AUTOMATIC EVALUATION" />
    <node id="CHR-F" />
    <node id="F-SCORE" />
    <node id="BERTSCORE" />
    <node id="PIONEERING WORK OF MILLER AND BEEBE-CENTER" />
    <node id="PAIRED BOOTSTRAP TEST" />
    <node id="RANDOMIZATION TEST" />
    <node id="SACREBLEU" />
    <node id="METEOR" />
    <node id="TASK ERROR RATE (TER)" />
    <node id="EMBEDDING-BASED METHODS" />
    <node id="COMET" />
    <node id="BLEURT" />
    <node id="CANDIDATE" />
    <node id="PAIRWISE COSINE SIMILARITY" />
    <node id="RBERT" />
    <node id="MAXIMUM SIMILARITY" />
    <node id="IDF WEIGHTS" />
    <node id="IMPORTANCE WEIGHTING" />
    <node id="WEIGHTING" />
    <node id="SIMILARITY SCORE" />
    <node id="RECALL METRIC RBERT" />
    <node id="TRANSFORMER ENCODER" />
    <node id="NONLINEAR TRANSFORMATIONS" />
    <node id="WINOMT DATASET" />
    <node id="EMBEDDING SIMILARITY" />
    <node id="TRANSFER APPROACHES" />
    <node id="DIRECT TRANSLATION" />
    <node id="INTERLINGUA APPROACHES" />
    <node id="VAUQUOIS TRIANGLE" />
    <node id="STATISTICAL MT" />
    <node id="IBM MODELS" />
    <node id="MAXENT" />
    <node id="PHRASE-BASED TRANSLATION" />
    <node id="HANSARD CORPUS" />
    <node id="CANDIDE" />
    <node id="NOISY CHANNEL MODEL" />
    <node id="MINIMUM ERROR RATE TRAINING (MERT)" />
    <node id="NIST" />
    <node id="GIZA" />
    <node id="MOSES" />
    <node id="TRANSDUCTION GRAMMARS" />
    <node id="INVERSION TRANSDUCTION GRAMMAR" />
    <node id="SYNCHRONOUS CONTEXT-FREE GRAMMARS" />
    <node id="NEURAL ENCODER-DECODER" />
    <node id="TRANSFORMER ENCODER-DECODER" />
    <node id="FACTOID QUESTIONS" />
    <node id="IBM WATSON" />
    <node id="DEEP THOUGHT" />
    <node id="ALPAC REPORT" />
    <node id="CALIBRATION" />
    <node id="AD HOC RETRIEVAL" />
    <node id="NEURAL RETRIEVERS" />
    <node id="COLLECTION" />
    <node id="TERM WEIGHTING" />
    <node id="BM25" />
    <node id="LEGAL DOMAIN" />
    <node id="QA DATASET" />
    <node id="PROPRIETARY DATA" />
    <node id="DOCUMENT VECTOR LENGTH" />
    <node id="TF-IDF COSINE" />
    <node id="STOP LIST" />
    <node id="INVERTED INDEX" />
    <node id="RANKED RETRIEVAL SYSTEM" />
    <node id="DOCUMENT 1" />
    <node id="DOCUMENT 2" />
    <node id="PRECISION-RECALL CURVE" />
    <node id="MEAN AVERAGE PRECISION (MAP)" />
    <node id="INTERPOLATED PRECISION" />
    <node id="VOCABULARY MISMATCH PROBLEM" />
    <node id="BI-ENCODER" />
    <node id="TRANSFORMER SELF-ATTENTION" />
    <node id="LINEAR LAYER" />
    <node id="COLBERT" />
    <node id="MAXSIM" />
    <node id="RAG (RETRIEVAL-AUGMENTED GENERATION)" />
    <node id="RETRIEVER" />
    <node id="READER" />
    <node id="FAISS" />
    <node id="MS MARCO" />
    <node id="MULTI-HOP ARCHITECTURES" />
    <node id="NEAREST NEIGHBOR SEARCH" />
    <node id="MEAN RECIPROCAL RANK (MRR)" />
    <node id="RETRIEVER/READER ARCHITECTURE" />
    <node id="NATURAL QUESTIONS" />
    <node id="READING COMPREHENSION" />
    <node id="F1 SCORE" />
    <node id="GOOGLE SEARCH ENGINE" />
    <node id="MICROSOFT BING" />
    <node id="CLOSED BOOK QA" />
    <node id="RANKED RETRIEVAL" />
    <node id="ATTRIBUTE-VALUE MATRIX" />
    <node id="ZELLIG HARRIS'S TDAP PROJECT" />
    <node id="LUNAR SYSTEM" />
    <node id="GEOQUERY DATASET" />
    <node id="PREDICATE CALCULUS" />
    <node id="NEURAL MODELS" />
    <node id="TREC" />
    <node id="DEEPQA" />
    <node id="INFORMATION-RETRIEVAL PARADIGM" />
    <node id="READING COMPREHENSION TESTS" />
    <node id="ROGERIAN PSYCHOLOGY" />
    <node id="FRAME" />
    <node id="EMOTIONAL ENGAGEMENT" />
    <node id="INSTITUTIONAL REVIEW BOARD (IRB)" />
    <node id="HUMAN CONVERSATION" />
    <node id="TURN-TAKING" />
    <node id="SPEECH ACTS" />
    <node id="GROUNDING" />
    <node id="DIALOGUE STRUCTURE" />
    <node id="GRICEAN PRINCIPLE OF RELEVANCE" />
    <node id="CONVERSATION ANALYSIS" />
    <node id="ADJACENCY PAIRS" />
    <node id="SIDE SEQUENCE" />
    <node id="CLARIFICATION QUESTION" />
    <node id="REQUEST" />
    <node id="RESPONSE" />
    <node id="PRESEQUENCE" />
    <node id="INITIATIVE" />
    <node id="MIXED INITIATIVE" />
    <node id="SYSTEM-INITIATIVE" />
    <node id="USER-INITIATIVE" />
    <node id="IMPLICATURE" />
    <node id="MAXIM OF RELEVANCE" />
    <node id="CONVERSATIONAL IMPLICATURE" />
    <node id="GUS SYSTEM" />
    <node id="DIALOGUE-STATE ARCHITECTURE" />
    <node id="SLOT" />
    <node id="SLOT FILLING" />
    <node id="DOMAIN ONTOLOGY" />
    <node id="DOMAIN CLASSIFICATION" />
    <node id="INTENT DETERMINATION" />
    <node id="TASK-BASED DIALOGUE SYSTEM" />
    <node id="SEQUENCE LABELER" />
    <node id="DATABASE QUERY" />
    <node id="SLOT ERROR RATE" />
    <node id="EFFICIENCY COSTS" />
    <node id="DIALOGUE POLICY" />
    <node id="HIS SYSTEM" />
    <node id="DIALOGUE STATE TRACKING" />
    <node id="USER CORRECTION ACTS" />
    <node id="HYPERARTICULATION" />
    <node id="CONTENT PLANNING" />
    <node id="BIO TAGS" />
    <node id="DOMAIN" />
    <node id="INTENT" />
    <node id="ONTOLOGY" />
    <node id="SYNONYMS" />
    <node id="IMPLICIT CONFIRMATION" />
    <node id="EXPLICIT CONFIRMATION" />
    <node id="ASR SYSTEMS" />
    <node id="REJECTION" />
    <node id="CONFIDENCE LEVELS" />
    <node id="NATURAL LANGUAGE GENERATION" />
    <node id="SENTENCE REALIZATION" />
    <node id="DELEXICALIZATION" />
    <node id="DIALOGUE ACT" />
    <node id="RELEXICALIZATION" />
    <node id="MULTIWOZ" />
    <node id="NEURAL CHATBOTS" />
    <node id="TRAINING CHATBOTS" />
    <node id="TOXICITY CLASSIFIERS" />
    <node id="TOPICAL-CHAT DATASET" />
    <node id="EMPATHETIC DIALOGUES" />
    <node id="SAFERDIALOGUES" />
    <node id="PSEUDO-CONVERSATIONS" />
    <node id="INSTRUCT TUNING" />
    <node id="CONTENT PLANNER" />
    <node id="LAMDA SYSTEM" />
    <node id="RESPONSE TOKEN" />
    <node id="SENSIBLE" />
    <node id="INTERESTING" />
    <node id="UNSAFE" />
    <node id="GENERATIVE TASK" />
    <node id="DISCRIMINATIVE TASK" />
    <node id="SPARROW CHATBOT" />
    <node id="SEARCH QUERY" />
    <node id="SEARCH RESULTS" />
    <node id="REINFORCEMENT LEARNING" />
    <node id="PARTICIPANT EVALUATION" />
    <node id="OBSERVER EVALUATION" />
    <node id="ACUTE-EVAL METRIC" />
    <node id="WIZARD-OF-OZ SYSTEM" />
    <node id="DIALOGUE SYSTEM DESIGN" />
    <node id="VALUE SENSITIVE DESIGN" />
    <node id="ETHICAL ISSUES" />
    <node id="HUMAN-COMPUTER INTERACTION (HCI)" />
    <node id="VOICE USER INTERFACE DESIGN" />
    <node id="MEDICAL ADVICE" />
    <node id="GENDER EQUALITY" />
    <node id="BDI MODELS" />
    <node id="SIRI" />
    <node id="ALEXA" />
    <node id="GOOGLE ASSISTANT" />
    <node id="FRAME-BASED ARCHITECTURE" />
    <node id="TAY CHATBOT" />
    <node id="TOXICITY" />
    <node id="DIALOGUE-STATE MODEL" />
    <node id="TASK-ORIENTED DIALOGUE" />
    <node id="MDP DIALOGUE SYSTEMS" />
    <node id="POMDP MODELS" />
    <node id="NEURAL REINFORCEMENT LEARNING MODELS" />
    <node id="CHATBOT SYSTEMS" />
    <node id="GUS ARCHITECTURE" />
    <node id="DIGITAL ASSISTANTS" />
    <node id="CORPUS-BASED CHATBOT ARCHITECTURES" />
    <node id="SEQUENCE-TO-SEQUENCE MODELS" />
    <node id="AFFECT IN DIALOGUE" />
    <node id="AFFECTIVE COMPUTING" />
    <node id="CTC LOSS FUNCTION" />
    <node id="ACOUSTIC FEATURES" />
    <node id="VOCABULARY SIZE" />
    <node id="READ SPEECH" />
    <node id="CONVERSATIONAL SPEECH" />
    <node id="CHANNEL AND NOISE" />
    <node id="ACCENT OR SPEAKER-CLASS CHARACTERISTICS" />
    <node id="LIBRISPEECH" />
    <node id="AUGMENTATIVE COMMUNICATION" />
    <node id="SMART HOME APPLIANCES" />
    <node id="TELEPHONY APPLICATIONS" />
    <node id="DICTATION" />
    <node id="SPEECH SYNTHESIZER" />
    <node id="AUDIO BOOKS" />
    <node id="BUSINESS MEETING TRANSCRIPTION" />
    <node id="HEAD-MOUNTED MICROPHONES" />
    <node id="DISTANT MICROPHONE" />
    <node id="REGIONAL DIALECTS" />
    <node id="ETHNIC DIALECTS" />
    <node id="CHILDREN'S SPEECH" />
    <node id="REJECTION AND CONFIRMATION" />
    <node id="CUE PHRASES" />
    <node id="PROSODY" />
    <node id="ALS" />
    <node id="NEUROLOGICAL DISORDERS" />
    <node id="PARADISE LOST" />
    <node id="MECHANICAL TURK" />
    <node id="ARTIFICIAL INTELLIGENCE" />
    <node id="VOCAL TRACT" />
    <node id="SWITCHBOARD" />
    <node id="CALLHOME" />
    <node id="SANTA BARBARA CORPUS" />
    <node id="CORAAL" />
    <node id="CHIME CHALLENGE" />
    <node id="HKUST" />
    <node id="AISHELL-1" />
    <node id="CHARACTER ERROR RATE (CER)" />
    <node id="TRANSCRIPTS" />
    <node id="TELEPHONE SPEECH" />
    <node id="DINNER PARTY SPEECH" />
    <node id="ACOUSTIC FEATURE VECTORS" />
    <node id="NYQUIST FREQUENCY" />
    <node id="PCM (PULSE CODE MODULATION)" />
    <node id="M-LAW COMPRESSION" />
    <node id="AIR PRESSURE CHANGES" />
    <node id="ANALOG-TO-DIGITAL CONVERSION" />
    <node id="LINEAR PCM" />
    <node id="M-LAW" />
    <node id="PULSE CODE MODULATION (PCM)" />
    <node id="WAV FORMAT" />
    <node id="RIFF FORMAT" />
    <node id="WINDOWING" />
    <node id="SPECTRAL FEATURES" />
    <node id="RECTANGULAR WINDOW" />
    <node id="HAMMING WINDOW" />
    <node id="DISCRETE FOURIER TRANSFORM (DFT)" />
    <node id="FAST FOURIER TRANSFORM (FFT)" />
    <node id="FOURIER ANALYSIS" />
    <node id="MEL SCALE" />
    <node id="MEL FILTER BANK" />
    <node id="HUMAN AUDITORY PERCEPTION" />
    <node id="ATTENTION-BASED ENCODER DECODER (AED)" />
    <node id="STATIONARY SIGNAL" />
    <node id="NON-STATIONARY SIGNAL" />
    <node id="EULER'S FORMULA" />
    <node id="FORMANTS" />
    <node id="STOP BURSTS" />
    <node id="FRICATIVE NOISE" />
    <node id="BPE (BYTE PAIR ENCODING)" />
    <node id="COMPRESSION STAGE" />
    <node id="ACOUSTIC FRAMES" />
    <node id="SUBSAMPLING" />
    <node id="LOW FRAME RATE" />
    <node id="BLANK SYMBOL" />
    <node id="VITERBI BEAM SEARCH" />
    <node id="RNN-T" />
    <node id="ATTENTION-BASED MODELS" />
    <node id="SCLITE" />
    <node id="MAPSSWE" />
    <node id="FORWARD-BACKWARD ALGORITHM" />
    <node id="WORD ERROR (MAPSSWE) TEST" />
    <node id="SEGMENTS" />
    <node id="Z VARIABLES" />
    <node id="MCNEMAR'S TEST" />
    <node id="TRIGRAM LMS" />
    <node id="TEXT-TO-SPEECH (TTS) SYSTEMS" />
    <node id="LJ SPEECH CORPUS" />
    <node id="VOCODING" />
    <node id="SPEAKER-DEPENDENT" />
    <node id="MEL SPECTROGRAM" />
    <node id="TEXT NORMALIZATION PREPROCESSING" />
    <node id="LSTMS" />
    <node id="SEMIOTIC CLASS" />
    <node id="RULE-BASED NORMALIZATION" />
    <node id="NON-STANDARD WORDS" />
    <node id="VERBALIZATION" />
    <node id="SPEAKER-INDEPENDENT" />
    <node id="VOCODER" />
    <node id="VERBALIZATION GRAMMAR" />
    <node id="TACOTRON2" />
    <node id="WAVENET" />
    <node id="LOCATION-BASED ATTENTION" />
    <node id="CONVOLUTIONAL LAYERS" />
    <node id="PRE-NET" />
    <node id="POST-NET" />
    <node id="STOP TOKEN" />
    <node id="SPECTROGRAM PREDICTION NETWORK" />
    <node id="DILATED CONVOLUTION LAYERS" />
    <node id="MIXTURE OF LOGISTIC DISTRIBUTIONS" />
    <node id="SPECTROGRAM" />
    <node id="TACOTRON 2" />
    <node id="MEAN OPINION SCORE (MOS)" />
    <node id="DILATED CONVOLUTIONS" />
    <node id="SOFTMAX DISTRIBUTION" />
    <node id="MU-LAW COMPRESSION" />
    <node id="GATED ACTIVATION FUNCTION" />
    <node id="SKIP CONNECTIONS" />
    <node id="CAUSAL CONVOLUTIONS" />
    <node id="AB TESTS" />
    <node id="WAKE WORD DETECTION" />
    <node id="VOICE-ENABLED ASSISTANT" />
    <node id="SPEAKER DIARIZATION" />
    <node id="SPEAKER RECOGNITION" />
    <node id="VOICE ACTIVITY DETECTION (VAD)" />
    <node id="LANGUAGE IDENTIFICATION" />
    <node id="HIDDEN MARKOV MODEL (HMM)" />
    <node id="DYNAMIC TIME WARPING" />
    <node id="ENCODER-DECODER WITH ATTENTION" />
    <node id="GAUSSIAN MIXTURE MODELS (GMM)" />
    <node id="TIME-DELAY NEURAL NETWORK (TDNN)" />
    <node id="HYBRID HMM/MLP" />
    <node id="MOORE'S LAW" />
    <node id="GPUS" />
    <node id="DEEP NEURAL NETWORKS" />
    <node id="HMM/GMM SYSTEMS" />
    <node id="RECTIFIED LINEAR UNITS" />
    <node id="HYBRID SYSTEMS" />
    <node id="UNSUPERVISED PRETRAINING" />
    <node id="DEEP BELIEF NETWORKS" />
    <node id="LOG MEL FEATURES" />
    <node id="MFCCS" />
    <node id="RNN-TRANSDUCER" />
    <node id="LISTEN ATTEND AND SPELL" />
    <node id="KALDI" />
    <node id="ESPNET" />
    <node id="FORMANT SYNTHESIS" />
    <node id="HASKINS LABORATORIES PATTERN PLAYBACK MACHINE" />
    <node id="ARTICULATORY SYNTHESIS" />
    <node id="ARTICULATORY SYNTHESIZERS" />
    <node id="KLATT FORMANT SYNTHESIZER" />
    <node id="MITALK" />
    <node id="KLATTALK" />
    <node id="DECTALK" />
    <node id="DIPHONIC SYNTHESIS" />
    <node id="UNIT SELECTION SYNTHESIS" />
    <node id="TEXT-TO-SPEECH SYSTEMS" />
    <node id="SPEECH-TO-SPEECH TRANSLATION" />
    <node id="PHONEMES" />
    <node id="DIPHONES" />
    <node id="LINGUISTIC STRUCTURE" />
    <node id="PARSE" />
    <node id="ENTITY RELATIONS" />
    <node id="EVENT" />
    <node id="COREFERENCE" />
    <node id="RNNS" />
    <node id="OPEN CLASS" />
    <node id="NOUN" />
    <node id="VERB" />
    <node id="ADJECTIVE" />
    <node id="ADVERB" />
    <node id="CLOSED CLASS" />
    <node id="PREPOSITION" />
    <node id="CONJUNCTION" />
    <node id="DETERMINER" />
    <node id="PARTICLE" />
    <node id="AUXILIARY VERB" />
    <node id="COMPLEMENTIZER" />
    <node id="MODAL VERB" />
    <node id="UNIVERSAL DEPENDENCIES TAGSET" />
    <node id="PENN TREEBANK TAGSET" />
    <node id="PENN TREEBANK CORPORA" />
    <node id="EXISTENTIAL THERE" />
    <node id="PROPER NOUN" />
    <node id="AMBIGUITY RESOLUTION" />
    <node id="MOST FREQUENT CLASS BASELINE" />
    <node id="UNIVERSAL DEPENDENCY (UD) TREEBANK" />
    <node id="WSJ CORPUS" />
    <node id="UNAMBIGUOUS WORDS" />
    <node id="AMBIGUOUS WORDS" />
    <node id="TAG AMBIGUITY" />
    <node id="UNIVERSAL DEPENDENCY (UD) TAGSET" />
    <node id="HUMAN PERFORMANCE" />
    <node id="IO TAGGING" />
    <node id="TRANSITION PROBABILITY MATRIX" />
    <node id="EMISSION PROBABILITIES" />
    <node id="OBSERVATION LIKELIHOOD" />
    <node id="INITIAL PROBABILITY DISTRIBUTION" />
    <node id="A TRANSITION PROBABILITIES" />
    <node id="B EMISSION PROBABILITIES" />
    <node id="OUTPUT INDEPENDENCE" />
    <node id="DECODE" />
    <node id="BIGRAM TAGGER" />
    <node id="BAYES' RULE" />
    <node id="TRANSITION PROBABILITY" />
    <node id="LOG-LINEAR MODEL" />
    <node id="LINEAR-CHAIN CRF" />
    <node id="FEATURE FUNCTION" />
    <node id="WORD SHAPE FEATURES" />
    <node id="POS TAGGER" />
    <node id="KNOWN-WORD TEMPLATES" />
    <node id="UNKNOWN-WORD FEATURES" />
    <node id="PART-OF-SPEECH (POS)" />
    <node id="GLOBAL FEATURES" />
    <node id="LOCAL FEATURES" />
    <node id="GAZETTEER" />
    <node id="ONTO NOTES" />
    <node id="RULE-BASED METHODS" />
    <node id="UNIVERSAL DEPENDENCIES" />
    <node id="MORPHOLOGICALLY RICH LANGUAGES" />
    <node id="HMM TAGGING" />
    <node id="CRF TAGGING" />
    <node id="GENERATIVE APPROACH" />
    <node id="TAG-LABELED TRAINING CORPORA" />
    <node id="DISCRIMINATIVE APPROACH" />
    <node id="NEURAL APPROACHES" />
    <node id="SUPERVISED TAGGING" />
    <node id="UNSUPERVISED ALGORITHMS" />
    <node id="LOB CORPUS" />
    <node id="CLAWS TAGGER" />
    <node id="MXPOST" />
    <node id="MAXIMUM ENTROPY MARKOV MODELS (MEMM)" />
    <node id="TOKENIZER" />
    <node id="POS-TAGGED TRAINING SET" />
    <node id="BIGRAM HMM TAGGER" />
    <node id="ERROR RATE" />
    <node id="PART-OF-SPEECH-TAGGED CORPUS" />
    <node id="OBSERVATION PROBABILITIES" />
    <node id="BIO TAGGING SCHEME" />
    <node id="NER SYSTEM" />
    <node id="PARSE TREE" />
    <node id="PARSE AMBIGUITY" />
    <node id="NEURAL SPAN-BASED PARSER" />
    <node id="METRICS FOR EVALUATING PARSER ACCURACY" />
    <node id="GRAMMAR CHECKING" />
    <node id="FORMAL SEMANTIC ANALYSIS" />
    <node id="NODE" />
    <node id="FORMAL LANGUAGE" />
    <node id="GENERATIVE GRAMMAR" />
    <node id="PRODUCTION RULE" />
    <node id="DERIVATION" />
    <node id="START SYMBOL" />
    <node id="SENTENCE" />
    <node id="NOUN PHRASE (NP)" />
    <node id="VERB PHRASE (VP)" />
    <node id="PREPOSITIONAL PHRASE (PP)" />
    <node id="ATIS CORPUS" />
    <node id="SYNTACTIC PARSING" />
    <node id="BRACKETED NOTATION" />
    <node id="GRAMMATICAL SENTENCE" />
    <node id="UNGRAMMATICAL SENTENCE" />
    <node id="PENN TREEBANK" />
    <node id="NON-TERMINAL SYMBOL" />
    <node id="TERMINAL SYMBOL" />
    <node id="CHOMSKY NORMAL FORM (CNF)" />
    <node id="CHOMSKY-ADJUNCTION" />
    <node id="BINARY BRANCHING" />
    <node id="STRUCTURAL AMBIGUITY" />
    <node id="SYNTACTIC DISAMBIGUATION" />
    <node id="ATTACHMENT AMBIGUITY" />
    <node id="COORDINATION AMBIGUITY" />
    <node id="GRAMMAR" />
    <node id="UNIT PRODUCTION" />
    <node id="DUMMY NON-TERMINAL" />
    <node id="LEXICAL RULE" />
    <node id="CHART PARSING" />
    <node id="FENCEPOSTS" />
    <node id="NON-TERMINAL" />
    <node id="TERMINAL" />
    <node id="CNF (CHOMSKY NORMAL FORM)" />
    <node id="NEURAL CKY" />
    <node id="PARSER" />
    <node id="PROBABILISTIC PARSERS" />
    <node id="SPAN-BASED CONSTITUENCY PARSING" />
    <node id="MLP (MULTI-LAYER PERCEPTRON)" />
    <node id="CONSTITUENT" />
    <node id="TRANSFORMER LAYERS" />
    <node id="SPAN SCORES" />
    <node id="MARGIN-BASED TRAINING ALGORITHM" />
    <node id="HEAD-FINDING" />
    <node id="PARSEVAL METRIC" />
    <node id="GOLD STANDARD" />
    <node id="CROSSING BRACKETS" />
    <node id="LEXICAL HEAD" />
    <node id="HEAD PERCOLATION TABLE" />
    <node id="NEURAL CONSTITUENCY PARSERS" />
    <node id="DYNAMIC PROGRAMMING PARSING" />
    <node id="LABELED RECALL" />
    <node id="LABELED PRECISION" />
    <node id="PARTIAL PARSING" />
    <node id="CHUNKING" />
    <node id="DEPENDENCY GRAMMAR" />
    <node id="WELL-FORMED SUBSTRING TABLE (WFST)" />
    <node id="EARLEY ALGORITHM" />
    <node id="MEMOIZATION" />
    <node id="PROBABILISTIC CONTEXT-FREE GRAMMARS" />
    <node id="NEURAL PARSING ALGORITHMS" />
    <node id="RECURSIVE NEURAL ARCHITECTURES" />
    <node id="SPAN-BASED SELF-ATTENTION" />
    <node id="DISCOVERY PROCEDURE" />
    <node id="IMMEDIATE-CONSTITUENT ANALYSIS" />
    <node id="DISTRIBUTIONAL SIMILARITY" />
    <node id="HEAD-DEPENDENT RELATIONSHIP" />
    <node id="PROJECTIVITY" />
    <node id="TRANSITION-BASED PARSING" />
    <node id="GRAPH-BASED PARSING" />
    <node id="DEPENDENCY TREEBANKS" />
    <node id="CLAUSAL RELATIONS" />
    <node id="MODIFIER RELATIONS" />
    <node id="ARC" />
    <node id="VERTEX" />
    <node id="GRAMMATICAL RELATION" />
    <node id="UNIVERSAL DEPENDENCY RELATIONS" />
    <node id="NON-PROJECTIVE TREES" />
    <node id="SHIFT-REDUCE PARSING" />
    <node id="ROOT NODE" />
    <node id="DEPENDENCY TREE" />
    <node id="STACK" />
    <node id="LEFT ARC" />
    <node id="RIGHT ARC" />
    <node id="TRANSITION OPERATOR" />
    <node id="BUFFER" />
    <node id="SHIFT" />
    <node id="ORACLE" />
    <node id="TRAINING ORACLE" />
    <node id="ARC STANDARD" />
    <node id="CONFIGURATION" />
    <node id="ROOT" />
    <node id="REFERENCE PARSE" />
    <node id="FEATURE-BASED CLASSIFIER" />
    <node id="NEURAL CLASSIFIER" />
    <node id="ARC EAGER" />
    <node id="WORD BUFFER" />
    <node id="SUPPORT VECTOR MACHINES (SVM)" />
    <node id="ARC-STANDARD APPROACH" />
    <node id="ARC-EAGER SYSTEM" />
    <node id="REDUCE" />
    <node id="MAXIMUM SPANNING TREE" />
    <node id="INPUT BUFFER" />
    <node id="HEAD-DEPENDENT RELATION" />
    <node id="DEPENDENCY PARSE" />
    <node id="DIRECTED GRAPH" />
    <node id="GRAPH" />
    <node id="CHU-LIU EDMONDS ALGORITHM" />
    <node id="SPANNING TREE" />
    <node id="CYCLE" />
    <node id="EDGE" />
    <node id="FEATURE-BASED ALGORITHM" />
    <node id="NEURAL ALGORITHM" />
    <node id="EDGE SCORE" />
    <node id="BIAFFINE PARSER" />
    <node id="INFERENCE-BASED LEARNING" />
    <node id="PERCEPTRON LEARNING RULE" />
    <node id="BIAFFINE FUNCTION" />
    <node id="MAXIMUM SPANNING TREE ALGORITHM" />
    <node id="EDGE-SCORER" />
    <node id="LABEL-SCORER" />
    <node id="LABELED ATTACHMENT SCORE (LAS)" />
    <node id="UNLABELED ATTACHMENT SCORE (UAS)" />
    <node id="LABEL ACCURACY SCORE (LS)" />
    <node id="PRAGUE DEPENDENCY TREEBANK" />
    <node id="STANFORD DEPENDENCIES" />
    <node id="GOOGLE'S UNIVERSAL PART-OF-SPEECH TAGS" />
    <node id="INTERSET INTERLINGUA" />
    <node id="DEPEND ABLE" />
    <node id="TEMPLATE FILLING" />
    <node id="ACE RELATION EXTRACTION TASK" />
    <node id="TACRED" />
    <node id="UMLS" />
    <node id="RDF" />
    <node id="DBPEDIA" />
    <node id="FREEBASE" />
    <node id="AIRLINE ANNOUNCEMENTS" />
    <node id="STOCK PRICES" />
    <node id="FARE INCREASE" />
    <node id="UNITED AIRLINES" />
    <node id="AMERICAN AIRLINES" />
    <node id="UAL CORP." />
    <node id="CHICAGO" />
    <node id="DALLAS" />
    <node id="DENVER" />
    <node id="SAN FRANCISCO" />
    <node id="AMR CORP." />
    <node id="TIM WAGNER" />
    <node id="INSTANCE-OF RELATION" />
    <node id="TACRED DATASET" />
    <node id="TAC KBP CHALLENGES" />
    <node id="RELATION TRIPLES" />
    <node id="RELATION TYPES" />
    <node id="NO RELATION TAG" />
    <node id="SEMEVAL 2010 TASK 8" />
    <node id="HEARST PATTERNS" />
    <node id="SUPERVISED LEARNING" />
    <node id="NEURAL SUPERVISED RELATION CLASSIFIERS" />
    <node id="HAND-BUILT PATTERNS" />
    <node id="NER TAGS" />
    <node id="NEGATIVE DATA" />
    <node id="TRANSFORMER-ENCODER ALGORITHM" />
    <node id="PRETRAINED ENCODER" />
    <node id="SEMI-SUPERVISED LEARNING" />
    <node id="UNSUPERVISED APPROACHES" />
    <node id="BOOTSTRAPPING" />
    <node id="SEED PATTERNS" />
    <node id="SEED TUPLES" />
    <node id="PATTERNS" />
    <node id="TUPLES" />
    <node id="CONFIDENCE VALUES" />
    <node id="SEMANTIC DRIFT" />
    <node id="NOISY-OR TECHNIQUE" />
    <node id="DISTANT SUPERVISION" />
    <node id="SUPERVISED CLASSIFIER" />
    <node id="NAMED ENTITY TAGGERS" />
    <node id="DATABASE" />
    <node id="PLACE-OF-BIRTH RELATIONSHIP" />
    <node id="FEATURE-BASED CLASSIFICATION" />
    <node id="NO-RELATION LABEL" />
    <node id="UNSUPERVISED RELATION EXTRACTION" />
    <node id="OPEN INFORMATION EXTRACTION" />
    <node id="REVERB" />
    <node id="KNOWLEDGE GRAPHS" />
    <node id="CONSTRAINTS" />
    <node id="LOGISTIC REGRESSION CLASSIFIER" />
    <node id="LIGHT VERBS" />
    <node id="TEMPORAL PROPERTIES" />
    <node id="HYPERNYM" />
    <node id="HYPONYM" />
    <node id="SEED-BASED SYSTEMS" />
    <node id="IOB SEQUENCE MODELS" />
    <node id="MULTI-CLASS CLASSIFIERS" />
    <node id="FEATURE-BASED MODELS" />
    <node id="TEMPORAL LOGIC" />
    <node id="INTERVAL ALGEBRA" />
    <node id="ALLEN RELATIONS" />
    <node id="TEMPORAL REPRESENTATION SYSTEMS" />
    <node id="REFERENCE POINT" />
    <node id="ASPECT" />
    <node id="STATES" />
    <node id="ACTIVITY" />
    <node id="ACCOMPLISHMENT" />
    <node id="ACHIEVEMENT" />
    <node id="TELIC EVENTS" />
    <node id="SAID EVENTS" />
    <node id="PAST" />
    <node id="REICHENBACH'S APPROACH" />
    <node id="PRESENT" />
    <node id="FUTURE" />
    <node id="TIMEBANK" />
    <node id="TIMEML" />
    <node id="TIME" />
    <node id="LINK" />
    <node id="TLINK" />
    <node id="ALINK" />
    <node id="SLINK" />
    <node id="TEMPORAL NORMALIZATION" />
    <node id="ISO 8601" />
    <node id="DELTA AIR LINES" />
    <node id="EARNINGS" />
    <node id="FISCAL FIRST QUARTER" />
    <node id="PACIFIC FIRST FINANCIAL CORP." />
    <node id="ACQUISITION" />
    <node id="ROYAL TRUSTCO LTD." />
    <node id="REGULATORY APPROVAL" />
    <node id="TRANSACTION" />
    <node id="WEEKEND" />
    <node id="ISO WEEK" />
    <node id="DURATION" />
    <node id="ANCHOR TIMEID" />
    <node id="ISO8601" />
    <node id="TEMPORAL ANCHOR" />
    <node id="TEMPORAL ARITHMETIC" />
    <node id="CLEAR TK" />
    <node id="TIME RELATION CLASSIFIERS" />
    <node id="TARSQI" />
    <node id="CAEVO" />
    <node id="CATENA" />
    <node id="ROLE-FILLER EXTRACTION" />
    <node id="SCRIPT" />
    <node id="FASTUS" />
    <node id="FINITE-STATE TRANSDUCERS" />
    <node id="MUC-5" />
    <node id="MESSAGE UNDERSTANDING CONFERENCES" />
    <node id="OPEN IE" />
    <node id="ENTITIES" />
    <node id="AMOUNT" />
    <node id="PRODUCTION" />
    <node id="START DATE" />
    <node id="TIE-UP" />
    <node id="JOINT VENTURE" />
    <node id="PRODUCT" />
    <node id="FOL TRANSLATIONS" />
    <node id="EVENT PLANNING" />
    <node id="NEWS TEXT" />
    <node id="THEMATIC ROLE" />
    <node id="XYZ CORPORATION" />
    <node id="SELECTIONAL RESTRICTIONS" />
    <node id="PĀṆINI" />
    <node id="DIATHESIS ALTERNATIONS" />
    <node id="LINGUISTIC REALIZATION" />
    <node id="THEMATIC GRID" />
    <node id="SANSKRIT GRAMMAR" />
    <node id="FRAMENET" />
    <node id="VERBNET" />
    <node id="SURFACE FORMS" />
    <node id="SHALLOW SEMANTIC REPRESENTATIONS" />
    <node id="SHELLY" />
    <node id="KNIFE" />
    <node id="FORK" />
    <node id="BANANA" />
    <node id="AGENT" />
    <node id="PROTO-AGENT" />
    <node id="PROTO-PATIENT" />
    <node id="PROP BANK" />
    <node id="NOM BANK" />
    <node id="ARG0" />
    <node id="ARG1" />
    <node id="ARG2" />
    <node id="ARG3" />
    <node id="ARG4" />
    <node id="ARGM" />
    <node id="PENN CHINESE TREEBANK" />
    <node id="VERB-SPECIFIC ROLES" />
    <node id="LEXICAL RESOURCES" />
    <node id="FRAME NET" />
    <node id="FRAME-SPECIFIC ROLES" />
    <node id="FRAME ELEMENTS" />
    <node id="LEXICAL UNITS" />
    <node id="CHANGE POSITION ON A SCALE FRAME" />
    <node id="ATTRIBUTE" />
    <node id="ITEM" />
    <node id="VALUE RANGE" />
    <node id="DIFFERENCE" />
    <node id="FINAL STATE" />
    <node id="FINAL VALUE" />
    <node id="INITIAL STATE" />
    <node id="INITIAL VALUE" />
    <node id="GROUP" />
    <node id="SPEED" />
    <node id="CAUSE CHANGE OF POSITION ON A SCALE" />
    <node id="CHANGE OF POSITION ON A SCALE" />
    <node id="VERBS" />
    <node id="PRECISION, RECALL, AND F-MEASURE" />
    <node id="CONLL-2005 AND CONLL-2012" />
    <node id="WORDNET SYNSETS" />
    <node id="EDIBLE THING" />
    <node id="NEURAL ALGORITHM FOR SRL" />
    <node id="CRF LAYER" />
    <node id="CONSTITUENCY PARSE" />
    <node id="ARGUMENT" />
    <node id="PREDICATE" />
    <node id="SELECTIONAL PREFERENCE" />
    <node id="PSEUDOWORD" />
    <node id="MAGNITUDE ESTIMATION" />
    <node id="SELECTIONAL ASSOCIATION" />
    <node id="SELECTIONAL PREFERENCE STRENGTH" />
    <node id="CONDITIONAL PROBABILITY MODEL" />
    <node id="KULLBACK-LEIBLER DIVERGENCE" />
    <node id="PRIMITIVE DECOMPOSITION" />
    <node id="CONCEPTUAL DEPENDENCY" />
    <node id="FINITE LISTS OF THEMATIC ROLES" />
    <node id="CASE FRAMES" />
    <node id="IMPLICIT ARGUMENT DETECTION" />
    <node id="CONNOTATION FRAMES" />
    <node id="AUGMENTED TRANSITION NETWORK (ATN)" />
    <node id="NOMBANK" />
    <node id="FRAME SEMANTICS" />
    <node id="SELECTIONAL PREFERENCE MODELS" />
    <node id="SUBJECTIVITY" />
    <node id="SCHERER TYPOLOGY" />
    <node id="EMOTION" />
    <node id="MOOD" />
    <node id="INTERPERSONAL STANCE" />
    <node id="ATTITUDE" />
    <node id="PERSONALITY TRAITS" />
    <node id="APPRAISAL THEORY" />
    <node id="TUTORIAL SYSTEM" />
    <node id="HELP LINE" />
    <node id="BLOG POSTS" />
    <node id="TWEETS" />
    <node id="NOVELS" />
    <node id="AFFECTIVE LEXICONS" />
    <node id="VALENCE-AROUSAL-DOMINANCE MODEL" />
    <node id="NAIVE BAYES CLASSIFICATION" />
    <node id="GENERAL INQUIRER" />
    <node id="MPQA SUBJECTIVITY LEXICON" />
    <node id="POLARITY LEXICON" />
    <node id="HUMAN LABELING" />
    <node id="SEMI-SUPERVISED" />
    <node id="SUPERVISED" />
    <node id="BASIC EMOTIONS" />
    <node id="PLUTCHIK WHEEL OF EMOTION" />
    <node id="EKMAN'S SIX EMOTIONS" />
    <node id="RUSSELL'S MODEL" />
    <node id="APPRAISAL VARIABLES" />
    <node id="LITERACY TUTORS" />
    <node id="COMPUTER GAMES" />
    <node id="NRC VAD LEXICON" />
    <node id="NRC WORD-EMOTION ASSOCIATION LEXICON" />
    <node id="BEST-WORST SCALING" />
    <node id="AFFECTIVE DIMENSIONS" />
    <node id="SPLIT-HALF RELIABILITY" />
    <node id="NRC EMOTION/AFFECT INTENSITY LEXICON" />
    <node id="CROWDSOURCING" />
    <node id="EMOTION LEXICONS" />
    <node id="LIWC" />
    <node id="SEMI-SUPERVISED INDUCTION" />
    <node id="SEMANTIC AXIS METHODS" />
    <node id="SEED WORDS" />
    <node id="AXIS-BASED METHODS" />
    <node id="GRAPH-BASED METHODS" />
    <node id="TURNING AND LITTMAN ALGORITHM" />
    <node id="AFFECT DICTIONARY" />
    <node id="SENTPROP ALGORITHM" />
    <node id="SYNSET" />
    <node id="SEMANTIC AXIS" />
    <node id="RANDOM WALK" />
    <node id="SENTIWORDNET" />
    <node id="THESAURUS" />
    <node id="ONLINE REVIEWS" />
    <node id="SEMI-SUPERVISED METHODS" />
    <node id="REVIEW SCORE" />
    <node id="POTTS SCORE" />
    <node id="WORD SENTIMENT" />
    <node id="POTTS DIAGRAM" />
    <node id="IMDB" />
    <node id="YELP" />
    <node id="GOODREADS" />
    <node id="AMAZON" />
    <node id="COORDINATION" />
    <node id="SEED SETS" />
    <node id="THESAURUS STRUCTURE" />
    <node id="EMBEDDING COSINE" />
    <node id="POTTS DIAGRAMS" />
    <node id="SCALAR ADJECTIVES" />
    <node id="EMPHATIC ADVERBS" />
    <node id="ATTENUATING ADVERBS" />
    <node id="SENTIMENT COMPOSITIONALITY" />
    <node id="LOG ODDS RATIO INFORMATIVE DIRICHLET PRIOR" />
    <node id="WORD POLARITY" />
    <node id="LOG LIKELIHOOD RATIO" />
    <node id="BACKGROUND CORPUS" />
    <node id="SUPERVISED LEARNING OF WORD SENTIMENT" />
    <node id="LIKELIHOOD P(W|C)" />
    <node id="POSTERIOR P(C|W)" />
    <node id="FREQUENCY DIFFERENCE" />
    <node id="RATIO OF FREQUENCIES" />
    <node id="DIRICHLET INTUITION" />
    <node id="LOG ODDS RATIO" />
    <node id="MONROE ET AL. METHOD" />
    <node id="SUPERVISED CLASSIFICATION" />
    <node id="NAIVE BAYES ALGORITHM" />
    <node id="AFFECT RECOGNITION" />
    <node id="ENTITY-CENTRIC AFFECT" />
    <node id="FIELD AND TSVETKOV METHOD" />
    <node id="YELP DATASET" />
    <node id="SCHWARTZ ET AL. STUDY" />
    <node id="PMI (POINTWISE MUTUAL INFORMATION)" />
    <node id="AFFECT LEXICONS" />
    <node id="ENTITY-CENTRIC METHOD" />
    <node id="REGRESSION MODELS" />
    <node id="VALENCE/AROUSAL/DOMINANCE" />
    <node id="AGENCY" />
    <node id="POWER" />
    <node id="CORE REFERENCE RESOLUTION" />
    <node id="GOLD COREFERENCE" />
    <node id="FRAME SEMANTIC LEXICONS" />
    <node id="THE DARK KNIGHT" />
    <node id="PLOT SUMMARY" />
    <node id="CHARACTER ARCHETYPES" />
    <node id="ASP" />
    <node id="BECHDEL TEST" />
    <node id="MOVIES" />
    <node id="AMT CROWDSOURCING" />
    <node id="AFFECTIVE STATES" />
    <node id="RULE-BASED CLASSIFIER" />
    <node id="SUPERVISED TEXT CLASSIFICATION" />
    <node id="GRAPH BASED ALGORITHMS" />
    <node id="MENTIONS" />
    <node id="INTER-ANNOTATOR AGREEMENT" />
    <node id="KRIPPENDORFF'S ALPHA" />
    <node id="DIMENSIONS" />
    <node id="ANTONYMS" />
    <node id="DENSIFIER ALGORITHM" />
    <node id="REFERENT" />
    <node id="DISCOURSE ENTITY" />
    <node id="DISCOURSE MODEL" />
    <node id="WINOGRAD SCHEMA" />
    <node id="EVENT COREFERENCE" />
    <node id="COREFERENCE CHAIN" />
    <node id="DISCOURSE DEIXIS" />
    <node id="INDEFINITE NOUN PHRASES" />
    <node id="DEFINITE NOUN PHRASES" />
    <node id="ANAPHORA" />
    <node id="ANTECEDENT" />
    <node id="PRONOUNS" />
    <node id="REAL-WORLD ENTITY" />
    <node id="HEARER'S SET OF BELIEFS" />
    <node id="DEFINITE NPS" />
    <node id="ZERO ANAPHORA" />
    <node id="NAMES" />
    <node id="INFORMATION STATUS" />
    <node id="BRIDGING INFERENCE" />
    <node id="NON-REFERRING EXPRESSIONS" />
    <node id="NEW YORK TIMES" />
    <node id="CATAPHORA" />
    <node id="QUANTIFIED CONTEXTS" />
    <node id="CLITICS" />
    <node id="DEMONSTRATIVE PRONOUNS" />
    <node id="EMMA" />
    <node id="DOROTHY" />
    <node id="EVERY DANCER" />
    <node id="ANCORA" />
    <node id="SPANISH" />
    <node id="THOREAU'S WALDEN" />
    <node id="CHINESE" />
    <node id="JAPANESE" />
    <node id="ITALIAN" />
    <node id="JOHN" />
    <node id="DISCOURSE-NEW" />
    <node id="DISCOURSE-OLD" />
    <node id="GIVEN-NEW DIMENSION" />
    <node id="VICTORIA CHEN" />
    <node id="ACCESSIBLE" />
    <node id="APPOSITIVES" />
    <node id="PREDICATIVE NPS" />
    <node id="EXPLETIVES" />
    <node id="UNITED" />
    <node id="SHANGHAI" />
    <node id="EMERALD CITY" />
    <node id="HER LEFT ARM" />
    <node id="GIOVANNI" />
    <node id="MEGABUCKS BANKING" />
    <node id="UAL" />
    <node id="CHINA'S BIGGEST CITY" />
    <node id="GENERICS" />
    <node id="PLEONASTIC IT" />
    <node id="NUMBER AGREEMENT" />
    <node id="PERSON AGREEMENT" />
    <node id="SINGULAR THEY" />
    <node id="GENDER OR NOUN CLASS AGREEMENT" />
    <node id="BINDING THEORY CONSTRAINTS" />
    <node id="RECENCY" />
    <node id="GRAMMATICAL ROLE" />
    <node id="VERB SEMANTICS" />
    <node id="ONTOLOGICAL DATASETS" />
    <node id="PRONOMINAL ANAPHORA" />
    <node id="GOLD MENTION-DETECTION" />
    <node id="SINGLETONS" />
    <node id="MUC, B3, AND CEAF E" />
    <node id="CONLL F1 SCORE" />
    <node id="MENTION DETECTION" />
    <node id="ARRAU" />
    <node id="ANCORA-CO" />
    <node id="LITBANK" />
    <node id="BRIDGING REFERENCES" />
    <node id="ANAPHORICITY CLASSIFIER" />
    <node id="REFERENTIALITY CLASSIFIER" />
    <node id="PLEONASTIC PRONOUNS" />
    <node id="ANAPHORICITY DETECTOR" />
    <node id="DISCOURSE-NEW CLASSIFIER" />
    <node id="END-TO-END MODEL" />
    <node id="ISNOTES" />
    <node id="ANAPHORIC CONTEXTS" />
    <node id="N-GRAM CONTEXTS" />
    <node id="MENTION-PAIR ARCHITECTURE" />
    <node id="MENTION-RANK ARCHITECTURE" />
    <node id="ENTITY-BASED MODEL" />
    <node id="SUPERVISED NEURAL MACHINE LEARNING" />
    <node id="COREFERENCE ALGORITHMS" />
    <node id="HAND-BUILT FEATURES" />
    <node id="CLOSEST-FIRST CLUSTERING" />
    <node id="BEST-FIRST CLUSTERING" />
    <node id="NEURAL REPRESENTATION LEARNING" />
    <node id="TRANSITIVE CLOSURE" />
    <node id="RANKING MODELS" />
    <node id="LATENT ANTECEDENTS" />
    <node id="SUPERVISED ANAPHORICITY CLASSIFIER" />
    <node id="ANAPHORICITY DETECTION" />
    <node id="MENTION-PAIR CLASSIFIER" />
    <node id="CONTEXTUAL WORD EMBEDDINGS" />
    <node id="MENTION-RANKING MODELS" />
    <node id="FEATURES OF ANAPHOR OR ANTECEDENT MENTION" />
    <node id="FEATURES OF ANTECEDENT ENTITY" />
    <node id="FEATURES OF PAIR OF MENTIONS" />
    <node id="FEATURES OF PAIR OF ENTITIES" />
    <node id="RANDOM FOREST" />
    <node id="NEURAL MENTION-RANKING ALGORITHM" />
    <node id="SPAN REPRESENTATION" />
    <node id="COREFERENCE LINK" />
    <node id="E2E-COREF" />
    <node id="MENTION SCORE" />
    <node id="ANTECEDENT SCORE" />
    <node id="KNOWLEDGE BASE" />
    <node id="WIKIFICATION" />
    <node id="ANCHOR DICTIONARY" />
    <node id="TAGME" />
    <node id="MENTION DISAMBIGUATION" />
    <node id="RELATEDNESS/COHERENCE" />
    <node id="RELATEDNESS SCORE" />
    <node id="VECTOR REPRESENTATION" />
    <node id="SPAN" />
    <node id="ELEMENT-WISE MULTIPLICATION" />
    <node id="ATTENTION WEIGHTS" />
    <node id="ANCHOR TEXT" />
    <node id="IN-LINK" />
    <node id="MUC METRIC" />
    <node id="B3 METRIC" />
    <node id="CEAF METRIC" />
    <node id="LEA METRIC" />
    <node id="TAGME ALGORITHM" />
    <node id="NEURAL GRAPH-BASED LINKING" />
    <node id="ELQ LINKING ALGORITHM" />
    <node id="WEBQUESTIONS SP" />
    <node id="GRAPHQUESTIONS" />
    <node id="CANDIDATE ANNOTATION" />
    <node id="RELATEDNESS" />
    <node id="COHERENCE" />
    <node id="LINK PROBABILITY" />
    <node id="MENTION SPAN" />
    <node id="HYPOTHESIS CHAIN" />
    <node id="REFERENCE CHAIN" />
    <node id="WINOGRAD SCHEMA CHALLENGE" />
    <node id="COREERENCE RESOLUTION" />
    <node id="KNOWREF" />
    <node id="WORLD KNOWLEDGE" />
    <node id="COMMON-SENSE REASONING" />
    <node id="ONTOLOGICAL ENTITY LINKING" />
    <node id="WINOBIAS" />
    <node id="GENDER BIAS IN COREFERENCE" />
    <node id="GENDERED AMBIGUOUS PRONOUNS (GAP)" />
    <node id="GLOVE EMBEDDINGS" />
    <node id="HOBBS ALGORITHM" />
    <node id="CENTERING" />
    <node id="MUC CONFERENCES" />
    <node id="ACE EVALUATIONS" />
    <node id="MENTION-RANKING" />
    <node id="METONYMY" />
    <node id="RULE-BASED SYSTEMS" />
    <node id="PRONOMINAL ANAPHORA RESOLUTION" />
    <node id="SINGLETON DETECTION" />
    <node id="ENTITY-CENTRIC FOUNDATION" />
    <node id="NEURAL ARCHITECTURES" />
    <node id="DISCOURSE" />
    <node id="LOCAL COHERENCE" />
    <node id="GLOBAL COHERENCE" />
    <node id="ENTITY-BASED COHERENCE" />
    <node id="CENTERING THEORY" />
    <node id="CENTERING THEORY (GROSZ ET AL., 1995)" />
    <node id="TOPICALLY COHERENT" />
    <node id="LEXICAL COHESION" />
    <node id="COHERENCE RELATIONS" />
    <node id="RHETORICAL STRUCTURE THEORY (RST)" />
    <node id="RHETORICAL STRUCTURE THEORY (MANN AND THOMPSON, 1987)" />
    <node id="REASON" />
    <node id="ELABORATION" />
    <node id="EVIDENCE" />
    <node id="ATTRIBUTION" />
    <node id="LIST" />
    <node id="ENTITY GRID" />
    <node id="ENTITY GRID MODEL (BARZILAY AND LAPATA, 2008)" />
    <node id="NUCLEUS" />
    <node id="SATELLITE" />
    <node id="CITIZEN KANE" />
    <node id="CHARLES FOSTER KANE" />
    <node id="FLASHBACKS" />
    <node id="ANDY" />
    <node id="COREFERENCE CHAPTER" />
    <node id="HOBBS (1979)" />
    <node id="INCOHERENT DISCOURSE" />
    <node id="JANE" />
    <node id="COHERENT DISCOURSE" />
    <node id="JENNY" />
    <node id="RST TREEBANK MANUAL (CARLSON AND MARCU, 2001)" />
    <node id="DAVID HUME" />
    <node id="RST RELATIONS" />
    <node id="EDU (ELEMENTARY DISCOURSE UNIT)" />
    <node id="RST DISCOURSE TREEBANK" />
    <node id="DISCOURSE PARSING" />
    <node id="CARLSON ET AL. (2001)" />
    <node id="BRAUD ET AL. (2017)" />
    <node id="PENN DISCOURSE TREEBANK (PDTB)" />
    <node id="DISCOURSE CONNECTIVES" />
    <node id="MILTSKAKI ET AL. (2004)" />
    <node id="PRASAD ET AL. (2008, 2014)" />
    <node id="EDU SEGMENTATION" />
    <node id="XUE ET AL. (2016)" />
    <node id="LUKASIK ET AL. (2020)" />
    <node id="SCIENTIFIC AMERICAN" />
    <node id="MARCU (2000A)" />
    <node id="ZHOU AND XUE (2015)" />
    <node id="CHINESE DISCOURSE TREEBANK" />
    <node id="NEURAL SEQUENCE MODELS" />
    <node id="AMERICAN TELEPHONE &amp; TELEGRAPH CO." />
    <node id="CARLSON ET AL. (2003)" />
    <node id="HIERARCHICAL BI-LSTMS" />
    <node id="RST PARSING" />
    <node id="NEURAL SYNTACTIC PARSERS" />
    <node id="IMPLICIT SYNTAX FEATURES" />
    <node id="ATTR" />
    <node id="ELAB" />
    <node id="BRAUD ET AL. (2016)" />
    <node id="YU ET AL. (2018)" />
    <node id="TRANSITION-BASED NEURAL MODEL" />
    <node id="DYNAMIC ORACLE" />
    <node id="BI-AFFINE DEPENDENCY PARSER" />
    <node id="ZHANG ET AL. (2017)" />
    <node id="EDU REPRESENTATION" />
    <node id="BI-LSTM" />
    <node id="SHIFT-REDUCE PARSER" />
    <node id="RST DISCOURSE PARSING" />
    <node id="PDTB DISCOURSE PARSING" />
    <node id="RST-PAREVAL METRICS" />
    <node id="BERT EMBEDDINGS" />
    <node id="ENTITY GRID MODEL" />
    <node id="BACKWARD-LOOKING CENTER" />
    <node id="FORWARD-LOOKING CENTERS" />
    <node id="PREFERRED CENTER" />
    <node id="CENTERING TRANSITIONS" />
    <node id="BARZILAY AND LAPATA (2008)" />
    <node id="BRENNAN ET AL. (1987)" />
    <node id="UTTERANCE" />
    <node id="PRONOMINALIZATION" />
    <node id="JUSTICE DEPARTMENT" />
    <node id="ANTI-TRUST TRIAL" />
    <node id="MICROSOFT CORP." />
    <node id="COMPETITORS" />
    <node id="MARKETS" />
    <node id="THE CASE" />
    <node id="NETSCAPE" />
    <node id="TACTICS" />
    <node id="INCREASED EARNINGS" />
    <node id="TRIAL" />
    <node id="ESTABLISHED BRANDS" />
    <node id="THE GOVERNMENT" />
    <node id="CIVIL SUIT" />
    <node id="CONSPIRACY" />
    <node id="COMPETITION" />
    <node id="COLLUSION" />
    <node id="SHERMAN ACT" />
    <node id="LOCAL ENTITY TRANSITION" />
    <node id="MACHINE LEARNING" />
    <node id="COHERENCE MODELS" />
    <node id="HUMAN-LABELED COHERENCE SCORES" />
    <node id="NEURAL COHERENCE MODEL" />
    <node id="LOCAL COHERENCE DISCRIMINATOR (LCD)" />
    <node id="SENTENCE ORDER DISCRIMINATION" />
    <node id="SENTENCE INSERTION" />
    <node id="SENTENCE ORDER RECONSTRUCTION" />
    <node id="COHERENCE ALGORITHM" />
    <node id="PERMUTATION" />
    <node id="LEXICAL CHAINS" />
    <node id="TEXTTILING" />
    <node id="LSA COHERENCE" />
    <node id="MARGIN LOSS" />
    <node id="SENTENCE ENCODER" />
    <node id="COHERENCE SCORE" />
    <node id="HUMAN RATINGS" />
    <node id="ESSAY GRADING" />
    <node id="TOPICAL COHERENCE" />
    <node id="SEMANTIC FIELD COHERENCE" />
    <node id="GENERATIVE COHERENCE MODEL" />
    <node id="DISCRIMINATIVE TRAINING" />
    <node id="DISCRIMINATION TASK" />
    <node id="PARAGRAPH RECONSTRUCTION TASK" />
    <node id="RNN LANGUAGE MODEL" />
    <node id="ARGUMENTATION STRUCTURE" />
    <node id="ARGUMENTATION MINING" />
    <node id="DISCOURSE CONNECTORS" />
    <node id="CLAIMS" />
    <node id="PREMISES" />
    <node id="SUPPORT" />
    <node id="ATTACK" />
    <node id="PERSUASIVE ESSAYS" />
    <node id="LCD MODEL" />
    <node id="PROPP'S MODEL" />
    <node id="DRAMATIS PERSONAE" />
    <node id="FUNCTIONS" />
    <node id="ARGUMENTATION SCHEMES" />
    <node id="PERSUASION" />
    <node id="SCIENTIFIC DISCOURSE" />
    <node id="ARGUMENTATIVE ZONING" />
    <node id="RHETORICAL RELATIONS" />
    <node id="SEGMENTED DISCOURSE REPRESENTATION THEORY (SDRT)" />
    <node id="LINGUISTIC DISCOURSE MODEL" />
    <node id="NEURAL RST MODELS" />
    <node id="SELF-SUPERVISION FOR COHERENCE" />
    <node id="HMM MODEL FOR TOPICS" />
    <node id="EXPLICIT AND IMPLICIT DISCOURSE CONNECTIVES" />
    <node id="GRID MODEL" />
    <node id="FUNCTIONAL LINGUISTICS" />
    <node id="PSYCHOLOGY OF DISCOURSE PROCESSING" />
    <node id="FOCUS OF ATTENTION" />
    <node id="DISCOURSE FOCI" />
    <node id="CONVOLUTIONAL MODEL" />
    <node id="VERB PHRASE ELLIPSIS" />
    <node id="GAPPING" />
    <node id="TENSE INTERPRETATION" />
    <node id="DISCOURSE PROCESSING" />
    <node id="DISCOURSE STRUCTURE" />
    <node id="DISCOURSE-LEVEL LINGUISTIC PHENOMENA" />
    <node id="GLOBAL FOCUS" />
    <node id="IMMEDIATE FOCUS" />
    <node id="HOW TO DO THINGS WITH WORDS" />
    <node id="SPEECH ACT THEORY" />
    <node id="CHARACTERIZING AND PREDICTING VOICE QUERY REFORMULATION" />
    <node id="VOICE QUERY REFORMULATION" />
    <node id="SENTIWORDNET 3.0" />
    <node id="ALGORITHMS FOR SCORING COREFERENCE CHAINS" />
    <node id="NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE" />
    <node id="NEURAL MACHINE TRANSLATION" />
    <node id="END-TO-END ATTENTION-BASED LARGE VOCABULARY SPEECH RECOGNITION" />
    <node id="LARGE-VOCABULARY SPEECH RECOGNITION" />
    <node id="MACHINE READING COMPREHENSION" />
    <node id="ANNOTATION FOR AND ROBUST PARSING OF DISCOURSE STRUCTURE" />
    <node id="OPEN INFORMATION EXTRACTION FOR THE WEB" />
    <node id="PARACRAWL" />
    <node id="THE PRESENT STATUS OF AUTOMATIC TRANSLATION OF LANGUAGES" />
    <node id="AUTOMATIC TRANSLATION" />
    <node id="A LATENT SEMANTIC ANALYSIS FRAMEWORK FOR LARGE-SPAN LANGUAGE MODELING" />
    <node id="LATENT SEMANTIC INFORMATION" />
    <node id="STATISTICAL LANGUAGE MODELING" />
    <node id="COMPUTATIONAL FIELDS" />
    <node id="NATURAL LANGUAGE TECHNOLOGY" />
    <node id="MOBILE DEVICES" />
    <node id="NEURAL PROBABILISTIC LANGUAGE MODEL" />
    <node id="SEMANTIC PARSING" />
    <node id="MAXIMUM ENTROPY APPROACH" />
    <node id="PATTERN RECOGNITION" />
    <node id="DEBIASING WORD EMBEDDINGS" />
    <node id="CONNECTIONIST SPEECH RECOGNITION" />
    <node id="HYBRID APPROACH" />
    <node id="AMERICAN ENGLISH SPEECH" />
    <node id="TNTPOS TAGGER" />
    <node id="CROSS-LINGUAL RST DISCOURSE PARSING" />
    <node id="DISCOURSE-TAGGED CORPUS" />
    <node id="CENTERING APPROACH" />
    <node id="DISCOURSE TAGGING" />
    <node id="PATTERN EXTRACTION" />
    <node id="SEMANTIC REPRESENTATIONS" />
    <node id="SELECTIONAL PREFERENCE ACQUISITION" />
    <node id="WORDNET-BASED MEASURES" />
    <node id="STATISTICAL MACHINE TRANSLATION" />
    <node id="TRAINING DATA EXTRACTION" />
    <node id="CONCRETENESS RATINGS" />
    <node id="MULTILINGUAL DEPENDENCY PARSING" />
    <node id="SEMANTIC BIASES" />
    <node id="WEB PATTERN EXTRACTION" />
    <node id="ERROR-SENSITIVE RESPONSE GENERATION" />
    <node id="AI IN CAI" />
    <node id="COMPUTER-ASSISTED INSTRUCTION" />
    <node id="DOMAIN-SPECIFIC KNOWLEDGE ACQUISITION" />
    <node id="NOUN PHRASE COREFERENCE" />
    <node id="ANALYTICAL LANGUAGE" />
    <node id="PART-OF-SPEECH TAGGER" />
    <node id="PROBABILISTIC REPRESENTATION" />
    <node id="PARAMETER ESTIMATION" />
    <node id="MACHINE TRANSLATION METRICS" />
    <node id="MULTILINGUAL PARSING" />
    <node id="LEXICAL SEMANTIC RELATEDNESS" />
    <node id="FEW-SHOT LEARNERS" />
    <node id="CONCRETENESS" />
    <node id="WORD CO-OCCURRENCE" />
    <node id="MANDARIN SPEECH CORPUS" />
    <node id="SPOKEN LANGUAGE DIALOGUE" />
    <node id="HUMAN-LIKE BIASES" />
    <node id="SENTENCE ANALYSIS" />
    <node id="REFERENCE" />
    <node id="DISCOURSE TAGGING MANUAL" />
    <node id="CONLL-2005 SHARED TASK" />
    <node id="ILLINOIS-COREF" />
    <node id="NAVYTIME" />
    <node id="MULTI-PASS ARCHITECTURE" />
    <node id="EVENT AND TIME ORDERING" />
    <node id="PSEUDO-WORDS" />
    <node id="TEMPLATE-BASED INFORMATION EXTRACTION" />
    <node id="END-TO-END CONTINUOUS SPEECH RECOGNITION" />
    <node id="MÉTÉO" />
    <node id="SUTIME" />
    <node id="LINGUISTICALLY AWARE COREFERENCE EVALUATION METRICS" />
    <node id="KNOWLEDGE-BASED WORD SENSE DISAMBIGUATION" />
    <node id="UNSUPERVISED POS INDUCTION" />
    <node id="STATISTICAL PARSING" />
    <node id="MULTILINGUAL DEPENDENCY-BASED SYNTACTIC AND SEMANTIC PARSING" />
    <node id="SYNTACTIC AND SEMANTIC PARSING" />
    <node id="READING WIKIPEDIA TO ANSWER OPEN-DOMAIN QUESTIONS" />
    <node id="FAST AND ACCURATE DEPENDENCY PARSER" />
    <node id="DEPENDENCY PARSER" />
    <node id="INCREMENTAL TEXT STRUCTURING" />
    <node id="SMOOTHING TECHNIQUES FOR LANGUAGE MODELING" />
    <node id="ADVERSARIAL MULTI-CRITERIA LEARNING" />
    <node id="LONG SHORT-TERM MEMORY-NETWORKS" />
    <node id="MACHINE READING" />
    <node id="MARKED PERSONAS" />
    <node id="DEEP REINFORCEMENT LEARNING FROM HUMAN PREFERENCES" />
    <node id="HIERARCHICAL PHRASE-BASED MODEL" />
    <node id="RNN ENCODER-DECODER" />
    <node id="MESSAGE UNDERSTANDING SYSTEMS" />
    <node id="DISCOURSE ACT RECOGNITION" />
    <node id="SYSTEMT" />
    <node id="RULE-BASED INFORMATION EXTRACTION" />
    <node id="TRANSITION-BASED SEMANTIC ROLE LABELING" />
    <node id="THREE MODELS FOR THE DESCRIPTION OF LANGUAGE" />
    <node id="LOGICAL STRUCTURE OF LINGUISTIC THEORY" />
    <node id="LECTURES ON GOVERNMENT AND BINDING" />
    <node id="SYNTACTIC STRUCTURES" />
    <node id="FORMAL PROPERTIES OF GRAMMARS" />
    <node id="ENHANCED GOOD-TURING AND DELETED ESTIMATION METHODS" />
    <node id="STOCHASTIC PARTS PROGRAM" />
    <node id="NOUN PHRASE PARSER" />
    <node id="WORD ASSOCIATION NORMS" />
    <node id="LEXICOGRAPHY" />
    <node id="INFLUENCE: THE PSYCHOLOGY OF PERSUASION" />
    <node id="USING LANGUAGE" />
    <node id="FISHER CORPUS" />
    <node id="SPEECH-TO-TEXT" />
    <node id="LANGUAGE ACQUISITION" />
    <node id="GIVENNESS" />
    <node id="CONTRASTIVENESS" />
    <node id="DEFINITENESS" />
    <node id="SUBJECTS" />
    <node id="TOPICS" />
    <node id="POINT OF VIEW" />
    <node id="SEMANTICS" />
    <node id="PRAGMATICS" />
    <node id="NAMED ENTITY DISAMBIGUATION" />
    <node id="CONTEXTUAL WORD SIMILARITY" />
    <node id="TRANSFORMER MODELS" />
    <node id="DIALOG APPLICATIONS" />
    <node id="NEURAL NETWORK ARCHITECTURE" />
    <node id="SEMANTIC PREDICTORS" />
    <node id="POS-TAGGERS" />
    <node id="LVCSR" />
    <node id="SEMI-SUPERVISED SEQUENCE LEARNING" />
    <node id="AUTOMATIC RECOGNITION OF SPOKEN DIGITS" />
    <node id="UNINTENDED BIAS IN TEXT CLASSIFICATION" />
    <node id="DEEP BIAFFINE ATTENTION" />
    <node id="REPLICABILITY ANALYSIS" />
    <node id="CONTEXT-DEPENDENT PRE-TRAINED DEEP NEURAL NETWORKS" />
    <node id="LEGAL HALLUCINATIONS" />
    <node id="DIALOGUE STRATEGIES" />
    <node id="SENTIMENT PARSING" />
    <node id="HATE SPEECH DETECTION" />
    <node id="CONTENT MODERATION" />
    <node id="WIKIPEDIA CORPUS" />
    <node id="CORPUS OF CONTEMPORARY AMERICAN ENGLISH" />
    <node id="GRAMMATICAL CATEGORY DISAMBIGUATION" />
    <node id="IMPLICIT SEMANTIC ROLE LABELING" />
    <node id="HMM WORD AND PHRASE ALIGNMENT" />
    <node id="MACHINE TRANSLATION DIVERGENCES" />
    <node id="COHERENCE IN SCHIZOPHRENIA" />
    <node id="GENDER BIAS IN DIALOGUE GENERATION" />
    <node id="SYNTHESIS LECTURES ON HUMAN LANGUAGE TECHNOLOGIES" />
    <node id="NEURAL SYNTACTIC LANGUAGE MODEL" />
    <node id="NLP LEADERBOARDS" />
    <node id="UNSUPERVISED NAMED-ENTITY EXTRACTION" />
    <node id="DISCOURSE PARSER" />
    <node id="ENTITY-CENTRIC CONTEXTUAL AFFECTIVE ANALYSIS" />
    <node id="WORLD ATLAS OF LANGUAGE STRUCTURES ONLINE" />
    <node id="MAX PLANCK INSTITUTE FOR EVOLUTIONARY ANTHROPOLOGY" />
    <node id="SANTA BARBARA CORPUS OF SPOKEN AMERICAN ENGLISH" />
    <node id="LINGUISTIC DATA CONSORTIUM" />
    <node id="LATENT STRUCTURE PERCEPTRON" />
    <node id="CONTEXT-FREE PARSING ALGORITHM" />
    <node id="J. EARLEY" />
    <node id="KESTREL TTS" />
    <node id="NATURAL LANGUAGE ENGINEERING" />
    <node id="OPTIMUM BRANCHINGS" />
    <node id="GRAPH THEORY" />
    <node id="BACK-TRANSLATION" />
    <node id="STATISTICS" />
    <node id="HERDAN’S LAW" />
    <node id="WORD FREQUENCIES" />
    <node id="HEAPS’ LAW" />
    <node id="P. EKMAN" />
    <node id="TRANSFORMER CIRCUITS" />
    <node id="SCHIZOPHRENIA" />
    <node id="MENTAL DISORDER" />
    <node id="CONTEXTUALIZED WORD REPRESENTATIONS" />
    <node id="WORD EMBEDDING ASSOCIATIONS" />
    <node id="WORD CLASSES" />
    <node id="MULTILINGUAL MACHINE TRANSLATION" />
    <node id="TRANSMISSION OF INFORMATION" />
    <node id="COMMUNICATION" />
    <node id="GLOTTAL FLOW" />
    <node id="PHONETICS" />
    <node id="EMPATH" />
    <node id="TEXT ANALYSIS" />
    <node id="CONCEPTUAL BLENDING" />
    <node id="COGNITIVE THEORY" />
    <node id="COGNITIVE SCIENCE" />
    <node id="LEXICAL DATABASE" />
    <node id="WIKIPEDIA ANNOTATION" />
    <node id="TEXT ANNOTATION" />
    <node id="WATSON" />
    <node id="BOTS" />
    <node id="AUTOMATION" />
    <node id="STRIPS" />
    <node id="ENGLISH PREPOSITIONS" />
    <node id="CASE" />
    <node id="IMPLICIT ARGUMENTS" />
    <node id="VALENCY" />
    <node id="SEARCH IN CONTEXT" />
    <node id="TEXTUAL COHERENCE" />
    <node id="PROPP’S FUNCTIONS" />
    <node id="VOCABULARY PROBLEM" />
    <node id="PARTICIPATORY RESEARCH" />
    <node id="DATASHEETS FOR DATASETS" />
    <node id="HUMAN-SYSTEM COMMUNICATION" />
    <node id="MINIMUM SPANNING TREES" />
    <node id="ALGORITHMS" />
    <node id="GENDER AND ETHNIC STEREOTYPES" />
    <node id="CLAWS WORD-TAGGING SYSTEM" />
    <node id="CORPUS ANNOTATION" />
    <node id="NEURAL TOXIC DEGENERATION" />
    <node id="NOMINAL PREDICATES" />
    <node id="NEURAL COMPUTATION" />
    <node id="PROBLEM SOLVING" />
    <node id="THEOREM PROVING" />
    <node id="LINGUISTIC THEORY" />
    <node id="SEMANTIC ANALYSIS" />
    <node id="SPEECH ANALYSIS" />
    <node id="VOCAL CORDS AND VOCAL TRACT" />
    <node id="LSTM-BASED RECURRENT NEURAL NETWORKS" />
    <node id="CONVOLUTIONAL NEURAL NETWORKS" />
    <node id="DEPENDENCY-BASED SEMANTIC ROLE LABELING" />
    <node id="FREQUENCY ANALYSIS" />
    <node id="EMNLP" />
    <node id="DYNAMIC RECURRENT NEURAL NETWORKS" />
    <node id="CONTINUAL PREDICTION" />
    <node id="SEQUENCE TRANSDUCTION" />
    <node id="BIDIRECTIONAL LSTM" />
    <node id="SYNTAX" />
    <node id="GRAMMATICAL TAGGING" />
    <node id="STATISTICAL VERB LEXICON" />
    <node id="TELEPHONE SPEECH CORPUS" />
    <node id="ERROR CORRECTION" />
    <node id="END-TO-END SPEECH RECOGNITION" />
    <node id="PHONEME CLASSIFICATION" />
    <node id="SYMBOL GROUNDING" />
    <node id="UNSUPERVISED DISCOVERY" />
    <node id="DIALOGUE AGENTS" />
    <node id="TOPICAL-CHAT" />
    <node id="HUMAN JUDGEMENTS" />
    <node id="IMPLICIT COGNITION" />
    <node id="NEURAL NETWORK METHODS" />
    <node id="NEURAL TURING MACHINES" />
    <node id="BROADCAST NEWS CORPUS" />
    <node id="AUTOMATIC QUESTION ANSWERER" />
    <node id="CROSS-LINGUISTIC VARIATION" />
    <node id="UNIVERSAL GRAMMAR" />
    <node id="MORPHOLOGICAL RELATIONS" />
    <node id="SEMANTIC RELATIONS" />
    <node id="USER-DERIVED INTERFACE" />
    <node id="HIGH-DIMENSIONAL THEORIES" />
    <node id="EMBODIED THEORIES" />
    <node id="ON-LINE HANDWRITING RECOGNITION" />
    <node id="SEMANTICS OF DEFINITE AND INDEFINITE NOUN PHRASES" />
    <node id="DISCOURSE PLANS" />
    <node id="GRAPH-BASED LOCAL COHERENCE MODELING" />
    <node id="COHESION" />
    <node id="LEXICAL RELATIONS" />
    <node id="WORDNET RELATIONS" />
    <node id="DISTRIBUTIONAL STRUCTURE" />
    <node id="OCCAM'S RAZOR" />
    <node id="TRANSFORMER-BASED DEPENDENCY PARSING" />
    <node id="COGNITIVE STATUS" />
    <node id="DOMAIN ADAPTATION" />
    <node id="DOMAIN-SPECIFIC SENTIMENT LEXICONS" />
    <node id="FAIRNESS WITHOUT DEMOGRAPHICS" />
    <node id="VARIABLE AND FEATURE SELECTION" />
    <node id="ELEMENTS OF STATISTICAL LEARNING" />
    <node id="BAYESIAN APPROACH TO FILTERING JUNK E-MAIL" />
    <node id="POLYSEME SENSE SIMILARITY" />
    <node id="WORD EMOTION MODELING" />
    <node id="NAMED-ENTITY LINKING" />
    <node id="SYNTACTICALLY ANNOTATED CORPUS" />
    <node id="MORPHOLOGICAL TAGGING" />
    <node id="DESCRIPTION BASED PARSING" />
    <node id="STATISTICAL MORPHOLOGICAL DISAMBIGUATION" />
    <node id="DIACHRONIC WORD EMBEDDINGS" />
    <node id="SEQUENCE MODELING WITH CTC" />
    <node id="LARGE VOCABULARY CONTINUOUS SPEECH RECOGNITION" />
    <node id="SEMANTIC ORIENTATION OF ADJECTIVES" />
    <node id="BAYESIAN FILTERING" />
    <node id="NEURAL EMBEDDING" />
    <node id="NEURAL EMBEDDING SPACES" />
    <node id="CONNECTIONIST NETWORK" />
    <node id="NEURAL NETWORK STATISTICAL PARSER" />
    <node id="ENERGY AND CARBON FOOTPRINTS" />
    <node id="DATA-DRIVEN DIALOGUE SYSTEMS" />
    <node id="ETHICAL CHALLENGES" />
    <node id="CANONICAL VERBS" />
    <node id="LANGUAGE PROCESSING" />
    <node id="ARGUMENT MINING" />
    <node id="DEEP BELIEF NETS" />
    <node id="USER CORRECTIONS" />
    <node id="SPOKEN DIALOGUE SYSTEM" />
    <node id="READING COMPREHENSION SYSTEM" />
    <node id="NEURAL TEXT DEGENERATION" />
    <node id="INSTRUCTION INDUCTION" />
    <node id="AUTOMATA THEORY" />
    <node id="BRIDGING RESOLUTION" />
    <node id="DISCOURSE STRUCTURE RELATIONS" />
    <node id="CUSTOMER REVIEWS MINING" />
    <node id="BIDIRECTIONAL LSTM-CRF MODELS" />
    <node id="SEQUENCE TAGGING" />
    <node id="INFORMATION EXTRACTION PATTERNS" />
    <node id="CONCATENATIVE SPEECH SYNTHESIS" />
    <node id="SOCIAL BIASES IN NLP MODELS" />
    <node id="PRIVACY CONCERNS IN CHATBOT INTERACTIONS" />
    <node id="DEEP RECURRENT NEURAL NETWORKS" />
    <node id="PRIVACY CONCERNS" />
    <node id="CHATBOT INTERACTIONS" />
    <node id="CONTRASTIVE SENTENCE OBJECTIVES" />
    <node id="AUTOMATIC DETECTION OF INCOHERENT SPEECH" />
    <node id="NEURAL SEMANTIC PARSER" />
    <node id="USER FEEDBACK" />
    <node id="RETRIEVAL AUGMENTED LANGUAGE MODELS" />
    <node id="GENDER BIAS AMPLIFICATION" />
    <node id="DISTRIBUTION BY POSTERIOR REGULARIZATION" />
    <node id="BILLION-SCALE SIMILARITY SEARCH" />
    <node id="CONTEXTUAL SPELLING CORRECTION" />
    <node id="DIALECTAL VARIABILITY" />
    <node id="CO-OCCURRENCES OF ANTONYMOUS ADJECTIVES" />
    <node id="SEMANTIC RELATIONSHIPS" />
    <node id="RECURRENT CONTINUOUS TRANSLATION MODELS" />
    <node id="PROPERTY-SHARING CONSTRAINT" />
    <node id="THEORY OF TRUTH AND SEMANTIC REPRESENTATION" />
    <node id="FORMAL METHODS IN THE STUDY OF LANGUAGE" />
    <node id="SEMANTIC THEORY" />
    <node id="DENSE PASSAGE RETRIEVAL" />
    <node id="AUGMENTATIVE AND ALTERNATIVE COMMUNICATION DEVICES" />
    <node id="COHERENCE IN ELLIPSIS AND ANAPHORA RESOLUTION" />
    <node id="SCALING LAWS FOR NEURAL LANGUAGE MODELS" />
    <node id="NEAREST NEIGHBOR LANGUAGE MODELS" />
    <node id="GENERAL SYNTACTIC PROCESSOR" />
    <node id="POWERFUL PARSER" />
    <node id="CENTERING-BASED METRICS OF COHERENCE" />
    <node id="CENTERING FOR PRONOUN INTERPRETATION" />
    <node id="TRANSFORMER VS RNN IN SPEECH APPLICATIONS" />
    <node id="MULTILINGUAL CONSTITUENCY PARSING" />
    <node id="CONSTRAINT GRAMMAR" />
    <node id="UNSUPERVISED MULTILINGUAL SENTENCE BOUNDARY DETECTION" />
    <node id="DISCOURSE REFERENTS" />
    <node id="COHERENCE, REFERENCE, AND THE THEORY OF GRAMMAR" />
    <node id="CONTEXT-FREE LANGUAGES" />
    <node id="REPRESENTATION OF EVENTS IN NERVE NETS AND FINITE AUTOMATA" />
    <node id="TEXT-TRANSLATION ALIGNMENT" />
    <node id="PREDICATE-ARGUMENT FREQUENCIES" />
    <node id="TEMPORAL RELATIONS" />
    <node id="PROBABILISTIC COREFERENCE" />
    <node id="PROBABILISTIC RECONCILIATION OF COHERENCE-DRIVEN AND CENTERING-DRIVEN THEORIES" />
    <node id="MODEL OF TEXT COMPREHENSION AND PRODUCTION" />
    <node id="FREQUENCIES FOR UNSEEN BIGRAMS" />
    <node id="CORPUS OF REGIONAL AFRICAN AMERICAN LANGUAGE" />
    <node id="SEMANTIC VECTOR SPACE MODEL PARAMETERS" />
    <node id="CLASS-BASED CONSTRUCTION OF A VERB LEXICON" />
    <node id="SKIP-GRAM WITH NEGATIVE SAMPLING" />
    <node id="ADAM" />
    <node id="SENTIMENT OF OPINIONS" />
    <node id="GENDER AND RACE BIAS IN SENTIMENT ANALYSIS SYSTEMS" />
    <node id="DEPENDENCY PARSING USING BIDIRECTIONAL LSTM" />
    <node id="CONSTITUENCY PARSING WITH A SELF-ATTENTIVE ENCODER" />
    <node id="VOICE ONSET TIME, FRICTION, AND ASPIRATION" />
    <node id="ARPA SPEECH UNDERSTANDING PROJECT" />
    <node id="KLATTALK TEXT-TO-SPEECH CONVERSION SYSTEM" />
    <node id="DISTRIBUTIONAL SEMANTIC MODELS" />
    <node id="DISCOURSE RELATIONS" />
    <node id="GOOGLE BOOKS NGRAM CORPUS" />
    <node id="ACL" />
    <node id="TACL" />
    <node id="INFORMATION STATE" />
    <node id="DIALOGUE MANAGEMENT" />
    <node id="CONVERSATIONAL ANALYSIS" />
    <node id="DIALOGUE MOVE ENGINE TOOLKIT" />
    <node id="TALK INCAR SYSTEM" />
    <node id="TEMPORAL INTERPRETATION" />
    <node id="FUNCTIONALITY IN LANGUAGE" />
    <node id="PENN DISCOURSE TREEBANK" />
    <node id="COMMON SENSE ENTAILMENT" />
    <node id="HUMAN-MACHINE INTERACTION" />
    <node id="BACKPROPAGATION" />
    <node id="DEEP REINFORCEMENT LEARNING" />
    <node id="NON-NEGATIVE MATRIX FACTORIZATION" />
    <node id="NEURIPS" />
    <node id="HOLISTIC EVALUATION" />
    <node id="ISU DIALOGUE SYSTEM" />
    <node id="ENGLISH VERB CLASSES" />
    <node id="ARGUMENT REALIZATION" />
    <node id="DEPENDENCY-BASED EVALUATION" />
    <node id="WORD SEGMENTATION" />
    <node id="NAACL HLT" />
    <node id="CIRCUS SYSTEM" />
    <node id="MUC-3" />
    <node id="COMPOSITIONAL CHARACTER MODELS" />
    <node id="OPEN VOCABULARY WORD REPRESENTATION" />
    <node id="SEMANTIC SPACES" />
    <node id="VECTOR-SPACE REPRESENTATIONS" />
    <node id="LARGE PARALLEL CORPORA" />
    <node id="PLAN RECOGNITION" />
    <node id="NATURAL LANGUAGE PROCESSING TOOLKIT" />
    <node id="INFINI-GRAM" />
    <node id="BIDIRECTIONAL LSTM MODEL" />
    <node id="SPEECH CORPUS" />
    <node id="SPEECH RECOGNITION SYSTEM" />
    <node id="MANDARIN TELEPHONE SPEECH CORPUS" />
    <node id="ROBUSTLY OPTIMIZED BERT" />
    <node id="DISCOURSE ANALYSIS" />
    <node id="FLAN COLLECTION" />
    <node id="DATA COMMONS" />
    <node id="SCIENTIFIC CREDIBILITY" />
    <node id="AI DATA COMMONS" />
    <node id="STEMMING ALGORITHM" />
    <node id="HARPY SPEECH RECOGNITION SYSTEM" />
    <node id="LANGID.PY" />
    <node id="DECISION-TREE MODELS" />
    <node id="RHETORICAL PARSING" />
    <node id="SYNTACTIC RECOGNITION" />
    <node id="ANNOTATED CORPUS" />
    <node id="CORENLP" />
    <node id="SYNTACTIC PATTERNS" />
    <node id="SCIENTIFIC CREDIBILITY OF MACHINE TRANSLATION" />
    <node id="FAIRNESS IN DIALOGUE SYSTEMS" />
    <node id="COHERENCE MODELING" />
    <node id="PRETRAINER'S GUIDE" />
    <node id="PREFERENCE MEASUREMENT" />
    <node id="MECHANIZED ENCODING" />
    <node id="ENCODING" />
    <node id="TEXT PROCESSING" />
    <node id="STATISTICAL INVESTIGATION" />
    <node id="MACHINE TRANSLATION RESEARCH" />
    <node id="UNIVERSAL STANFORD DEPENDENCIES" />
    <node id="DECISION TREES" />
    <node id="RECURSIVE NEURAL NETWORKS" />
    <node id="TRACE MODEL" />
    <node id="MAPSSWE TEST" />
    <node id="INCREMENTAL NON-PROJECTIVE DEPENDENCY PARSING" />
    <node id="NON-PROJECTIVE DEPENDENCY PARSING" />
    <node id="PROJECTIVE DEPENDENCY PARSING" />
    <node id="PSEUDO-PROJECTIVE DEPENDENCY PARSING" />
    <node id="CONLL 2007 SHARED TASK" />
    <node id="MALTPARSER" />
    <node id="DISTANCE VECTORS" />
    <node id="THE DESIGN OF EVERYDAY THINGS" />
    <node id="BIBLIOGRAPHY" />
    <node id="DISCRIMINATIVE TRAINING AND MAXIMUM ENTROPY MODELS" />
    <node id="RULE SYNTHESIS OF SPEECH" />
    <node id="THE PROPOSITION BANK" />
    <node id="OPINION MINING AND SENTIMENT ANALYSIS" />
    <node id="THUMBS UP? SENTIMENT CLASSIFICATION" />
    <node id="GOOGLE HOME VS ALEXA" />
    <node id="DESIGNING VOICE USER INTERFACES" />
    <node id="VOICE USER INTERFACES" />
    <node id="MULTILINGUAL BERT HAS AN ACCENT" />
    <node id="REDUCING GENDER BIAS IN ABUSIVE LANGUAGE DETECTION" />
    <node id="IDENTIFYING APPROPRIATE SUPPORT FOR PROPOSITIONS" />
    <node id="BBQ: A HAND-BUILT BIAS BENCHMARK" />
    <node id="AUTOMATIC DIFFERENTIATION IN PYTORCH" />
    <node id="FROM ARGUMENT DIAGRAMS TO ARGUMENTATION MINING" />
    <node id="AN ANNOTATED CORPUS OF ARGUMENTATIVE MICROTEXTS" />
    <node id="LINGUISTIC INQUIRY AND WORD COUNT (LIWC) 2007" />
    <node id="DEEP CONTEXTUALIZED WORD REPRESENTATIONS" />
    <node id="HEAD-DRIVEN PHRASE STRUCTURE GRAMMAR" />
    <node id="INDIRECT SPEECH ACTS" />
    <node id="SEGMENTATION TECHNIQUES IN SPEECH SYNTHESIS" />
    <node id="STOCHASTIC REPRESENTATION OF CONCEPTUAL STRUCTURE" />
    <node id="LANGUAGE MODELS AS KNOWLEDGE BASES" />
    <node id="UNIVERSAL PART-OF-SPEECH TAGSET" />
    <node id="THE EMOTIONS: FACTS, THEORIES, AND A NEW MODEL" />
    <node id="PSYCHO-EVOLUTIONARY THEORY OF EMOTION" />
    <node id="ANAPHORA RESOLUTION" />
    <node id="BLEU SCORE" />
    <node id="SEMANTIC RELATEDNESS" />
    <node id="INSTRUCTION SEARCH" />
    <node id="TIMEBANK CORPUS" />
    <node id="GENDER BIAS IN MACHINE TRANSLATION" />
    <node id="GOOGLE TRANSLATE" />
    <node id="DARPA 1000-WORD RESOURCE MANAGEMENT DATABASE" />
    <node id="CONTINUOUS SPEECH RECOGNITION" />
    <node id="MORPHOLOGY OF THE FOLKTALE" />
    <node id="V. PROPP" />
    <node id="SPECIFICATION LANGUAGE TIMEML" />
    <node id="SQUAD" />
    <node id="MACHINE COMPREHENSION OF TEXT" />
    <node id="IN-CONTEXT RETRIEVAL-AUGMENTED LANGUAGE MODELS" />
    <node id="MACHINE TRANSLATION EVALUATION" />
    <node id="NEURAL COMPUTING AND APPLICATIONS" />
    <node id="ANLP/NAACL" />
    <node id="PENN DISCOURSE TREEBANK 2.0" />
    <node id="INTERSPEECH" />
    <node id="OPENAI" />
    <node id="AI RESEARCH" />
    <node id="NEURAL INFORMATION PROCESSING" />
    <node id="JMLR" />
    <node id="HARVARD UNIVERSITY PRESS" />
    <node id="ACADEMIC PUBLICATIONS" />
    <node id="LINGUA" />
    <node id="LINGUISTICS" />
    <node id="LREC" />
    <node id="LANGUAGE RESOURCES" />
    <node id="CAMBRIDGE UNIVERSITY PRESS" />
    <node id="MIT PRESS" />
    <node id="MACMILLAN" />
    <node id="EDUCATIONAL PUBLICATIONS" />
    <node id="AAAI" />
    <node id="EXTRACTION PATTERNS" />
    <node id="UNSUPERVISED MODELING" />
    <node id="TWITTER CONVERSATIONS" />
    <node id="MISSING DATA MODELING" />
    <node id="LANGUAGE MODEL PARAMETERS" />
    <node id="ADAPTIVE STATISTICAL LANGUAGE MODELING" />
    <node id="OKAPI" />
    <node id="SMART RETRIEVAL SYSTEM" />
    <node id="TEXT RETRIEVAL" />
    <node id="RECURRENT ERROR PROPAGATION NETWORK" />
    <node id="SEMANTIC SIMILARITY MODEL" />
    <node id="SEMANTICALLY ANNOTATED LEXICON" />
    <node id="LEXICAL CO-OCCURRENCE" />
    <node id="OPEN-DOMAIN CHATBOT" />
    <node id="SPOKEN DIALOGUE MANAGEMENT" />
    <node id="ERROR PROPAGATION" />
    <node id="TURN-TAKING SYSTEM" />
    <node id="SEMANTIC EVALUATION" />
    <node id="CIRCUMPLEX MODEL OF AFFECT" />
    <node id="AFFECTIVE MODELING" />
    <node id="DISTRIBUTIONALLY ROBUST NEURAL NETWORKS" />
    <node id="IMPLICIT DISCOURSE RELATIONS" />
    <node id="SYNTACTIC DEPENDENCIES" />
    <node id="DENSE PASSAGE RETRIEVER" />
    <node id="INTONATIONAL DISAMBIGUATION" />
    <node id="DECEPTION DETECTION" />
    <node id="PROBABILISTIC GRAMMARS" />
    <node id="GRAMMATICAL CODING SYSTEMS" />
    <node id="VARIABLE RULES" />
    <node id="RACIAL BIAS IN HATE SPEECH DETECTION" />
    <node id="AUGMENTED CONTEXT FREE GRAMMAR" />
    <node id="SCRIPTS, PLANS, AND KNOWLEDGE" />
    <node id="SEQUENCING IN CONVERSATIONAL OPENINGS" />
    <node id="PSYCHOLOGICAL MODELS OF EMOTION" />
    <node id="CONVERSATIONAL OPENINGS" />
    <node id="MACHINE TRANSLATION: ANALYZING GENDER" />
    <node id="SCIENTIFIC RESEARCH AND GENDER" />
    <node id="GENDER ANALYSIS" />
    <node id="WORD ANALOGY TESTING CAVEAT" />
    <node id="KNOWLEDGE-FREE INDUCTION OF MORPHOLOGY" />
    <node id="BIDIRECTIONAL RECURRENT NEURAL NETWORKS" />
    <node id="CONTEXT SPACE" />
    <node id="PROBABILISTIC APPROACHES" />
    <node id="CONTINUOUS SPACE LANGUAGE MODELS" />
    <node id="CCMATRIX" />
    <node id="PARALLEL DATA" />
    <node id="LATENT VARIABLE MODELS OF SELECTIONAL PREFERENCE" />
    <node id="SPMRL 2013 SHARED TASK" />
    <node id="PARSING" />
    <node id="NEURAL MACHINE TRANSLATION OF RARE WORDS" />
    <node id="BIDIRECTIONAL ATTENTION FLOW" />
    <node id="NATURAL TTS SYNTHESIS" />
    <node id="MACHINE COMPREHENSION" />
    <node id="MATHEMATICAL THEORY OF COMMUNICATION" />
    <node id="PREDICTION AND ENTROPY OF PRINTED ENGLISH" />
    <node id="COMMUNICATION THEORY" />
    <node id="TEXT-TO-SPEECH SYNTHESIS" />
    <node id="REPLUG" />
    <node id="PROSODY AND DIALOG ACT CLASSIFICATION" />
    <node id="DEFINITE ANAPHORA COMPREHENSION" />
    <node id="SEMANTIC NETWORKS" />
    <node id="ETHNOLOGUE: LANGUAGES OF THE WORLD" />
    <node id="OPTIMIZING DIALOGUE MANAGEMENT" />
    <node id="MULTILINGUAL INSTRUCTION TUNING" />
    <node id="NICOMACHEAN ETHICS" />
    <node id="SEPTEM CIRCUMSTANTIAE" />
    <node id="CONNECTIONISM" />
    <node id="SYMBOLIC STRUCTURES" />
    <node id="LEXICAL CHAINING" />
    <node id="DISCOURSE GENERATION" />
    <node id="KAGGLE TEXT NORMALIZATION CHALLENGE" />
    <node id="ARGUMENTATIVE DISCOURSE STRUCTURES" />
    <node id="ASSERTION" />
    <node id="AUTHORS AND PUBLICATIONS" />
    <node id="EXPLICIT WORD ERROR MINIMIZATION" />
    <node id="DIALOGUE ACT MODELING" />
    <node id="STOCHASTIC APPROACH" />
    <node id="MULTILINGUAL AND CROSS-DOMAIN TEMPORAL TAGGING" />
    <node id="FUNCTIONAL CENTERING" />
    <node id="ENERGY AND POLICY CONSIDERATIONS FOR DEEP LEARNING" />
    <node id="CHARACTERISTIC-RICH QUESTION SETS" />
    <node id="END-TO-END MEMORY NETWORKS" />
    <node id="MUC PROCEEDINGS" />
    <node id="TAC2013 KNOWLEDGE BASE POPULATION" />
    <node id="PREDICATE-ARGUMENT STRUCTURES" />
    <node id="RHETORICAL STRUCTURE THEORY PARSERS" />
    <node id="SEQUENCE TO SEQUENCE LEARNING" />
    <node id="BIG-BENCH TASKS" />
    <node id="CORRECTIONS IN SPOKEN DIALOGUE SYSTEMS" />
    <node id="UNSUPERVISED SEMANTIC ROLE LABELLING" />
    <node id="VECTOR IMAGES IN DOCUMENT RETRIEVAL" />
    <node id="CORPUS-BASED TECHNIQUES IN SYNTHESIS SYSTEMS" />
    <node id="LEXICALIZATION PATTERNS" />
    <node id="INTERACTION DYNAMICS AND PERSUASION STRATEGIES" />
    <node id="FRAME THEORY" />
    <node id="CLOZE PROCEDURE" />
    <node id="PRONOUNCING DICTIONARY" />
    <node id="HIDDEN MARKOV MODEL FOR PART-OF-SPEECH TAGGING" />
    <node id="WORD EMBEDDING METHODS" />
    <node id="ROGUE DIMENSIONS IN TRANSFORMER MODELS" />
    <node id="UNSUPERVISED INDUCTION OF SEMANTIC ROLES" />
    <node id="BAYESIAN APPROACH TO UNSUPERVISED SEMANTIC ROLE INDUCTION" />
    <node id="FEATURE-RICH PART-OF-SPEECH TAGGING" />
    <node id="AFFECT, IMAGERY, CONSCIOUSNESS" />
    <node id="LINGUISTIC RULES FOR TEXT-TO-SPEECH" />
    <node id="COMMON-SENSE REASONING EVALUATION" />
    <node id="WORD PREDICTION IN AAC" />
    <node id="WORD REPRESENTATIONS" />
    <node id="SEMANTIC ORIENTATION" />
    <node id="CORPUS-BASED LEARNING OF ANALOGIES" />
    <node id="CORPUS-BASED LEARNING" />
    <node id="ANAPHORIC PHENOMENA" />
    <node id="DISCOURSE ANAPHORA" />
    <node id="NATURAL LANGUAGE UNDERSTANDING" />
    <node id="TEMPORAL ANNOTATION" />
    <node id="VAGUENESS AND REFERENTIAL AMBIGUITY" />
    <node id="SPEECH DISCRIMINATION" />
    <node id="TIME-DELAY NEURAL NETWORKS" />
    <node id="DIALOGUE STRATEGY SELECTION" />
    <node id="SENTIMENT AND TOPIC CLASSIFICATION" />
    <node id="DISCOURSE SEGMENTATION" />
    <node id="END-TO-END SPEECH PROCESSING" />
    <node id="MACHINE TRANSLATION OF LANGUAGES" />
    <node id="WIKIDATA" />
    <node id="EMAIL DIALOGUE AGENT" />
    <node id="CENTERING IN DISCOURSE" />
    <node id="MULTI-TASK BENCHMARK" />
    <node id="GLUE" />
    <node id="INFORMATION SYSTEMS" />
    <node id="DATA VISUALIZATION" />
    <node id="CONVERSATIONAL SAFETY" />
    <node id="ANNOTATION" />
    <node id="SYNTACTIC TAGGING" />
    <node id="CONTEXT CHANGE" />
    <node id="MULTILINGUAL SHALLOW DISCOURSE PARSING" />
    <node id="PROMPT-BASED MODELS" />
    <node id="PROBABILISTIC MODELS" />
    <node id="ZERO-FREQUENCY PROBLEM" />
    <node id="ADAPTIVE SWITCHING CIRCUITS" />
    <node id="NATURAL LANGUAGE QUESTION ANSWERING" />
    <node id="SUBJECTIVITY CLASSIFICATIONS" />
    <node id="PHILOSOPHICAL INVESTIGATIONS" />
    <node id="VÖLKERPSYCHOLOGIE" />
    <node id="DATA MINING" />
    <node id="TAY EXPERIMENT" />
    <node id="DETOXIFYING LANGUAGE MODELS" />
    <node id="UNSUPERVISED SEMANTIC ROLE LABELING" />
    <node id="GOOGLE'S NEURAL MACHINE TRANSLATION SYSTEM" />
    <node id="ZERO-SHOT ENTITY LINKING" />
    <node id="CONLL 2016 SHARED TASK" />
    <node id="STATISTICAL DEPENDENCY ANALYSIS" />
    <node id="PERSUASIVE STRATEGIES" />
    <node id="CROWDFUNDING PLATFORMS" />
    <node id="COMPETITION LEARNING APPROACH" />
    <node id="SPEECH USER INTERFACES" />
    <node id="SPEECHACTS" />
    <node id="KNOWLEDGE BASE QUESTION ANSWERING" />
    <node id="SEMANTIC PARSE LABELING" />
    <node id="HIDDEN INFORMATION STATE MODEL" />
    <node id="DISCOURSE UNIT SEGMENTATION" />
    <node id="CONNECTIVE DETECTION" />
    <node id="SEMANTIC ROLE CLASSIFICATION" />
    <node id="INDUCTIVE LOGIC PROGRAMMING" />
    <node id="DATABASE QUERY PARSING" />
    <node id="TAGSET CONVERSION" />
    <node id="TAGSET DRIVERS" />
    <node id="PHRASE-TABLE REPRESENTATION" />
    <node id="PROBABILISTIC CATEGORIAL GRAMMARS" />
    <node id="LOGICAL FORM MAPPING" />
    <node id="SPEECH APPLICATIONS" />
    <node id="GENDER BIAS IN WORD EMBEDDINGS" />
    <node id="DEBIASING METHODS" />
    <node id="MULTILINGUAL DEPENDENCY LEARNING" />
    <node id="SEMANTIC DEPENDENCY PARSING" />
    <node id="GAUSSIAN FIELDS" />
    <node id="STORY-LIKE VISUAL EXPLANATIONS" />
    <node id="BOOKS AND MOVIES" />
    <node id="AIFF FILE" />
    <node id="ALGORITHM" />
    <node id="PHRASE-STRUCTURE GRAMMAR" />
    <node id="REGRESSION" />
    <node id="RELEVANCE" />
    <node id="RESOURCE MANAGEMENT" />
    <node id="SHALLOW DISCOURSE PARSING" />
    <node id="SYNTACTIC DISAMB(&quot;ENTITY&quot;" />
    <node id="PER-WORD ENTROPY" />
    <node id="NAIVE BAYES APPROACH" />
    <node id="TRANSCRIPTION" />
    <node id="TEMPORAL INFORMATION EXTRACTION" />
    <node id="PART-OF-S(&quot;ENTITY&quot;" />
    <node id="TURK, MECHANICAL" />
    <node id="TURKISHAGGLUTINATIVE" />
    <edge source="SPEECH AND LANGUAGE PROCESSING" target="NATURAL LANGUAGE PROCESSING (NLP)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH AND LANGUAGE PROCESSING" target="COMPUTATIONAL LINGUISTICS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH AND LANGUAGE PROCESSING" target="SPEECH RECOGNITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH AND LANGUAGE PROCESSING" target="DANIEL JURAFSKY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH AND LANGUAGE PROCESSING" target="JAMES H. MARTIN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="MACHINE TRANSLATION (MT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="QUESTION ANSWERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="DEPENDENCY PARSING">
      <data key="d0">17.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="INFORMATION EXTRACTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SEMANTIC ROLE LABELING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="DISCOURSE COHERENCE">
      <data key="d0">10.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="CORPORA">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="CHATBOTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="EDIT DISTANCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="TEXT NORMALIZATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="TF-IDF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="VECTOR SEMANTICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="COMPUTATIONAL LINGUISTICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="COREFFERENCE RESOLUTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="CORE REFERENCE RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SEMANTIC PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="MAXIMUM ENTROPY APPROACH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="WORD EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="REPLICABILITY ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="STATISTICAL SIGNIFICANCE TESTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SYNTHESIS LECTURES ON HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="COREFERENCE RESOLUTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="NEURAL SYNTACTIC LANGUAGE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="NLP LEADERBOARDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="UNSUPERVISED NAMED-ENTITY EXTRACTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="DISCOURSE PARSER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="ENTITY-CENTRIC CONTEXTUAL AFFECTIVE ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="TEXT PREPROCESSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="LATENT SEMANTIC ANALYSIS (LSA)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="EMNLP">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="NATURAL LANGUAGE ENGINEERING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="ANLP/NAACL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="MULTI-TASK BENCHMARK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SENTIMENT ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="DIALOGUE SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SYNTACTIC TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="LARGE LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="LOGISTIC REGRESSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="INFORMATION RETRIEVAL (IR)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="EMBEDDING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SPEECH PROCESSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="SYNTACTIC PATTERNS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING (NLP)" target="AUTHORS AND PUBLICATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COMPUTATIONAL LINGUISTICS" target="SELECTIONAL PREFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COMPUTATIONAL LINGUISTICS" target="PENN DISCOURSE TREEBANK 2.0">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COMPUTATIONAL LINGUISTICS" target="ACL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="AUTOMATIC SPEECH RECOGNITION (ASR)">
      <data key="d0">36.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="TEXT-TO-SPEECH (TTS)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="DISFLUENCIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="LANGUAGE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="N-GRAM LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="NLP TASKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="DIALOGUE SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="ENCODER-DECODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)">
      <data key="d0">36.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="RNN-TRANSDUCER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="SPEECH ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="SWITCHBOARD">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="TELEPHONE SPEECH CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="ERROR CORRECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="END-TO-END SPEECH RECOGNITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="PHONEME CLASSIFICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="BIDIRECTIONAL LSTM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="MAPSSWE TEST">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="MACHINE TRANSLATION (MT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="RECURRENT ERROR PROPAGATION NETWORK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="DYNAMIC PROGRAMMING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="SPOKEN DIALOGUE SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION" target="SPEAKER DIARIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="ENCODER-DECODER">
      <data key="d0">18.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BEAM SEARCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="LOW-RESOURCE TRANSLATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="MT EVALUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="LANGUAGE DIVERGENCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="TYPOLOGY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BIAS AND ETHICAL ISSUES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="ALIGNMENT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="N-GRAM LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="ENCODER-DECODER MODEL">
      <data key="d0">18.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="ENCODER-DECODER ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="CHRF">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="ENCODER-DECODER NETWORK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="DIGITAL DIVIDE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="POST-EDITING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="COMPUTER-AIDED TRANSLATION (CAT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="INCREMENTAL TRANSLATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="IMAGE-CENTRIC TRANSLATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="LINGUISTIC TYPOLOGY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="NLP TASKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BACKTRANSLATION">
      <data key="d0">20.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="MULTILINGUAL MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="PARALLEL CORPORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BITEXT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BLEU">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="PARALLEL CORPUS">
      <data key="d0">34.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="METEOR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="TASK ERROR RATE (TER)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="EMBEDDING-BASED METHODS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="ALPAC REPORT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="COREFERENCE RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="PROBABILISTIC REPRESENTATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="PARAMETER ESTIMATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="MACHINE TRANSLATION METRICS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="HIERARCHICAL PHRASE-BASED MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="DEEP NEURAL NETWORKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BACK-TRANSLATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="MULTILINGUAL MACHINE TRANSLATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="AUTOMATA THEORY">
      <data key="d0">14.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="DECISION-TREE MODELS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="MINIMUM ERROR RATE TRAINING (MERT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="BLEU SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="GENDER BIAS">
      <data key="d0">18.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="MACHINE TRANSLATION OF LANGUAGES">
      <data key="d0">27.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="SEMANTICS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="PHRASE-TABLE REPRESENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="UNITED NATIONS PARALLEL CORPUS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="CHR-F">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION (MT)" target="WINOMT DATASET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">36.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="WORD PREDICTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="NLP TASKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="FACTOID QUESTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="HALLUCINATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="IBM WATSON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="LARGE LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="DEEP THOUGHT">
      <data key="d0">6.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="PROPRIETARY DATA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="QA DATASET">
      <data key="d0">36.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="INFORMATION RETRIEVAL (IR)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="MEAN RECIPROCAL RANK (MRR)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="RETRIEVER/READER ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="DEEP NEURAL NETWORKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="BBQ: A HAND-BUILT BIAS BENCHMARK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="ENTITY LINKING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="TEXT CATEGORIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="QUESTION ANSWERING" target="READING COMPREHENSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="CONSTITUENCY PARSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="DEPENDENCY RELATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="TRANSITION-BASED DEPENDENCY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="GRAPH-BASED DEPENDENCY PARSING">
      <data key="d0">19.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="PARSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="DEPENDENCY GRAMMAR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="HEAD-DEPENDENT RELATIONSHIP">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="PROJECTIVITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="TRANSITION-BASED PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="GRAPH-BASED PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="DEPENDENCY TREEBANKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="CLAUSAL RELATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="MODIFIER RELATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="ARC">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="VERTEX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="HEAD-DEPENDENT RELATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="INFORMATION THEORY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING" target="INCREMENTAL NON-PROJECTIVE DEPENDENCY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="RELATION EXTRACTION">
      <data key="d0">26.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="EVENT EXTRACTION">
      <data key="d0">17.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="TIME REPRESENTATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="TEMPLATE FILLING">
      <data key="d0">18.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="MESSAGE UNDERSTANDING CONFERENCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="SEQUENCE LABELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="OPEN IE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="OPEN INFORMATION EXTRACTION FOR THE WEB">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="OPEN INFORMATION EXTRACTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="WIKIPEDIA ANNOTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION" target="DISTANT SUPERVISION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="DISCOURSE COHERENCE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="THEMATIC ROLE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="XYZ CORPORATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="SELECTIONAL RESTRICTIONS">
      <data key="d0">15.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="FRAMENET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="PROPBANK">
      <data key="d0">18.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="PRECISION, RECALL, AND F-MEASURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="CONLL-2005 AND CONLL-2012">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="FEATURE VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="IMPLICIT ARGUMENT DETECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="CONNOTATION FRAMES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="DEPENDENCY GRAMMAR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="AUGMENTED TRANSITION NETWORK (ATN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="UNSUPERVISED APPROACHES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="CONLL-2005 SHARED TASK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="WORD EMBEDDING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="TEXT PREPROCESSING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="THE PROPOSITION BANK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="UNIVERSAL PART-OF-SPEECH TAGSET">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="RECURSIVE NEURAL NETWORKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLE LABELING" target="ROLE-FILLER EXTRACTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="CHRF">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="LINGUISTIC STRUCTURE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="DAVID HUME">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="CENTERING THEORY">
      <data key="d0">10.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="ENTITY GRID MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="PRONOMINALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="COHERENCE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="ENTITY-BASED COHERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="NEURAL COHERENCE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="RHETORICAL RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="SEGMENTED DISCOURSE REPRESENTATION THEORY (SDRT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="LINGUISTIC DISCOURSE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="SELF-SUPERVISION FOR COHERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="HMM MODEL FOR TOPICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="EXPLICIT AND IMPLICIT DISCOURSE CONNECTIVES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="DISCOURSE CONNECTIVES">
      <data key="d0">18.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="VERB PHRASE ELLIPSIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="GAPPING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="TENSE INTERPRETATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="DISCOURSE PROCESSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="DISCOURSE STRUCTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="DISCOURSE-LEVEL LINGUISTIC PHENOMENA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="COHERENCE RELATIONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="COMMON SENSE ENTAILMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="DISCOURSE PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="TEXT SUMMARIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="NAACL HLT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="LEXICAL CHAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="SUBJECTIVITY CLASSIFICATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE COHERENCE" target="CORE REFERENCE RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="TEXT-TO-SPEECH (TTS)">
      <data key="d0">64.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="FEATURE EXTRACTION">
      <data key="d0">36.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="LOG MEL SPECTRUM">
      <data key="d0">18.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="SPEECH RECOGNITION ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="WORD ERROR RATE (WER)">
      <data key="d0">105.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="NEURAL NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="ENCODER-DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="ALIGNMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CTC LOSS FUNCTION">
      <data key="d0">15.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="ACOUSTIC FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="VOCABULARY SIZE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="READ SPEECH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CONVERSATIONAL SPEECH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CHANNEL AND NOISE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="ACCENT OR SPEAKER-CLASS CHARACTERISTICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="LIBRISPEECH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="AUGMENTATIVE COMMUNICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="SMART HOME APPLIANCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="TELEPHONY APPLICATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="DICTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="SWITCHBOARD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CALLHOME">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="SANTA BARBARA CORPUS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CORAAL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CHIME CHALLENGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="HKUST">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="AISHELL-1">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="CHARACTER ERROR RATE (CER)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="TEXT-TO-SPEECH (TTS) SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="SPEAKER-INDEPENDENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="WAKE WORD DETECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="DYNAMIC TIME WARPING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="ENCODER-DECODER WITH ATTENTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="SPEECH-TO-SPEECH TRANSLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC SPEECH RECOGNITION (ASR)" target="AIFF FILE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="SPEECH SYNTHESIS">
      <data key="d0">36.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="TEXT SUMMARIZATION">
      <data key="d0">12.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="TRANSCRIPTION">
      <data key="d0">14.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="ENCODER-DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="CONVERSATIONAL AGENTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="SPEECH SYNTHESIZER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS)" target="MEAN OPINION SCORE (MOS)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="N-GRAM LANGUAGE MODEL">
      <data key="d0">18.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="NAIVE BAYES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="LARGE LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="MASKED LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="INSTRUCTION-TUNING DATA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="CODEX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="INSTRUCTGPT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="PARSING AS LANGUAGE MODELING (PALM)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="GREEDY DECODING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="EXACT MATCH (EM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="BBH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="HUMAN-RATER BASELINES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="WINOGRAD SCHEMA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="DIALOG APPLICATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="IN-CONTEXT RETRIEVAL-AUGMENTED LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="CONTINUOUS SPACE LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="INTERPOLATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="RLHF">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="BEAM SEARCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SPELLING CORRECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="N-GRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="AUGMENTATIVE AND ALTERNATIVE COMMUNICATION (AAC)">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="WORD PREDICTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="GRAMMAR CORRECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="TRAINING SET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="TEST SET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="PERPLEXITY">
      <data key="d0">18.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SAMPLING">
      <data key="d0">15.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="UNIGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="BIGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="TRIGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="WALL STREET JOURNAL (WSJ)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="OVERFITTING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SHAKESPEARE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SMOOTHING ALGORITHMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">18.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SOFTMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SELF-SUPERVISED LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="CROSS-ENTROPY LOSS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="TEXT GENERATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="LAMDA SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="RESPONSE TOKEN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="SENSIBLE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="INTERESTING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="UNSAFE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="GENERATIVE TASK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="DISCRIMINATIVE TASK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="FINE-TUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="MACHINE READING COMPREHENSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL" target="NEURAL EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="SMOOTHING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="INTERPOLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="BACKOFF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="QUANTIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="KENLM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="REVERSE TRIES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="ENTROPY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="PERPLEXITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="MARKOV MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="NEURAL NET LANGUAGE MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="NEURAL LANGUAGE MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="MARKOV CHAIN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="INFINI-GRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM LANGUAGE MODEL" target="FEEDFORWARD NEURAL LANGUAGE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="PRECISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="RECALL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="F-MEASURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="CROSS-VALIDATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="STATISTICAL SIGNIFICANCE TESTING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="TEXT CATEGORIZATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="SENTIMENT ANALYSIS">
      <data key="d0">17.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="BINARY NAIVE BAYES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="SPAM DETECTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="LANGUAGE ID">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="UNIGRAM LANGUAGE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="TEXT CLASSIFICATION">
      <data key="d0">18.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="LOGISTIC REGRESSION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="TEST SET">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="MODEL CARD">
      <data key="d0">6.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="BAG-OF-WORDS ASSUMPTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="CONDITIONAL INDEPENDENCE ASSUMPTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="BAG-OF-WORDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="CONDITIONAL INDEPENDENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="DISCRIMINATIVE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAIVE BAYES" target="CORRELATED FEATURES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="TRANSFORMER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="MODEL ALIGNMENT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="SAMPLING FOR LLM GENERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PRETRAINING LARGE LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="DEALING WITH SCALE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="POTENTIAL HARMS FROM LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PRETRAINING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="GENERATIVE AI">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="GREEDY DECODING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="BEAM SEARCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="SAMPLING METHODS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="SELF-SUPERVISED TRAINING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="TRANSFORMER LANGUAGE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="UNIGRAM LANGUAGE MODEL">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="COMMON CRAWL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="C4">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="WIKIPEDIA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="THE PILE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="DOLMA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="CONTEXT WINDOW">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="FAQ LISTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="TRANSLATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="SUMMARIES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="LORA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="HALLUCINATION">
      <data key="d0">18.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="TOXIC LANGUAGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="BIAS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="MISINFORMATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PRIVACY VIOLATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="DATASETS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="MODEL CARD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="NLP TASKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="SAMPLING ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="CV CACHE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PARAMETER-EFFICIENT FINETUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="CALIBRATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="LEGAL DOMAIN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="QA DATASET">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="TNTPOS TAGGER">
      <data key="d0">5.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="LEGAL HALLUCINATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="INSTRUCTION SEARCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="PROMPT ENGINEERING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="TRANSFORMER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="BIDIRECTIONAL TRANSFORMER ENCODER">
      <data key="d0">16.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="TRAINING BIDIRECTIONAL ENCODERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="CONTEXTUAL EMBEDDING">
      <data key="d0">18.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="FINE-TUNING FOR CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="FINE-TUNING FOR SEQUENCE LABELLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="SUBWORD TOKENIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODEL" target="MULTILINGUAL MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMOOTHING" target="LAPLACE SMOOTHING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMOOTHING" target="DISCOUNTING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SMOOTHING" target="INTERPOLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMOOTHING" target="BACKOFF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMOOTHING" target="ZERO PROBABILITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INTERPOLATION" target="HELD-OUT CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INTERPOLATION" target="EM ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRECISION" target="FALSE POSITIVE">
      <data key="d0">32.0</data>
    </edge>
    <edge source="PRECISION" target="FALSE NEGATIVE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRECISION" target="RECALL">
      <data key="d0">69.0</data>
    </edge>
    <edge source="PRECISION" target="F-MEASURE">
      <data key="d0">17.0</data>
    </edge>
    <edge source="PRECISION" target="TRUE POSITIVE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRECISION" target="F1 MEASURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRECISION" target="CHRF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRECISION" target="RANKED RETRIEVAL SYSTEM">
      <data key="d0">16.0</data>
    </edge>
    <edge source="PRECISION" target="PRECISION-RECALL CURVE">
      <data key="d0">18.0</data>
    </edge>
    <edge source="PRECISION" target="MEAN AVERAGE PRECISION (MAP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRECISION" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRECISION" target="PARSEVAL METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRECISION" target="F1 SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRECISION" target="CONFUSION MATRIX">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECALL" target="FALSE NEGATIVE">
      <data key="d0">18.0</data>
    </edge>
    <edge source="RECALL" target="F-MEASURE">
      <data key="d0">17.0</data>
    </edge>
    <edge source="RECALL" target="TRUE POSITIVE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECALL" target="F1 MEASURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECALL" target="CHRF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECALL" target="RANKED RETRIEVAL SYSTEM">
      <data key="d0">2.0</data>
    </edge>
    <edge source="RECALL" target="PRECISION-RECALL CURVE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECALL" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECALL" target="PARSEVAL METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECALL" target="F1 SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CROSS-VALIDATION" target="TEST SET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-VALIDATION" target="10-FOLD CROSS-VALIDATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CROSS-VALIDATION" target="FOLDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CROSS-VALIDATION" target="DEVSET">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CROSS-VALIDATION" target="TRAINING SET">
      <data key="d0">26.0</data>
    </edge>
    <edge source="STATISTICAL SIGNIFICANCE TESTING" target="NULL HYPOTHESIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL SIGNIFICANCE TESTING" target="P-VALUE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STATISTICAL SIGNIFICANCE TESTING" target="APPROXIMATE RANDOMIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="STATISTICAL SIGNIFICANCE TESTING" target="BOOTSTRAP TEST">
      <data key="d0">1.0</data>
    </edge>
    <edge source="STATISTICAL SIGNIFICANCE TESTING" target="EFFECT SIZE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="RNNS AND LSTMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="THE TRANSFORMER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="FEEDFORWARD NEURAL NETWORKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="RECURRENT NEURAL NETWORKS (RNNS)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="XOR PROBLEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="LOGISTIC REGRESSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="FEEDFORWARD NETWORK">
      <data key="d0">99.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="RECURRENT NETWORKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="TRANSFORMER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="DEEP LEARNING">
      <data key="d0">18.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="ERROR BACKPROPAGATION">
      <data key="d0">18.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="HIDDEN LAYER">
      <data key="d0">36.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="OPTIMIZATION ALGORITHMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="ACTIVATION FUNCTION">
      <data key="d0">34.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="CONNECTIONIST MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="DISTRIBUTED REPRESENTATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="TIME-DELAY NEURAL NETWORK (TDNN)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">18.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="HYBRID HMM/MLP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="NEURAL PROBABILISTIC LANGUAGE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="BIDIRECTIONAL RECURRENT NEURAL NETWORKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="DROPOUT">
      <data key="d0">16.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="SIGMOID FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="GRADIENT DESCENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="REGULARIZATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="OVERFITTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="LOSS FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="HYPERPARAMETER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="RELU FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="BACKWARD PASS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="FORWARD PASS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="FEEDFORWARD NEURAL LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="PYTORCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="TENSORFLOW">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="MODEL ARCHITECTURE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="LISTEN ATTEND AND SPELL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL NETWORK" target="MACHINE LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHATBOTS" target="DIALOGUE SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHATBOTS" target="ELIZA">
      <data key="d0">17.0</data>
    </edge>
    <edge source="CHATBOTS" target="CONVERSATIONAL AGENTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHATBOTS" target="PRIVACY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHATBOTS" target="EMOTIONAL ENGAGEMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHATBOTS" target="FRAME-BASED DIALOGUE SYSTEM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CHATBOTS" target="NEURAL CHATBOTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHATBOTS" target="TRAINING CHATBOTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHATBOTS" target="PARTICIPANT EVALUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHATBOTS" target="OBSERVER EVALUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="FRAME-BASED DIALOGUE SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="DIALOGUE ACTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="DIALOGUE STATE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="NLP TASKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="FRAME">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="MEDICAL ADVICE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="REPRESENTATIONAL HARM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="PRIVACY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="GENDER EQUALITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="VALUE SENSITIVE DESIGN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="INSTITUTIONAL REVIEW BOARD (IRB)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="GUS SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="BDI MODELS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="SIRI">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="ALEXA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="GOOGLE ASSISTANT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="ETHICAL ISSUES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="SPEECH ACTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="FRAME-BASED ARCHITECTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="DIALOGUE-STATE ARCHITECTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="HUMAN-COMPUTER INTERACTION (HCI)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="GUS ARCHITECTURE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="SLOT ERROR RATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="PLAN RECOGNITION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="FAIRNESS IN DIALOGUE SYSTEMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="SPOKEN DIALOGUE MANAGEMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="SPEECH SYNTHESIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="TASK-BASED DIALOGUE SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM" target="CONVERSATIONAL SAFETY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="PARTS OF SPEECH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="NAMED ENTITY">
      <data key="d0">16.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="CONTEXT-FREE GRAMMAR (CFG)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="NAMED-ENTITY TAGGING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="HMM PART-OF-SPEECH TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="CONDITIONAL RANDOM FIELDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">18.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="BIDIRECTIONAL TRANSFORMER ENCODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="SOFTMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="ARGMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="PART-OF-SPEECH TAGGING">
      <data key="d0">18.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="RNNS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="TRANSFORMER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="PART-OF-SPEECH (POS)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="POSITIONAL EMBEDDING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="RELATION EXTRACTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEQUENCE LABELING" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARTS OF SPEECH" target="TEXT-TO-SPEECH SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAMED ENTITY" target="TEXT-TO-SPEECH SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAMED ENTITY" target="PART-OF-SPEECH TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY" target="SEQUENCE MODELING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAMED ENTITY" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="CONSTITUENCY PARSING">
      <data key="d0">17.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="TREEBANK">
      <data key="d0">32.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="GRAMMAR EQUIVALENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="NORMAL FORM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="CKY PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="COREFERENCE RESOLUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="CKY ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="BIGRAM">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="PARSE TREE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="PARSE AMBIGUITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="DEPENDENCY GRAMMAR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="STATISTICAL PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="FORMAL LANGUAGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="LEXICON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="GENERATIVE GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="PRODUCTION RULE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="DERIVATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="PENN TREEBANK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="CHOMSKY NORMAL FORM (CNF)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE GRAMMAR (CFG)" target="GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONSTITUENCY PARSING" target="SPAN-BASED NEURAL CONSTITUENCY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONSTITUENCY PARSING" target="HEADS AND HEAD-FINDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONSTITUENCY PARSING" target="PARSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONSTITUENCY PARSING" target="STRUCTURAL AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONSTITUENCY PARSING" target="NEURAL CONSTITUENCY PARSERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LEXICON" target="SENTIMENT">
      <data key="d0">17.0</data>
    </edge>
    <edge source="LEXICON" target="SENTIMENT ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LEXICON" target="AFFECTIVE STATES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICON" target="SEMI-SUPERVISED METHODS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICON" target="RULE-BASED CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICON" target="VECTOR SPACE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICON" target="GRAMMAR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT" target="CONNOTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT" target="SEMANTIC FRAME">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SENTIMENT" target="EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT" target="SENTIMENT ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT" target="VALENCE/AROUSAL/DOMINANCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT" target="SUPERVISED TEXT CLASSIFICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT" target="GRAPH BASED ALGORITHMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ENTITY LINKING">
      <data key="d0">33.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="TEMPLATE FILLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="DISCOURSE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="WINOGRAD SCHEMA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="EVENT COREFERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="MENTIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="COREFERENCE CHAIN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ONTOLOGICAL DATASETS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="PRONOMINAL ANAPHORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="DEFINITE NOUN PHRASES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="GOLD MENTION-DETECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="COREFERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ONTO NOTES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="MENTION-PAIR ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="MENTION-RANK ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ENTITY-BASED MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="SUPERVISED NEURAL MACHINE LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="COREFERENCE ALGORITHMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="MENTION-RANKING MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="MUC METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="B3 METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="CEAF METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="LEA METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ENTITY GRID">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="SENTENCE ANALYSIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="NAMED ENTITY DISAMBIGUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="KNOWREF">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="LATENT STRUCTURE PERCEPTRON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="COGNITIVE STATUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="NAMED-ENTITY LINKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="BRIDGING RESOLUTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="BERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="PRONOMINAL ANAPHORA RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="WINOGRAD SCHEMA CHALLENGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="EMNLP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="CONFERENCE ON NATURAL LANGUAGE LEARNING (CONLL)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="DISCOURSE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ONTOLOGY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="DISCOURSE ANAPHORA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ANNOTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="COMPETITION LEARNING APPROACH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE RESOLUTION" target="ANAPHORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="COREFFERENCE RESOLUTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="DISCOURSE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="ONTOLOGY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="REAL-WORLD ENTITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="WIKIPEDIA">
      <data key="d0">18.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="KNOWLEDGE BASE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="WIKIFICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="TAGME ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="NEURAL GRAPH-BASED LINKING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="ELQ LINKING ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="WEBQUESTIONS SP">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="GRAPHQUESTIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTITY LINKING" target="COREFERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TOKENIZATION" target="EDIT DISTANCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TOKENIZATION" target="REGULAR EXPRESSION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TOKENIZATION" target="WORD NORMALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="SENTENCE SEGMENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="TEXT NORMALIZATION">
      <data key="d0">39.0</data>
    </edge>
    <edge source="TOKENIZATION" target="NLP ALGORITHMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="BPE ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="PENN TREEBANK TOKENIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="MULTIWORD EXPRESSIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="FINITE STATE AUTOMATA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TOKENIZATION" target="NATURAL LANGUAGE TOOLKIT (NLTK)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TOKENIZATION" target="CORENLP TOOLKIT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TOKENIZATION" target="EMBEDDING MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="SUBWORD TOKENIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKENIZATION" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EDIT DISTANCE" target="REGULAR EXPRESSION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="EDIT DISTANCE" target="LEVENSHTEIN DISTANCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EDIT DISTANCE" target="DYNAMIC PROGRAMMING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDIT DISTANCE" target="OPERATION LIST">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDIT DISTANCE" target="WORD ERROR RATE (WER)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="PATTERN MATCHING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="STRING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="CONCATENATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="OPTIONALITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="KLEENE STAR">
      <data key="d0">16.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="KLEENE PLUS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="WILDCARD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="ANCHOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="DISJUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="PARENTHESES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="OPERATOR PRECEDENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="GREEDY MATCHING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="NON-GREEDY MATCHING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="WORD BOUNDARY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="CARET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="DOLLAR SIGN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="WORD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="CAPTURE GROUP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="SUBSTITUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="OPERATORS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="ALIAS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="COUNTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="ESCAPED CHARACTERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="LOOKAHEAD ASSERTIONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="UNIX TOOLS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="TEXT NORMALIZATION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="FINITE AUTOMATON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULAR EXPRESSION" target="TEXT SEARCHING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD NORMALIZATION" target="BYTE-PAIR ENCODING (BPE)">
      <data key="d0">6.0</data>
    </edge>
    <edge source="WORD NORMALIZATION" target="LEMMATIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD NORMALIZATION" target="STEMMING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTENCE SEGMENTATION" target="TEXT NORMALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE SEGMENTATION" target="CORENLP TOOLKIT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTENCE SEGMENTATION" target="PUNCTUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="SIGMOID FUNCTION">
      <data key="d0">28.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="CROSS-ENTROPY LOSS FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="GRADIENT DESCENT">
      <data key="d0">16.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="REGULARIZATION">
      <data key="d0">14.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="DISCRIMINATIVE CLASSIFIER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="PROBABILISTIC CLASSIFIER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="DECISION BOUNDARY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="SENTIMENT CLASSIFICATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="FEATURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="MATRIX ARITHMETIC">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="TEST SET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="TRAINING SET">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="WEIGHT VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="CROSS-ENTROPY LOSS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="CORRELATED FEATURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="BINARY LOGISTIC REGRESSION">
      <data key="d0">17.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="MULTINOMIAL LOGISTIC REGRESSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="BERNOULLI DISTRIBUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="FEATURE VECTOR">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="SOFTMAX REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="INTERPRETABILITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="MAXIMUM ENTROPY MODELING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="SKIP-GRAM">
      <data key="d0">17.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="CLASSIFICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="HIDDEN LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="SIGMOID">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGISTIC REGRESSION" target="FEATURE-BASED CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SIGMOID FUNCTION" target="LOGIT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SIGMOID FUNCTION" target="BINARY LOGISTIC REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SIGMOID FUNCTION" target="ACTIVATION FUNCTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="SIGMOID FUNCTION" target="SATURATED">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SIGMOID FUNCTION" target="BINARY CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="SCALING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="LOSS FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="STOCHASTIC GRADIENT DESCENT">
      <data key="d0">16.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="CONVEX FUNCTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="OPTIMIZATION ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="SLOPE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="LEARNING RATE">
      <data key="d0">10.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="GRADIENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="CROSS-ENTROPY LOSS">
      <data key="d0">27.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="CONVEX OPTIMIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="PARTIAL DERIVATIVE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="OPTIMIZATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="MINI-BATCH GRADIENT DESCENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="ADAM OPTIMIZER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="NEURAL NET LANGUAGE MODELS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="TRANSFORMER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="BATCH SIZE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRADIENT DESCENT" target="PARAMETER-EFFICIENT FINE TUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULARIZATION" target="OVERFITTING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REGULARIZATION" target="L2 REGULARIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REGULARIZATION" target="L1 REGULARIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="TF-IDF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="WORD2VEC">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="COSINE SIMILARITY">
      <data key="d0">24.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="VISUALIZING EMBEDDINGS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="SEMANTIC PROPERTIES OF EMBEDDINGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="BIAS AND EMBEDDINGS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="EVALUATING VECTOR MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="DISTRIBUTIONAL HYPOTHESIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="EMBEDDING">
      <data key="d0">27.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="TERM-DOCUMENT MATRIX">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="SPARSE VECTOR MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="DENSE VECTOR MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="DOT PRODUCT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="MUTUAL INFORMATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="INFORMATION RETRIEVAL (IR)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="MULTIDIMENSIONAL SEMANTIC SPACE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS" target="SEMANTIC FEATURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TF-IDF" target="TERM FREQUENCY (TF)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TF-IDF" target="INVERSE DOCUMENT FREQUENCY (IDF)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TF-IDF" target="CO-OCCURRENCE MATRIX">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TF-IDF" target="SHAKESPEARE PLAYS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TF-IDF" target="INFORMATION RETRIEVAL (IR)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TF-IDF" target="VECTOR SEMANTICS MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TF-IDF" target="DOCUMENT SIMILARITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TF-IDF" target="TERM WEIGHTING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TF-IDF" target="BM25">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TF-IDF" target="TEXT CATEGORIZATION">
      <data key="d0">18.0</data>
    </edge>
    <edge source="WORD2VEC" target="EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD2VEC" target="SKIP-GRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD2VEC" target="SELF-SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD2VEC" target="STATIC EMBEDDINGS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WORD2VEC" target="GLOVE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD2VEC" target="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD2VEC" target="PARALLELOGRAM MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD2VEC" target="VECTOR SPACE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD2VEC" target="EMBEDDING ALGORITHMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD2VEC" target="WORD EMBEDDING">
      <data key="d0">18.0</data>
    </edge>
    <edge source="WORD2VEC" target="CONTEXTUAL EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="EMBEDDING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="DOT PRODUCT">
      <data key="d0">17.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="UNIT VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="VECTOR SEMANTICS MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="VECTOR SPACE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="GLOVE VECTORS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="CONTEXTUAL EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="MULTILINGUAL EMBEDDING SPACE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="SIMILARITY SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="RECALL METRIC RBERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="WORD EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COSINE SIMILARITY" target="EMBEDDING SIMILARITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="LONG SHORT-TERM MEMORY (LSTM)">
      <data key="d0">10.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="STACKED AND BIDIRECTIONAL RNN ARCHITECTURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="ENCODER-DECODER MODEL WITH RNNS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="NEURAL LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="SEQUENCE MODELING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="BACKPROPAGATION THROUGH TIME (BPTT)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNNS)" target="VANISHING GRADIENTS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="XOR PROBLEM" target="PERCEPTRON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="SEQUENCE MODELING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">27.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="VANISHING GRADIENTS">
      <data key="d0">18.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="FORGET GATE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="ADD GATE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="OUTPUT GATE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="SIGMOID ACTIVATION FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="HADAMARD PRODUCT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="DECODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="ENCODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="ENCODER-DECODER MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="NEURAL TOXIC DEGENERATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="NEURAL COMPUTATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="DYNAMIC RECURRENT NEURAL NETWORKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="CONTINUAL PREDICTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="SEQUENCE TRANSDUCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY (LSTM)" target="BIDIRECTIONAL LSTM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="ATTENTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSFORMER" target="PARALLELIZING COMPUTATION USING A SINGLE MATRIX X">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="INPUT EMBEDDINGS FOR TOKEN AND POSITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="DECODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="ENCODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="SELF-ATTENTION">
      <data key="d0">18.0</data>
    </edge>
    <edge source="TRANSFORMER" target="MULTI-HEAD ATTENTION">
      <data key="d0">18.0</data>
    </edge>
    <edge source="TRANSFORMER" target="LANGUAGE MODELING HEAD">
      <data key="d0">17.0</data>
    </edge>
    <edge source="TRANSFORMER" target="EMBEDDING MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="UNEMBEDDING MATRIX">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRANSFORMER" target="CONTEXTUAL EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="DECODER-ONLY MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="FEEDFORWARD LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="LAYER NORMALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="PRETRAINING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRANSFORMER" target="RESIDUAL STREAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="POSITIONAL ENCODING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="STACKED TRANSFORMER BLOCKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSFORMER" target="ENCODER-DECODER ARCHITECTURE">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TRANSFORMER" target="MEMORY NETWORKS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRANSFORMER" target="CAUSAL LANGUAGE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="VOCABULARY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="NATURAL LANGUAGE UNDERSTANDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSFORMER" target="ENCODER-DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="EMBEDDING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRANSFORMER" target="MASKED LANGUAGE MODELING (MLM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER" target="GPT2">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSFORMER" target="FOUNDATION MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER" target="CAUSAL TRANSFORMERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION" target="GENERATIVE DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION" target="SOFT WEIGHTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION" target="SELF-ATTENTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ATTENTION" target="CAUSAL SELF-ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION" target="QUERY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ATTENTION" target="KEY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ATTENTION" target="VALUE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ATTENTION" target="ATTENTION HEAD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="PROMPTING">
      <data key="d0">15.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="POST-TRAINING AND MODEL ALIGNMENT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="IN-CONTEXT LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="RLHF">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="DIRECT POLICY OPTIMIZATION (DPO)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="INSTRUCTION TUNING">
      <data key="d0">34.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="POST-TRAINING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="HUMAN PREFERENCES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="PREFERENCE ALIGNMENT">
      <data key="d0">16.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="SAFETY TRAINING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MODEL ALIGNMENT" target="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIDIRECTIONAL TRANSFORMER ENCODER" target="BERT">
      <data key="d0">36.0</data>
    </edge>
    <edge source="BIDIRECTIONAL TRANSFORMER ENCODER" target="SELF-ATTENTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIDIRECTIONAL TRANSFORMER ENCODER" target="XLM-ROBERTA">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BIDIRECTIONAL TRANSFORMER ENCODER" target="WORDPIECE TOKENIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="GLOVE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="UMAP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="CONTEXTUAL EMBEDDINGS AND WORD SENSE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="NEAREST-NEIGHBOR CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="SEMANTIC CLUSTERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="ANISOTROPY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="ENTITY-CENTRIC METHOD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="REGRESSION MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="ELMO">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="CANDIDATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="PAIRWISE COSINE SIMILARITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXTUAL EMBEDDING" target="RBERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPTING" target="CHAIN-OF-THOUGHT PROMPTING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROMPTING" target="AUTOMATIC PROMPT OPTIMIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPTING" target="EVALUATING PROMPTED LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROMPTING" target="IN-CONTEXT LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPTING" target="MMLU">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPTING" target="FEW-SHOT LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPTING" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IN-CONTEXT LEARNING" target="INDUCTION HEADS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IN-CONTEXT LEARNING" target="FUZZY PATTERN COMPLETION RULE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RLHF" target="REINFORCEMENT LEARNING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="SUPERVISED FINE TUNING (SFT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="AYA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="SUPERNATURAL INSTRUCTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="FLAN 2022">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="OPT-IML">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="SUPERVISED TRAINING DATA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="SUPER NATURAL INSTRUCTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="CHAIN-OF-THOUGHT PROMPTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="SAFETY INSTRUCTIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="NATURAL LANGUAGE PROCESSING TOOLKIT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INSTRUCTION TUNING" target="FLAN COLLECTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POST-TRAINING" target="FINETUNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POST-TRAINING" target="BASE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POST-TRAINING" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="REASONING TASKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT PROMPTING" target="PROMPT-BASED MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="COMPRESSION STAGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="LOSS FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="GREEDY DECODING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="TEACHER FORCING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER" target="ATTENTION-BASED MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="PROMPT OPTIMIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="PRIORITY QUEUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="ENCODER-DECODER MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="GREEDY DECODING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="SEARCH TREE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="BEAM WIDTH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="HYPOTHESIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="SOFTMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="EOS (END OF SEQUENCE)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="LENGTH NORMALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="BACKTRANSLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="TRANSITION-BASED PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BEAM SEARCH" target="SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MT EVALUATION" target="ADEQUACY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MT EVALUATION" target="FLUENCY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MT EVALUATION" target="HUMAN RATERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MT EVALUATION" target="AUTOMATIC EVALUATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MT EVALUATION" target="POST-EDITING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="DENSE VECTORS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="DOCUMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="MECHANICAL INDEXING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="VECTOR SPACE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="NLP TASKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">54.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="BM25">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="BERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="INVERTED INDEX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="HEAPS’ LAW">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="QUERY">
      <data key="d0">18.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="RELEVANCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="AD HOC RETRIEVAL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INFORMATION RETRIEVAL (IR)" target="NEURAL RETRIEVERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DENSE VECTORS" target="EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DENSE VECTORS" target="VOCABULARY MISMATCH PROBLEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DENSE VECTORS" target="LATENT SEMANTIC INDEXING (LSI)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DENSE VECTORS" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="HALLUCINATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="NEURAL MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME-BASED DIALOGUE SYSTEM" target="TEMPLATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FRAME-BASED DIALOGUE SYSTEM" target="FRAME">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME-BASED DIALOGUE SYSTEM" target="GUS SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FRAME-BASED DIALOGUE SYSTEM" target="DIALOGUE-STATE ARCHITECTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FRAME-BASED DIALOGUE SYSTEM" target="SLOT FILLING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME-BASED DIALOGUE SYSTEM" target="DATABASE QUERY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE ACTS" target="DIALOGUE STATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE ACTS" target="DIALOGUE POLICY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE ACTS" target="SPEECH ACTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE ACTS" target="GROUNDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE ACTS" target="HIS SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE STATE" target="DIALOGUE STATE TRACKING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FEATURE EXTRACTION" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FEATURE EXTRACTION" target="LOG MEL SPECTRUM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE EXTRACTION" target="ACOUSTIC FEATURE VECTORS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="ALIGNMENT">
      <data key="d0">17.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="BLANK SYMBOL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="CTC LOSS FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="SOFTMAX">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="ENCODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="DECODER">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="VITERBI BEAM SEARCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="RNN-T">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="INFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="FORWARD-BACKWARD ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)" target="SEQUENCE TRANSDUCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ERROR RATE (WER)" target="ALIGNMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ERROR RATE (WER)" target="SCLITE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ERROR RATE (WER)" target="MAPSSWE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WORD ERROR RATE (WER)" target="ASR SYSTEMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAMED-ENTITY TAGGING" target="FINETUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED-ENTITY TAGGING" target="WORD TYPES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELDS" target="PART-OF-SPEECH TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELDS" target="LOG-LINEAR MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELDS" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TREEBANK" target="PART-OF-SPEECH TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TREEBANK" target="SYNTACTIC PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TREEBANK" target="PENN TREEBANK">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TREEBANK" target="PARSEVAL METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TREEBANK" target="TRAINING ORACLE">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TREEBANK" target="PARSER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TREEBANK" target="TRANSITION-BASED PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TREEBANK" target="GRAPH-BASED PARSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TREEBANK" target="PART-OF-S(&quot;ENTITY&quot;">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CKY PARSING" target="CHOMSKY NORMAL FORM (CNF)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CKY PARSING" target="STRUCTURAL AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CKY PARSING" target="DYNAMIC PROGRAMMING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CKY PARSING" target="SYNTACTIC DISAMBIGUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CKY PARSING" target="CNF (CHOMSKY NORMAL FORM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CKY PARSING" target="NEURAL CKY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CKY PARSING" target="PARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CKY PARSING" target="GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CKY PARSING" target="PROBABILISTIC PARSERS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CKY PARSING" target="UNIT PRODUCTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPAN-BASED NEURAL CONSTITUENCY PARSING" target="NEURAL CONSTITUENCY PARSERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY RELATION" target="REFERENCE PARSE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="GRAPH-BASED DEPENDENCY PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="SHIFT-REDUCE PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="STACK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="BUFFER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="ORACLE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="ARC STANDARD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="CONFIGURATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSITION-BASED DEPENDENCY PARSING" target="PARSING AS LANGUAGE MODELING (PALM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRAPH-BASED DEPENDENCY PARSING" target="MAXIMUM SPANNING TREE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="GRAPH-BASED DEPENDENCY PARSING" target="NON-PROJECTIVE TREES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="ACE RELATION EXTRACTION TASK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="TACRED">
      <data key="d0">1.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="TACRED DATASET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="SEMEVAL 2010 TASK 8">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="HEARST PATTERNS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="SUPERVISED LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="NEURAL SUPERVISED RELATION CLASSIFIERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="HAND-BUILT PATTERNS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="NER TAGS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="SEMI-SUPERVISED LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="UNSUPERVISED APPROACHES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="DISTANT SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RELATION EXTRACTION" target="ROLE-FILLER EXTRACTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT EXTRACTION" target="LIGHT VERBS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EVENT EXTRACTION" target="TEMPORAL PROPERTIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT EXTRACTION" target="IOB SEQUENCE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT EXTRACTION" target="MULTI-CLASS CLASSIFIERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT EXTRACTION" target="FEATURE-BASED MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT LEXICONS" target="SENTIMENT ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT LEXICONS" target="GENERAL INQUIRER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="TEXT CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="BINARY CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="NEGATION HANDLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="FEEDFORWARD NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="TASK PERFORMANCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="FEW-SHOT LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="TASK TEMPLATES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="ATTITUDE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="AFFECTIVE LEXICONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="VALENCE-AROUSAL-DOMINANCE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="NAIVE BAYES CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="SEED WORDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="THESAURUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="SUPERVISED CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="NAIVE BAYES ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="SENTIWORDNET 3.0">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="NATURAL LANGUAGE PROCESSING TOOLKIT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="OPINION MINING AND SENTIMENT ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTIMENT ANALYSIS" target="TEXT CATEGORIZATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFFERENCE RESOLUTION" target="MENTIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFFERENCE RESOLUTION" target="ILLINOIS-COREF">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COREFFERENCE RESOLUTION" target="WINOGRAD SCHEMA CHALLENGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFFERENCE RESOLUTION" target="CENTERING THEORY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFFERENCE RESOLUTION" target="MACHINE LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="CROSS-ENTROPY LOSS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="MULTI-LAYER PERCEPTRONS (MLP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="NEURAL LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="BIAFFINE PARSER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="PARSER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="MENTION SCORE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="ANTECEDENT SCORE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="ENCODER-DECODER ARCHITECTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEEDFORWARD NETWORK" target="LOCAL COHERENCE DISCRIMINATOR (LCD)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="EMBEDDING" target="REPRESENTATION LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMBEDDING" target="SKIP-GRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMBEDDING" target="VOCABULARY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="FASTTEXT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="GLOVE">
      <data key="d0">10.0</data>
    </edge>
    <edge source="EMBEDDING" target="HISTORICAL SEMANTICS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="EMBEDDING" target="HAND-DESIGNED FEATURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMBEDDING" target="POOLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="PRETRAINING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMBEDDING" target="FEEDFORWARD NEURAL LANGUAGE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMBEDDING" target="NEURAL LANGUAGE MODELS">
      <data key="d0">36.0</data>
    </edge>
    <edge source="EMBEDDING" target="DENSIFIER ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="DOT PRODUCT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="LATENT SPACE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING" target="MENTION SPAN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ELIZA" target="ROGERIAN PSYCHOTHERAPIST">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ELIZA" target="PATTERN MATCHING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ELIZA" target="USER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ELIZA" target="SUBSTITUTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ELIZA" target="ROGERIAN PSYCHOLOGY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ELIZA" target="NATURAL LANGUAGE QUESTION ANSWERING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONVERSATIONAL AGENTS" target="PERSONALITY TRAITS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CORPUS" target="BROWN CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CORPUS" target="SWITCHBOARD CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="LEMMATIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="STEMMING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="UNIX TOOLS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="SPELLING CORRECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="TEXT PREPROCESSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="TEXT SEGMENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="TEXT-TO-SPEECH (TTS) SYSTEMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="SEMIOTIC CLASS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="RULE-BASED NORMALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="ENCODER-DECODER MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="NON-STANDARD WORDS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="VERBALIZATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="KAGGLE TEXT NORMALIZATION CHALLENGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="SPEECH APPLICATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT NORMALIZATION" target="STOP WORDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STEMMING" target="PORTER STEMMER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STEMMING" target="PORTER ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STEMMING" target="MORPHOLOGICAL PARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STEMMING" target="AFFIX-STRIPPING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="STEMMING" target="STEMMING ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ANCHOR" target="CANDIDATE ANNOTATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GREEDY MATCHING" target="BERTSCORE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBSTITUTION" target="LOOKAHEAD ASSERTIONS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SUBSTITUTION" target="ELIZA ARCHITECTURE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOOKAHEAD ASSERTIONS" target="NEGATIVE LOOKAHEAD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ELIZA ARCHITECTURE" target="EXERCISE 2.3">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ELIZA ARCHITECTURE" target="CHAPTER 15">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BROWN CORPUS" target="PART-OF-SPEECH TAGGING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BROWN CORPUS" target="TAG-LABELED TRAINING CORPORA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SWITCHBOARD CORPUS" target="DISFLUENCIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISFLUENCIES" target="SPEAKER IDENTIFICATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD TYPES" target="WORD INSTANCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD TYPES" target="HERDAN'S LAW">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD INSTANCES" target="HERDAN'S LAW">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEMMA" target="WORDFORM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEMMA" target="WORD SENSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEMMA" target="WORDNET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NLP ALGORITHMS" target="AFRICAN AMERICAN ENGLISH (AAE)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BPE ALGORITHM" target="SUBWORD TOKENIZATION">
      <data key="d0">17.0</data>
    </edge>
    <edge source="AFRICAN AMERICAN ENGLISH (AAE)" target="MAINSTREAM AMERICAN ENGLISH (MAE)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFRICAN AMERICAN ENGLISH (AAE)" target="TRAINING CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PUNCTUATION" target="PART-OF-SPEECH TAGGING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PUNCTUATION" target="SPEECH SYNTHESIS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">24.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">34.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="UNIVERSAL DEPENDENCIES TAGSET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="PENN TREEBANK TAGSET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="AMBIGUITY RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="MOST FREQUENT CLASS BASELINE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="UNIVERSAL DEPENDENCY (UD) TREEBANK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="WSJ CORPUS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="UNAMBIGUOUS WORDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="AMBIGUOUS WORDS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="TAG AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="SEQUENCE LABELER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="BIGRAM TAGGER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="NAMED ENTITY RECOGNITION (NER)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="UNIVERSAL DEPENDENCIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="MORPHOLOGICALLY RICH LANGUAGES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="SEQUENCE MODELING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PART-OF-SPEECH TAGGING" target="SYNTACTIC RECOGNITION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="TEXT-TO-SPEECH SYSTEMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="SPEECH ANALYSIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="VOCAL CORDS AND VOCAL TRACT">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="HUMAN-MACHINE INTERACTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="DYNAMIC PROGRAMMING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="TEXT-TO-SPEECH SYNTHESIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIS" target="END-TO-END SPEECH PROCESSING">
      <data key="d0">27.0</data>
    </edge>
    <edge source="AFRICAN AMERICAN VERNACULAR ENGLISH" target="CODE SWITCHING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFRICAN AMERICAN VERNACULAR ENGLISH" target="TWITTER POSTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AFRICAN AMERICAN VERNACULAR ENGLISH" target="CORPUS OF REGIONAL AFRICAN AMERICAN LANGUAGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GENRE" target="DEMOGRAPHIC CHARACTERISTICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE CHANGE" target="DATASHEET">
      <data key="d0">6.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="BIO TAGGING">
      <data key="d0">32.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="SEQUENCE LABELER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">20.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="ONTO NOTES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="RULE-BASED METHODS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="F1 MEASURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="PAIRED BOOTSTRAP TEST">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="RANDOMIZATION TEST">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="TRANSITION-BASED SEMANTIC ROLE LABELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="MAXIMUM ENTROPY MARKOV MODELS (MEMM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="GEO-POLITICAL ENTITY (GPE)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="TEMPORAL EXPRESSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="NUMERICAL EXPRESSIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAMED ENTITY RECOGNITION (NER)" target="GAZETTEER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FINITE STATE AUTOMATA" target="DETERMINISTIC ALGORITHMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD TOKENIZATION" target="CHINESE WORD SEGMENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHINESE WORD SEGMENTATION" target="HANZI">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BYTE-PAIR ENCODING (BPE)" target="SUBWORD TOKENIZATION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="BYTE-PAIR ENCODING (BPE)" target="SENTENCEPIECE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BYTE-PAIR ENCODING (BPE)" target="ALGORITHM">
      <data key="d0">16.0</data>
    </edge>
    <edge source="BYTE-PAIR ENCODING (BPE)" target="FOUNDATION MODEL">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="TOKEN LEARNER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="TOKEN SEGMENTER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="MORPHEME">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="UNIGRAM LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="UNKNOWN WORD PROBLEM">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="TEST SET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="SENTENCEPIECE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="WORDPIECE ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBWORD TOKENIZATION" target="UNIGRAM TOKENIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCEPIECE" target="UNIGRAM LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCEPIECE" target="XLM-ROBERTA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKEN SEGMENTER" target="TRAINING DATA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MORPHEME" target="MORPHOLOGICAL PARSER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MORPHEME" target="STEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHEME" target="AFFIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHEME" target="MORPHOLOGICAL TYPOLOGY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE" target="STRING SIMILARITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE" target="ALIGNMENT PATH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE" target="LEVENSHTEIN DISTANCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE" target="VITERBI ALGORITHM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE" target="STRING COMPARISON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRAINING DATA" target="TEST DATA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING DATA" target="TAY CHATBOT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRAINING DATA" target="TOXICITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRAINING DATA" target="BIAS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRAINING DATA" target="FEW-SHOT LEARNERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING DATA" target="PRETRAINER'S GUIDE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEVENSHTEIN DISTANCE" target="MINIMUM EDIT DISTANCE ALGORITHM">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LEVENSHTEIN DISTANCE" target="COST">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="MINIMUM EDIT DISTANCE ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="TABLE-DRIVEN METHOD">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="VITERBI ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="CKY ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="BACKPOINTER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="BACKTRACE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="DYNAMIC PROGRAMMING MATRIX">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="ALIGNMENT ALGORITHM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="COMPUTATIONAL FIELDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING" target="SPEECH DISCRIMINATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE ALGORITHM" target="ALIGNMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINIMUM EDIT DISTANCE ALGORITHM" target="SEARCH TASK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="PROBABILITY ALIGNMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">18.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="DECODE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="LINEAR-CHAIN CRF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="HMM TAGGING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="CRF TAGGING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="BIGRAM HMM TAGGER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VITERBI ALGORITHM" target="TRANSITION PROBABILITY">
      <data key="d0">18.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="NEURAL SPAN-BASED PARSER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="METRICS FOR EVALUATING PARSER ACCURACY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="CHOMSKY NORMAL FORM (CNF)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="CHART PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="PARSE TREE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="FENCEPOSTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CKY ALGORITHM" target="DYNAMIC PROGRAMMING PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT PREPROCESSING" target="CORPUS INTERFACES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEXT SEGMENTATION" target="TEXT PROCESSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="BIGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="TRIGRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM" target="MARKOV ASSUMPTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM" target="PERPLEXITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM" target="UNIGRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM" target="MARKOV CHAIN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM" target="CLASS-BASED N-GRAM MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM" target="SRILM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="KENLM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="NEURAL LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM" target="MARKOV">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="SHANNON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="JELINEK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="BAKER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM" target="FREQUENCY ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD PREDICTION" target="TEXT SUMMARIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD PREDICTION" target="GREEDY DECODING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="WORD PREDICTION" target="POSITIVE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD PREDICTION" target="NEGATIVE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRAINING SET" target="TEST SET">
      <data key="d0">15.0</data>
    </edge>
    <edge source="TRAINING SET" target="DEVSET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRAINING SET" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING SET" target="SUPERVISED CLASSIFIER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRAINING SET" target="TRANSFER LEARNING">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TEST SET" target="DEVELOPMENT SET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEST SET" target="TRAINING CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEST SET" target="BOOTSTRAP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEST SET" target="CLASSIFIER A">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEST SET" target="CLASSIFIER B">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PERPLEXITY" target="INTRINSIC EVALUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PERPLEXITY" target="PROBABILITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PERPLEXITY" target="CROSS-ENTROPY RATE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PERPLEXITY" target="BRANCHING FACTOR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PERPLEXITY" target="ENTROPY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PERPLEXITY" target="CROSS-ENTROPY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PERPLEXITY" target="FINETUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PERPLEXITY" target="NLP TASKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PERPLEXITY" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SAMPLING" target="TEXT GENERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SAMPLING" target="QUANTIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SAMPLING" target="NYQUIST FREQUENCY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIGRAM" target="N-GRAM MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIGRAM" target="ADD-ONE SMOOTHING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIGRAM" target="STUPID BACKOFF">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BIGRAM" target="TRIGRAM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRIGRAM" target="N-GRAM MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRIGRAM" target="LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MARKOV ASSUMPTION" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATION (MLE)" target="PROBABILITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATION (MLE)" target="BIGRAM PROBABILITIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATION (MLE)" target="RELATIVE FREQUENCY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATION (MLE)" target="HMM TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILITY" target="CHAIN RULE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROBABILITY" target="SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHAIN RULE" target="DERIVATIVE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHAIN RULE" target="ERROR BACKPROPAGATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHAIN RULE" target="BACKWARD PASS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHAIN RULE" target="BACKPROPAGATION THROUGH TIME">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL LARGE LANGUAGE MODELS" target="TRANSFORMER ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIGRAM PROBABILITIES" target="N-GRAM MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIGRAM PROBABILITIES" target="BERKELEY RESTAURANT PROJECT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BIGRAM PROBABILITIES" target="BIGRAM COUNTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIGRAM PROBABILITIES" target="UNIGRAM COUNTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="LOG PROBABILITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="TRIGRAM MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="SUFFIX ARRAYS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="QUANTIZATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="REVERSE TRIES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="CORPUS OF CONTEMPORARY AMERICAN ENGLISH (COCA)">
      <data key="d0">6.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="GOOGLE WEB 5-GRAM CORPUS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="GOOGLE BOOKS NGRAMS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="INFINI-GRAM (¥-GRAM) PROJECT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="UNIGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="N-GRAM MODELS" target="PSEUDO-SHAKESPEARE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LOG PROBABILITY" target="CHAIN RULE OF PROBABILITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUANTIZATION" target="PCM (PULSE CODE MODULATION)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="KENLM" target="MERGE SORTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTROPY" target="CROSS-ENTROPY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTROPY" target="SHANNON-MCMILLAN-BREIMAN THEOREM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTROPY" target="PROBABILITY FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTROPY" target="RANDOM VARIABLE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTROPY" target="INFORMATION THEORY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EXTRINSIC EVALUATION" target="INTRINSIC EVALUATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="EXTRINSIC EVALUATION" target="VECTOR MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INTRINSIC EVALUATION" target="VECTOR MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INTRINSIC EVALUATION" target="SIMLEX-999">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INTRINSIC EVALUATION" target="TOEFL DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INTRINSIC EVALUATION" target="STANFORD CONTEXTUAL WORD SIMILARITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INTRINSIC EVALUATION" target="WORD-IN-CONTEXT DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INTRINSIC EVALUATION" target="SEMANTIC TEXTUAL SIMILARITY TASK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WALL STREET JOURNAL (WSJ)" target="TRAINING CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="OVERFITTING" target="SHAKESPEARE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TRAINING CORPUS" target="NIGERIAN PIDGIN">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRAINING CORPUS" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LAPLACE SMOOTHING" target="NAIVE BAYES CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LAPLACE SMOOTHING" target="WORD COUNTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LAPLACE SMOOTHING" target="POINTWISE MUTUAL INFORMATION (PMI)">
      <data key="d0">14.0</data>
    </edge>
    <edge source="ZERO PROBABILITY" target="MAXIMUM LIKELIHOOD ESTIMATE (MLE)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATE (MLE)" target="NAIVE BAYES CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATE (MLE)" target="WORD COUNTS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATE (MLE)" target="A TRANSITION PROBABILITIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM LIKELIHOOD ESTIMATE (MLE)" target="B EMISSION PROBABILITIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ADD-ONE SMOOTHING" target="ADD-K SMOOTHING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="STUPID BACKOFF" target="DISCOUNT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY" target="BERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SHANNON-MCMILLAN-BREIMAN THEOREM" target="STATIONARY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SHANNON-MCMILLAN-BREIMAN THEOREM" target="EROGDIC">
      <data key="d0">1.0</data>
    </edge>
    <edge source="RANDOM VARIABLE" target="STOCHASTIC PROCESS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATIONARY" target="MARKOV MODELS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="STATIONARY" target="STOCHASTIC PROCESS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EROGDIC" target="STOCHASTIC PROCESS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SMOOTHING ALGORITHMS" target="ADD-1 SMOOTHING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SMOOTHING ALGORITHMS" target="GOOD-TURING DISCOUNTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMOOTHING ALGORITHMS" target="WITTEN-BELL DISCOUNTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMOOTHING ALGORITHMS" target="MODIFIED INTERPOLATED KNESER-NEY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ADD-1 SMOOTHING" target="LAPLACE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ADD-1 SMOOTHING" target="JEFFREYS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ADD-1 SMOOTHING" target="GALE AND CHURCH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ADD-1 SMOOTHING" target="MULTINOMIAL NAIVE BAYES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GOOD-TURING DISCOUNTING" target="KATZ">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MODIFIED INTERPOLATED KNESER-NEY" target="CHEN AND GOODMAN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MARKOV CHAIN" target="MACHINE TRANSLATION RESEARCH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MARKOV CHAIN" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MARKOV CHAIN" target="INITIAL PROBABILITY DISTRIBUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="TRANSFORMER-BASED LARGE LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="FEEDFORWARD LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="RECURRENT LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="SKIP-GRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="CBOW (CONTINUOUS BAG OF WORDS)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="NEGATIVE SAMPLING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="EMBEDDING MATRIX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="VOCABULARY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="WORD PREDICTOR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL LANGUAGE MODELS" target="GPT-3">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MARKOV" target="CHOMSKY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEEDFORWARD LANGUAGE MODELS" target="BENGIO">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEEDFORWARD LANGUAGE MODELS" target="SCHWENK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT LANGUAGE MODELS" target="MIKOLOV">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="FEATURE SELECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="PROMPT ENGINEERING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="BAG-OF-WORDS ASSUMPTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="NAIVE BAYES APPROACH">
      <data key="d0">18.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="UNKNOWN WORD">
      <data key="d0">14.0</data>
    </edge>
    <edge source="TEXT CATEGORIZATION" target="TOPIC MODELS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SPAM DETECTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="LANGUAGE ID">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="AUTHORSHIP ATTRIBUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SUPERVISED MACHINE LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="FEATURE SELECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="LATENT DIRICHLET ALLOCATION (LDA)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BINARY CLASSIFICATION" target="CONFUSION MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPAM DETECTION" target="SPAMASSASSIN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE ID" target="CHARACTER N-GRAMS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LANGUAGE ID" target="FEATURE SELECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE ID" target="MULTILINGUAL TEXT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE ID" target="TWITTER TEXT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE ID" target="URBAN DICTIONARY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="NAIVE BAYES CLASSIFIER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="DISCRIMINATIVE CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="MUC CONFERENCES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="ACE EVALUATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="NEURAL ARCHITECTURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="PRETRAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="RANDOM SAMPLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="RELU">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="REPRESENTATION LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED MACHINE LEARNING" target="RESOURCE MANAGEMENT">
      <data key="d0">6.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="BAG-OF-WORDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="BAYESIAN INFERENCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="PROBABILISTIC CLASSIFIER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="GENERATIVE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="BAG-OF-WORDS ASSUMPTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="NAIVE BAYES ASSUMPTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES CLASSIFIER" target="LINEAR CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCRIMINATIVE CLASSIFIER" target="GENERATIVE CLASSIFIER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="GENERATIVE MODEL" target="CLASSIFICATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CLASSIFICATION" target="STOP WORDS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CLASSIFICATION" target="SOFTMAX FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CLASSIFICATION" target="MULTINOMIAL CLASSIFICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STOP WORDS" target="VOCABULARY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PRIOR PROBABILITY" target="LIKELIHOOD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRIOR PROBABILITY" target="DOCUMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRIOR PROBABILITY" target="MENTION DISAMBIGUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRIOR PROBABILITY" target="CANDIDATE ANNOTATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LIKELIHOOD" target="FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LIKELIHOOD" target="NAIVE BAYES MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LIKELIHOOD" target="PRIOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LIKELIHOOD" target="WORD SENTIMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOCUMENT" target="FEATURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DOCUMENT" target="VOCABULARY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DOCUMENT" target="TERM-DOCUMENT MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOCUMENT" target="WORD VECTOR">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DOCUMENT" target="COLLECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURES" target="WORD COUNTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURES" target="WEIGHT VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINEAR CLASSIFIER" target="ENCODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VOCABULARY" target="UNKNOWN WORD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VOCABULARY" target="ONE-HOT VECTOR">
      <data key="d0">1.0</data>
    </edge>
    <edge source="VOCABULARY" target="PROBABILITY DISTRIBUTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="VOCABULARY" target="LANGUAGE MODELING HEAD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VOCABULARY" target="DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNKNOWN WORD" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEATURE SELECTION" target="CHI-SQUARED (Χ²)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE SELECTION" target="POINTWISE MUTUAL INFORMATION (PMI)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE SELECTION" target="GINI INDEX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIGRAM LANGUAGE MODEL" target="NAIVE BAYES MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BAYES MODEL" target="NAIVE BAYES MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAIVE BAYES MODEL" target="PRIOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POSITIVE CLASS" target="NEGATIVE CLASS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONFUSION MATRIX" target="GOLD LABELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONFUSION MATRIX" target="MULTI-CLASS CLASSIFICATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CONFUSION MATRIX" target="BIGRAM HMM TAGGER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MICROAVERAGING" target="MACROAVERAGING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRUE NEGATIVE" target="ACCURACY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACCURACY" target="HUMAN PERFORMANCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NULL HYPOTHESIS" target="P-VALUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="P-VALUE" target="CLASSIFIER A">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BOOTSTRAP" target="VIRTUAL TEST SET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BOOTSTRAP" target="SAMPLING DISTRIBUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BOOTSTRAP" target="STATISTICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REPRESENTATIONAL HARM" target="TOXICITY DETECTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REPRESENTATIONAL HARM" target="WORD EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOXICITY DETECTION" target="SAFETY FILTERING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MODEL CARD" target="STATISTICAL SIGNIFICANCE TESTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MULTINOMIAL NAIVE BAYES" target="BINARY MULTINOMIAL NAIVE BAYES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTINOMIAL NAIVE BAYES" target="MULTIVARIATE BERNOULLI NAIVE BAYES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="POINTWISE MUTUAL INFORMATION (PMI)" target="PHRASE-BASED TRANSLATION">
      <data key="d0">5.0</data>
    </edge>
    <edge source="POINTWISE MUTUAL INFORMATION (PMI)" target="CO-OCCURRENCE MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POINTWISE MUTUAL INFORMATION (PMI)" target="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POINTWISE MUTUAL INFORMATION (PMI)" target="WORD ASSOCIATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POINTWISE MUTUAL INFORMATION (PMI)" target="POTTS SCORE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FEATURE REPRESENTATION" target="CLASSIFICATION FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OBJECTIVE FUNCTION" target="STOCHASTIC GRADIENT DESCENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STOCHASTIC GRADIENT DESCENT" target="CROSS-ENTROPY LOSS">
      <data key="d0">17.0</data>
    </edge>
    <edge source="STOCHASTIC GRADIENT DESCENT" target="HYPERPARAMETER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="STOCHASTIC GRADIENT DESCENT" target="MINI-BATCH TRAINING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="STOCHASTIC GRADIENT DESCENT" target="LOSS FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STOCHASTIC GRADIENT DESCENT" target="SKIP-GRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STOCHASTIC GRADIENT DESCENT" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="CONDITIONAL MAXIMUM LIKELIHOOD ESTIMATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="NEGATIVE LOG LIKELIHOOD LOSS">
      <data key="d0">17.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="MINI-BATCH TRAINING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="MULTINOMIAL LOGISTIC REGRESSION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="ONE-HOT VECTOR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="DECODER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="SELF-SUPERVISED TRAINING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="MASKED LANGUAGE MODELING (MLM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="NEXT SENTENCE PREDICTION (NSP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="SOFTMAX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="ENCODER-DECODER MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="COLBERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="NEURAL CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="EDGE-SCORER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="LOSS FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CROSS-ENTROPY LOSS" target="RST DISCOURSE PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DECISION BOUNDARY" target="HYPERPLANE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT CLASSIFICATION" target="MOVIE REVIEW">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SENTIMENT CLASSIFICATION" target="SEQUENCE CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTIMENT CLASSIFICATION" target="SENTIMENT PROMPT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOGIT" target="DOT PRODUCT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOGIT" target="SOFTMAX FUNCTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WEIGHT" target="BIAS TERM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT" target="PARAMETERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WEIGHT" target="GRADIENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WEIGHT" target="LOSS FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WEIGHT" target="BIAS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT" target="BILINEAR MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WEIGHT" target="FEATURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT" target="POSITIVE LEXICON WORDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WEIGHT" target="NEGATIVE LEXICON WORDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WEIGHT" target="PARAMETER VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIAS TERM" target="NEURAL UNIT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DOT PRODUCT" target="VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOT PRODUCT" target="VECTOR LENGTH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOT PRODUCT" target="LOGISTIC FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOT PRODUCT" target="SOFTMAX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DOT PRODUCT" target="QUERY, KEY, VALUE MATRICES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="POSITIVE SENTIMENT" target="NEGATIVE SENTIMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE" target="PERIOD DISAMBIGUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE" target="REPRESENTATION LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FEATURE" target="SCALING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE" target="FEATURE INTERACTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE" target="FEATURE TEMPLATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PERIOD DISAMBIGUATION" target="EOS (END-OF-SENTENCE)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PERIOD DISAMBIGUATION" target="NOT-EOS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REPRESENTATION LEARNING" target="BENGIO ET AL.">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REPRESENTATION LEARNING" target="FEATURE ENGINEERING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REPRESENTATION LEARNING" target="NEURAL COHERENCE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCALING" target="STANDARDIZE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCALING" target="NORMALIZE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE TEMPLATE" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE TEMPLATE" target="FEATURE-BASED CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POSITIVE LEXICON WORDS" target="SENTIMENT DECISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEGATIVE LEXICON WORDS" target="SENTIMENT DECISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STANDARDIZE" target="Z-SCORE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="Z-SCORE" target="LOG ODDS RATIO">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT VECTOR" target="WEIGHT MATRIX">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="SOFTMAX FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="ONE-HOT VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="WEIGHT MATRIX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="HARD CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="SOFTMAX REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="LOG-LINEAR MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MULTINOMIAL LOGISTIC REGRESSION" target="FEATURE-BASED CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SOFTMAX FUNCTION" target="PROBABILITY DISTRIBUTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ONE-HOT VECTOR" target="EMBEDDING MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT MATRIX" target="HIDDEN UNIT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT MATRIX" target="HIDDEN LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT MATRIX" target="QUERY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT MATRIX" target="KEY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHT MATRIX" target="VALUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOSS FUNCTION" target="COST FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOSS FUNCTION" target="GRADIENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOSS FUNCTION" target="ARGMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOSS FUNCTION" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COST FUNCTION" target="SENTENCE ALIGNMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEARNING RATE" target="HYPERPARAMETER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRADIENT" target="PARAMETER VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRADIENT" target="PARTIAL DERIVATIVE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARAMETER VECTOR" target="BIAS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE VECTOR" target="MACHINE LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINI-BATCH TRAINING" target="BATCH TRAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINI-BATCH TRAINING" target="VECTORIZE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="L2 REGULARIZATION" target="RIDGE REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="L2 REGULARIZATION" target="GAUSSIAN DISTRIBUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="L2 REGULARIZATION" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="L1 REGULARIZATION" target="LASSO REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="L1 REGULARIZATION" target="LAPLACE PRIOR">
      <data key="d0">1.0</data>
    </edge>
    <edge source="L1 REGULARIZATION" target="CONDITIONAL RANDOM FIELD (CRF)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RIDGE REGRESSION" target="REGRESSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LASSO REGRESSION" target="ROGUE DIMENSIONS IN TRANSFORMER MODELS">
      <data key="d0">4.0</data>
    </edge>
    <edge source="SPEECH PROCESSING" target="INTERSPEECH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SMILODON" target="THYLACOSMILUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SMILODON" target="PARALLEL OR CONVERGENT EVOLUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="THYLACOSMILUS" target="PARALLEL OR CONVERGENT EVOLUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARALLEL OR CONVERGENT EVOLUTION" target="GOULD">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL HYPOTHESIS" target="JOOS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL HYPOTHESIS" target="HARRIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL HYPOTHESIS" target="FIRTH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="MASKED LANGUAGE MODELING (MLM)">
      <data key="d0">54.0</data>
    </edge>
    <edge source="BERT" target="FINETUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="WORDPIECE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="SPANBERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="ROBERTA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="NEXT SENTENCE PREDICTION (NSP)">
      <data key="d0">36.0</data>
    </edge>
    <edge source="BERT" target="BOOKSCORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="WORD SENSE DISAMBIGUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="FINE-TUNING">
      <data key="d0">17.0</data>
    </edge>
    <edge source="BERT" target="ELMO">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BERT" target="SEQUENCE CLASSIFICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="NSP OBJECTIVE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="COMET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="BLEURT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="BERTSCORE">
      <data key="d0">17.0</data>
    </edge>
    <edge source="BERT" target="RECALL METRIC RBERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="TRANSFORMER ENCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="NLP TASKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="BI-ENCODER">
      <data key="d0">16.0</data>
    </edge>
    <edge source="BERT" target="TRANSFORMER SELF-ATTENTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="LINEAR LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="COLBERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="ENCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="NEURAL APPROACHES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="SPAN-BASED CONSTITUENCY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="TRANSFORMER LAYERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="NEURAL SUPERVISED RELATION CLASSIFIERS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BERT" target="PRETRAINED ENCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="SPAN REPRESENTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="ELQ LINKING ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="GENDER BIAS IN COREFERENCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BERT" target="TRANSFORMER MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="DEEP NEURAL NETWORKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="NATURAL LANGUAGE PROCESSING TOOLKIT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERT" target="ROBUSTLY OPTIMIZED BERT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BERT" target="DETOXIFYING LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICAL SEMANTICS" target="WORD SENSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICAL SEMANTICS" target="SYNONYMY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICAL SEMANTICS" target="WORD SIMILARITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICAL SEMANTICS" target="WORD RELATEDNESS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICAL SEMANTICS" target="SEMANTIC FIELD">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICAL SEMANTICS" target="SEMANTIC FRAME">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD SENSE" target="WORD SENSE DISAMBIGUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD SENSE" target="POLYSEMY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD SENSE" target="LINGUISTIC STRUCTURE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SYNONYMY" target="WORD SIMILARITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SYNONYMY" target="PRINCIPLE OF CONTRAST">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD SIMILARITY" target="WORD RELATEDNESS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD SIMILARITY" target="SIMLEX-999">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD RELATEDNESS" target="BUDANITSKY AND HIRST">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC FIELD" target="TOPIC MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORDNET" target="POLYSEMY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORDNET" target="WORD SENSE DISAMBIGUATION">
      <data key="d0">17.0</data>
    </edge>
    <edge source="WORDNET" target="RDF">
      <data key="d0">6.0</data>
    </edge>
    <edge source="WORDNET" target="INSTANCE-OF RELATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORDNET" target="DISTANT SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORDNET" target="VERBNET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORDNET" target="SENTIWORDNET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORDNET" target="LEXICAL DATABASE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="LEXICAL DIVERGENCES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="SELECTIONAL PREFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="DISCOURSE CONNECTIVES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="BIO TAGGING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="KNOWLEDGE-BASED WORD SENSE DISAMBIGUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="COMPOSITIONAL CHARACTER MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD SENSE DISAMBIGUATION" target="SEMANTIC SPACES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRINCIPLE OF CONTRAST" target="WORD ASSOCIATION NORMS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PRINCIPLE OF CONTRAST" target="LANGUAGE ACQUISITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SIMLEX-999" target="SEMANTIC RELATIONS">
      <data key="d0">14.0</data>
    </edge>
    <edge source="TOPIC MODELS" target="LATENT DIRICHLET ALLOCATION (LDA)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LATENT DIRICHLET ALLOCATION (LDA)" target="EMBEDDING ALGORITHMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LATENT DIRICHLET ALLOCATION (LDA)" target="DISTANT SUPERVISION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LATENT DIRICHLET ALLOCATION (LDA)" target="SELECTIONAL PREFERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PLEISTOCENE EPOCH" target="ICE AGES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNOTATION" target="AFFECTIVE MEANING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONNOTATION" target="AFFECTIVE LEXICONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONNOTATION" target="CONNOTATION FRAMES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AFFECTIVE MEANING" target="VALENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AFFECTIVE MEANING" target="AROUSAL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AFFECTIVE MEANING" target="DOMINANCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AFFECTIVE MEANING" target="SUBJECTIVITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AFFECTIVE MEANING" target="LITERACY TUTORS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFFECTIVE MEANING" target="COMPUTER GAMES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANTONYMY" target="PARAPHRASE">
      <data key="d0">5.0</data>
    </edge>
    <edge source="PARAPHRASE" target="SEMANTIC ROLES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MERONYMY" target="SEMANTIC ROLES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="HYPERNYMY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="LINGUISTIC STRUCTURE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="THEMATIC ROLE">
      <data key="d0">16.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="CASE FRAMES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="VALENCY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="SYNTAX">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC ROLES" target="STATISTICAL VERB LEXICON">
      <data key="d0">1.0</data>
    </edge>
    <edge source="VECTOR SPACE" target="VECTOR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TERM-TERM MATRIX" target="WORD VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="JULIUS CAESAR" target="AS YOU LIKE IT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="JULIUS CAESAR" target="TWELFTH NIGHT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="JULIUS CAESAR" target="HENRY V">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AS YOU LIKE IT" target="TWELFTH NIGHT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AS YOU LIKE IT" target="HENRY V">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TWELFTH NIGHT" target="HENRY V">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BATTLE" target="FOOL">
      <data key="d0">6.0</data>
    </edge>
    <edge source="GOOD" target="WIT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TERM FREQUENCY (TF)" target="RAW FREQUENCY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TERM FREQUENCY (TF)" target="INVERSE DOCUMENT FREQUENCY (IDF)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INVERSE DOCUMENT FREQUENCY (IDF)" target="DOCUMENT FREQUENCY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INVERSE DOCUMENT FREQUENCY (IDF)" target="BERTSCORE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CO-OCCURRENCE MATRIX" target="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOCUMENT FREQUENCY" target="COLLECTION FREQUENCY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)" target="WORD ASSOCIATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)" target="VECTOR SEMANTICS MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POINTWISE POSITIVE MUTUAL INFORMATION (PPMI)" target="SPARSE VECTOR MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SKIP-GRAM" target="NEGATIVE SAMPLING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEGATIVE SAMPLING" target="NOISE WORD">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEGATIVE SAMPLING" target="LOCAL COHERENCE DISCRIMINATOR (LCD)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR SEMANTICS MODEL" target="SPARSE VECTORS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOCUMENT SIMILARITY" target="CENTROID">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="TRAINING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="COHERENCE MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="NEURAL COHERENCE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="SENTENCE ORDER DISCRIMINATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="SENTENCE INSERTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="SENTENCE ORDER RECONSTRUCTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELF-SUPERVISION" target="COHERENCE ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTROID" target="WORD EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTROID" target="SEMANTIC AXIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FASTTEXT" target="SKIPGRAM EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GLOVE" target="PARALLELOGRAM MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GLOVE" target="VECTOR SPACE MODEL">
      <data key="d0">18.0</data>
    </edge>
    <edge source="GLOVE" target="EMBEDDING ALGORITHMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GLOVE" target="WORD EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GLOVE" target="MULTILINGUAL BERT HAS AN ACCENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GLOVE" target="AUTOMATIC DIFFERENTIATION IN PYTORCH">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TARGET WORD" target="CONTEXT WORD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NOISE WORD" target="UNIGRAM FREQUENCY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIGRAM FREQUENCY" target="WEIGHTING PARAMETER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PARALLELOGRAM MODEL" target="ANALOGY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MULTIDIMENSIONAL SCALING" target="HIERARCHICAL CLUSTERING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MULTIDIMENSIONAL SCALING" target="T-SNE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="FIRST-ORDER CO-OCCURRENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="SECOND-ORDER CO-OCCURRENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="TRANSFORMER BLOCK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="LLAMA 3">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HISTORICAL SEMANTICS" target="GOOGLE N-GRAMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HISTORICAL SEMANTICS" target="CORPUS OF HISTORICAL AMERICAN ENGLISH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CORPUS OF HISTORICAL AMERICAN ENGLISH" target="WIKIPEDIA CORPUS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SGNS VECTORS" target="SEMANTIC CHANGE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="DYNAMIC SOCIAL REPRESENTATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="HISTORICAL EMBEDDINGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="LATENT SEMANTIC ANALYSIS (LSA)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="CO-OCCURRENCE VECTORS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="TEMPORAL TOPIC MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="POINT-WISE MUTUAL INFORMATION-BASED EMBEDDINGS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC CHANGE" target="NEURAL WORD-EMBEDDING METHODS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HISTORICAL EMBEDDINGS" target="GENDER BIAS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="A LATENT SEMANTIC ANALYSIS FRAMEWORK FOR LARGE-SPAN LANGUAGE MODELING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="GRAMMATICAL CATEGORY DISAMBIGUATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="IMPLICIT SEMANTIC ROLE LABELING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="TEXTUAL COHERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="VOCABULARY PROBLEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="CONTEXTUAL SPELLING CORRECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="SINGULAR VALUE DECOMPOSITION (SVD)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="LATENT SEMANTIC ANALYSIS (LSA) EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LATENT SEMANTIC ANALYSIS (LSA)" target="LSA COHERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CO-OCCURRENCE VECTORS" target="DISTANCE VECTORS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="GENDER BIAS">
      <data key="d0">36.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="DEBIASING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">32.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="UNEMBEDDING LAYER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="NEURAL ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="SYNSET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="FINE-TUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="DEBIASING WORD EMBEDDINGS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="CONTEXTUALIZED WORD REPRESENTATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="WORD EMBEDDING ASSOCIATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="GENDER AND ETHNIC STEREOTYPES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="SYMBOL GROUNDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="UNSUPERVISED DISCOVERY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="DISTRIBUTIONAL SEMANTIC MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="NON-NEGATIVE MATRIX FACTORIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD EMBEDDING" target="BIDIRECTIONAL LSTM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GENDER BIAS" target="ALLOCATION HARM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENDER BIAS" target="REDUCING GENDER BIAS IN ABUSIVE LANGUAGE DETECTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC TEXTUAL SIMILARITY TASK" target="ANALOGY TASK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMANTIC TEXTUAL SIMILARITY TASK" target="HUMAN-LABELED SIMILARITY SCORES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMPLICIT ASSOCIATION TEST" target="GLOVE VECTORS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMPLICIT ASSOCIATION TEST" target="SYMBOL GROUNDING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ANALOGY TASK" target="MORPHOLOGY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANALOGY TASK" target="LEXICOGRAPHIC RELATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANALOGY TASK" target="ENCYCLOPEDIA RELATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANALOGY TASK" target="SEMEVAL-2012 TASK 2 DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MORPHOLOGY" target="SEED SETS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MORPHOLOGY" target="KNOWLEDGE-FREE INDUCTION OF MORPHOLOGY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MORPHOLOGY" target="TURKISHAGGLUTINATIVE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMBEDDING ALGORITHMS" target="NON-NEGATIVE MATRIX FACTORIZATION (NMF)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="EMBEDDING ALGORITHMS" target="BOOTSTRAP SAMPLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BOOTSTRAP SAMPLING" target="SENTPROP ALGORITHM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPARSE VECTOR MODELS" target="TF-IDF WEIGHTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MUTUAL INFORMATION" target="WORD ASSOCIATION NORMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SINGULAR VALUE DECOMPOSITION (SVD)" target="PROBABILISTIC LATENT SEMANTIC INDEXING (PLSI)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SINGULAR VALUE DECOMPOSITION (SVD)" target="LATENT SEMANTIC INDEXING (LSI)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SINGULAR VALUE DECOMPOSITION (SVD)" target="SINGULAR VALUE DECOMPOSITION (SVD) EMBEDDING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PROBABILISTIC LATENT SEMANTIC INDEXING (PLSI)" target="READING COMPREHENSION SYSTEM">
      <data key="d0">12.0</data>
    </edge>
    <edge source="DEEP LEARNING" target="NEURAL NETWORK METHODS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEEP LEARNING" target="LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEEP LEARNING" target="NEURAL TURING MACHINES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL UNIT" target="WEIGHTED SUM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL UNIT" target="ACTIVATION FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEIGHTED SUM" target="CONTEXT VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACTIVATION FUNCTION" target="TANH FUNCTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="ACTIVATION FUNCTION" target="RELU FUNCTION">
      <data key="d0">10.0</data>
    </edge>
    <edge source="ACTIVATION FUNCTION" target="ACTIVATION VALUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACTIVATION FUNCTION" target="HIDDEN UNIT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ACTIVATION FUNCTION" target="HIDDEN LAYER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ACTIVATION FUNCTION" target="RELU">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RELU" target="VANISHING GRADIENT PROBLEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RELU" target="RECTIFIED LINEAR TRANSFORMATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="VANISHING GRADIENT PROBLEM" target="TANH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VANISHING GRADIENT PROBLEM" target="SIGMOID">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PERCEPTRON" target="ERROR PROPAGATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PERCEPTRON" target="RECURSIVE NEURAL NETWORKS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ERROR BACKPROPAGATION" target="COMPUTATION GRAPH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ERROR BACKPROPAGATION" target="BACKWARD PASS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="HIDDEN UNIT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="INPUT LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="OUTPUT LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="SOFTMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="FEEDFORWARD NEURAL LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">18.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="WEIGHT MATRIX U">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="WEIGHT MATRIX W">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN LAYER" target="WEIGHT MATRIX V">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN UNIT" target="BIAS VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OUTPUT LAYER" target="SOFTMAX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILITY DISTRIBUTION" target="FEEDFORWARD NEURAL LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILITY DISTRIBUTION" target="SOFTMAX">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROBABILITY DISTRIBUTION" target="SEQUENCE PROBABILITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILITY DISTRIBUTION" target="SAMPLING METHODS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MULTILAYER NETWORK" target="SINGLE LAYER NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIAS UNIT" target="DUMMY NODE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="POOLING" target="SEQUENCE CLASSIFICATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRETRAINING" target="CONTRASTIVE SENTENCE OBJECTIVES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX" target="MULTINOMIAL REGRESSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX" target="FORWARD INFERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SOFTMAX" target="SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SOFTMAX" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SOFTMAX" target="DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX" target="DOT-PRODUCT ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX" target="MULTI-HEAD ATTENTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SOFTMAX" target="UNEMBEDDING LAYER">
      <data key="d0">16.0</data>
    </edge>
    <edge source="SOFTMAX" target="CLASSIFIER HEAD">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SOFTMAX" target="BIO TAGS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SOFTMAX" target="BIAFFINE FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX" target="MAXIMUM SPANNING TREE ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX" target="LINEAR LAYER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COMPUTATION GRAPH" target="FORWARD PASS">
      <data key="d0">30.0</data>
    </edge>
    <edge source="COMPUTATION GRAPH" target="BACKWARD PASS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DROPOUT" target="DEEP NEURAL NETWORKS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="FEEDFORWARD NEURAL LANGUAGE MODEL" target="FORWARD INFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL NET LANGUAGE MODELS" target="SELF-TRAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FORWARD INFERENCE" target="DECODER">
      <data key="d0">6.0</data>
    </edge>
    <edge source="FORWARD INFERENCE" target="ENCODER">
      <data key="d0">6.0</data>
    </edge>
    <edge source="EMBEDDING MATRIX" target="FREEZING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMBEDDING MATRIX" target="RECURRENT NEURAL NETWORKS (RNN)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMBEDDING MATRIX" target="HIDDEN DIMENSION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMBEDDING MATRIX" target="MODEL DIMENSION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMBEDDING MATRIX" target="TOKEN EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMBEDDING MATRIX" target="UNEMBEDDING LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST MODELS" target="COGNITIVE SCIENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTRIBUTED REPRESENTATIONS" target="NEURAL MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTRIBUTED REPRESENTATIONS" target="DEEP BELIEF NETS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="DISTRIBUTED REPRESENTATIONS" target="RECURSIVE NEURAL NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="BACKPROPAGATION THROUGH TIME">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="TEMPORAL DIMENSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="INFERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="TEACHER FORCING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="WEIGHT TYING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="SEQUENCE CLASSIFICATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="SOFTMAX LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="END-TO-END TRAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="STACKED RNN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="BIDIRECTIONAL RNN">
      <data key="d0">16.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="GATED RECURRENT UNIT (GRU)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="DECODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="ENCODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="BPTT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="VANISHING GRADIENTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="PROBABILISTIC LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="AUTO-REGRESSIVE GENERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="ENCODER-DECODER ARCHITECTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="PARALLEL DISTRIBUTED PROCESSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="ELMAN NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="JORDAN NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="CONVOLUTIONAL NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="CONFERENCE ON NATURAL LANGUAGE LEARNING (CONLL)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="SEMEVAL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="ONTONOTES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="PROPBANK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="PHONEME RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="HANDWRITING RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="SYNTACTIC CHUNKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="OPINION MINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="AMR PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="ENTITY-BASED MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="NEURAL MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURRENT NEURAL NETWORKS (RNN)" target="BIDIRECTIONAL LSTM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BACKPROPAGATION THROUGH TIME" target="MEMORY NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INFERENCE" target="KV CACHE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFERENCE" target="IMPLICATURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN DIMENSION" target="MODEL DIMENSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCORE" target="NEURAL CKY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEACHER FORCING" target="DECODER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEACHER FORCING" target="SOFTMAX OUTPUT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEACHER FORCING" target="CE LOSS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEACHER FORCING" target="ENCODER-DECODER MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEACHER FORCING" target="TACOTRON2">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEACHER FORCING" target="TACOTRON 2">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE CLASSIFICATION" target="FINE-TUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE CLASSIFICATION" target="NATURAL LANGUAGE INFERENCE (NLI)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT GENERATION" target="AUTOREGRESSIVE GENERATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEXT GENERATION" target="GENERATIVE AI">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEXT GENERATION" target="BLEURT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT GENERATION" target="BERTSCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUTOREGRESSIVE GENERATION" target="SUMMARIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOREGRESSIVE GENERATION" target="DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOREGRESSIVE GENERATION" target="END-OF-SEQUENCE TOKEN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUMMARIZATION" target="TEMPLATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIDIRECTIONAL RNN" target="TIMIT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="CONTEXT VECTOR">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="TRANSFORMER BLOCK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="CROSS-ATTENTION">
      <data key="d0">16.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="DELEXICALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="MULTIWOZ">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="VERBALIZATION GRAMMAR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER MODEL" target="NEURAL PARSING ALGORITHMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT VECTOR" target="DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT VECTOR" target="ATTENTION MECHANISM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT VECTOR" target="HIDDEN STATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODELING" target="BROADCAST NEWS CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODELING" target="AUTOMATIC QUESTION ANSWERER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DECODER" target="ENCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DECODER" target="HIDDEN STATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DECODER" target="EMBEDDING LAYER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DECODER" target="ENCODER-DECODER NETWORK">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ENCODER" target="SENTENCE SEPARATOR TOKEN">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ENCODER" target="HIDDEN STATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER" target="EMBEDDING LAYER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER" target="BILSTM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER" target="ENCODER-DECODER NETWORK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER" target="BIO TAGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER" target="NEURAL ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER" target="PARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER" target="LINEAR LAYER">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ENCODER" target="HIERARCHICAL BI-LSTMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER" target="FEATURE-BASED MODELS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BILSTM" target="NEURAL ALGORITHM FOR SRL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER APPROACH" target="ATTENTION MECHANISM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ATTENTION MECHANISM" target="DOT-PRODUCT ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTENTION MECHANISM" target="SELF-ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SOFTMAX OUTPUT" target="LOSS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOT-PRODUCT ATTENTION" target="BILINEAR MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DOT-PRODUCT ATTENTION" target="SCORE FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SELF-ATTENTION" target="MULTI-HEAD ATTENTION">
      <data key="d0">17.0</data>
    </edge>
    <edge source="SELF-ATTENTION" target="TRANSFORMER BLOCK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SELF-ATTENTION" target="TRANSFORMER ENCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="CNN ENCODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="RNN DECODER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="ATTENTION-BASED ENCODER DECODER (AED)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="TEXT-TO-SPEECH (TTS) SYSTEMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="LSTMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="LISTEN ATTEND AND SPELL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="BI-LSTM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENCODER-DECODER ARCHITECTURE" target="SHIFT-REDUCE PARSER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARALLEL DISTRIBUTED PROCESSING" target="TRACE MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PARALLEL DISTRIBUTED PROCESSING" target="ERROR PROPAGATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONFERENCE ON NATURAL LANGUAGE LEARNING (CONLL)" target="DEPEND ABLE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMEVAL" target="QA DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEMEVAL" target="SEMANTIC EVALUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ONTONOTES" target="COREFERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ONTONOTES" target="ISNOTES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ONTONOTES" target="SINGLETONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ONTONOTES" target="DISCOURSE STRUCTURE RELATIONS">
      <data key="d0">14.0</data>
    </edge>
    <edge source="PROPBANK" target="FRAMENET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROPBANK" target="VERBNET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROPBANK" target="NOMBANK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PHONEME RECOGNITION" target="TIME-DELAY NEURAL NETWORKS">
      <data key="d0">18.0</data>
    </edge>
    <edge source="OPINION MINING" target="CUSTOMER REVIEWS MINING">
      <data key="d0">18.0</data>
    </edge>
    <edge source="OPINION MINING" target="DEEP RECURRENT NEURAL NETWORKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AMR PARSING" target="SEMANTIC ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AMR PARSING" target="LSTM-BASED RECURRENT NEURAL NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TIMIT" target="DEEP NEURAL NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MULTI-HEAD ATTENTION" target="TRANSFORMER BLOCK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MULTI-HEAD ATTENTION" target="WEIGHT MATRIX WO">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTI-HEAD ATTENTION" target="ATTENTION HEAD">
      <data key="d0">18.0</data>
    </edge>
    <edge source="MULTI-HEAD ATTENTION" target="RESIDUAL STREAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTI-HEAD ATTENTION" target="MASKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTI-HEAD ATTENTION" target="QUERY, KEY, VALUE MATRICES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE MODELING HEAD" target="TRANSFORMER BLOCK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODELING HEAD" target="UNEMBEDDING LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUERY" target="KEY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUERY" target="DOCUMENT 1">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUERY" target="DOCUMENT 2">
      <data key="d0">8.0</data>
    </edge>
    <edge source="KEY" target="VALUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VALUE" target="SPEED">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ROAD" target="CHICKEN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TOKEN" target="LAYER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOKEN" target="RESIDUAL STREAM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="KEY VECTOR" target="QUERY VECTOR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="KEY VECTOR" target="WEIGHT MATRIX WK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUERY VECTOR" target="VALUE VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUERY VECTOR" target="WEIGHT MATRIX WQ">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VALUE VECTOR" target="WEIGHT MATRIX WV">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="RESIDUAL CONNECTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="LAYER NORM">
      <data key="d0">15.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="FEEDFORWARD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="RESIDUAL STREAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="STACKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="PARALLELIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="GPT-3">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="T5">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="LAYER NORMALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="FEEDFORWARD NETWORK (FFN)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="XLM-ROBERTA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSFORMER BLOCK" target="MULTIHEAD ATTENTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RESIDUAL CONNECTIONS" target="LAYER NORM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RESIDUAL CONNECTIONS" target="FEEDFORWARD">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RESIDUAL CONNECTIONS" target="WAVENET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIMENSIONALITY DK" target="MODEL DIMENSIONALITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MODEL DIMENSIONALITY" target="DIMENSIONALITY DV">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARALLELIZATION" target="MATRIX X">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GPT-3" target="BATCH SIZE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GPT-3" target="SCALING LAWS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TOKEN EMBEDDING" target="POSITIONAL EMBEDDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POSITIONAL EMBEDDING" target="ABSOLUTE POSITION EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POSITIONAL EMBEDDING" target="RELATIVE POSITION EMBEDDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DECODER-ONLY MODEL" target="CAUSAL LANGUAGE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNEMBEDDING LAYER" target="LOGIT LENS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CAUSAL LANGUAGE MODEL" target="TRAINING CHATBOTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CAUSAL LANGUAGE MODEL" target="MASKED LANGUAGE MODELING (MLM)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CAUSAL LANGUAGE MODEL" target="LLAMA 3">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL GENERATION" target="TEXT COMPLETION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL GENERATION" target="PROMPT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT" target="LLM (LARGE LANGUAGE MODEL)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROMPT" target="PROMPT ENGINEERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT" target="TEMPLATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT" target="INSTRUCTION-TUNING DATA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="CNN/DAILY MAIL SUMMARIZATION CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT SUMMARIZATION" target="WORD SEGMENTATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SAMPLING METHODS" target="RANDOM SAMPLING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SAMPLING METHODS" target="TOP-K SAMPLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SAMPLING METHODS" target="TOP-P SAMPLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SAMPLING METHODS" target="TEMPERATURE SAMPLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEMPERATURE SAMPLING" target="CANDIDATE TRANSLATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPERATURE SAMPLING" target="BACKTRANSLATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFORMER LANGUAGE MODEL" target="RNN LANGUAGE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CE LOSS" target="TRAINING SEQUENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COMMON CRAWL" target="THE PILE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COMMON CRAWL" target="XLM-R">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WIKIPEDIA" target="THE PILE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WIKIPEDIA" target="NATURAL QUESTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WIKIPEDIA" target="DISTANT SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WIKIPEDIA" target="ONTOLOGY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSLATION" target="TEMPLATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSLATION" target="SENTENCE ALIGNMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="QUALITY FILTERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="SAFETY FILTERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="COPYRIGHT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="DATA CONSENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="PRIVACY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="FINETUNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="INTERNET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="PROSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRETRAINING DATA" target="DIALOGUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="QUALITY FILTERING" target="DE-DUPLICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COPYRIGHT" target="FAIR USE DOCTRINE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DATA CONSENT" target="ROBOTS.TXT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRIVACY" target="EMOTIONAL ENGAGEMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FINETUNING" target="PARAMETER-EFFICIENT FINETUNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FINETUNING" target="SUPERVISED FINETUNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FINETUNING" target="TRANSFER LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FINETUNING" target="NATURAL LANGUAGE INFERENCE (NLI)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FINETUNING" target="DEMONSTRATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MODEL SIZE" target="ENERGY USAGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MODEL SIZE" target="MEMORY CONSTRAINTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="KV CACHE" target="ATTENTION VECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FAIRNESS" target="STEREOSET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FAIRNESS" target="REALTOXICITYPROMPTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FAIRNESS" target="BBQ">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FAIRNESS" target="RAWLSIAN FAIRNESS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DYNABENCH" target="HELM">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LLAMA 3.1 405B INSTRUCT" target="SCALING LAWS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SCALING LAWS" target="LORA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SCALING LAWS" target="COMPUTE BUDGET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCALING LAWS" target="DATASET SIZE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LORA" target="PARAMETER-EFFICIENT FINE TUNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LORA" target="LOW-RANK ADAPTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ATTENTION VECTOR" target="MATRIX MULTIPLICATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ATTENTION VECTOR" target="SPAN REPRESENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARAMETER-EFFICIENT FINE TUNING" target="TASK-BASED FINE TUNING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NLP TASKS" target="GPT2">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODELING (MLM)" target="CLOZE TASK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODELING (MLM)" target="DENOISING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MASKED LANGUAGE MODELING (MLM)" target="BIDIRECTIONAL ENCODERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GPT2" target="AUTOREGRESSIVE LANGUAGE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GPT2" target="ZERO-SHOT LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FOUNDATION MODEL" target="VISION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FOUNDATION MODEL" target="SPEECH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FOUNDATION MODEL" target="GENETICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FOUNDATION MODEL" target="ENERGY AND CARBON FOOTPRINTS">
      <data key="d0">18.0</data>
    </edge>
    <edge source="WORDPIECE" target="BPE (BYTE PAIR ENCODING)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE INFERENCE (NLI)" target="MULTI-GENRE NATURAL LANGUAGE INFERENCE (MULTINLI)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE INFERENCE (NLI)" target="FEW-SHOT LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE INFERENCE (NLI)" target="TASK TEMPLATES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="XLM-ROBERTA" target="SENTENCEPIECE UNIGRAM LM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEXT SENTENCE PREDICTION (NSP)" target="POSITIVE PAIRS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEXT SENTENCE PREDICTION (NSP)" target="RANDOM PAIRS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTILINGUAL MODELS" target="CURSE OF MULTILINGUALITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FINE-TUNING" target="SUPERVISED TRAINING DATA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FINE-TUNING" target="TRAINING CHATBOTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FINE-TUNING" target="INSTRUCT TUNING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ELMO" target="GENDER BIAS IN COREFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMCORE" target="SENSEEVAL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BIO TAGGING" target="BIOES TAGGING">
      <data key="d0">15.0</data>
    </edge>
    <edge source="BIO TAGGING" target="SLOT FILLING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BIO TAGGING" target="IO TAGGING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BIO TAGGING" target="NEURAL ALGORITHM FOR SRL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPORAL EXPRESSION" target="TEMPORAL LOGIC">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPORAL EXPRESSION" target="FOL TRANSLATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPORAL EXPRESSION" target="EVENT PLANNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEMPORAL EXPRESSION" target="NEWS TEXT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPORAL EXPRESSION" target="TEXT ANNOTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEMPORAL EXPRESSION" target="TEMPORAL NORMALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED TRAINING DATA" target="TASK TEMPLATES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CLASSIFIER HEAD" target="CLS TOKEN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CLASSIFIER HEAD" target="LOGISTIC CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PREMISE" target="HYPOTHESIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HYPOTHESIS" target="FRONTIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="FORWARD-BACKWARD ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="LINEAR-CHAIN CRF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="FEATURE FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="WORD SHAPE FEATURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="POS TAGGER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="KNOWN-WORD TEMPLATES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="UNKNOWN-WORD FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONDITIONAL RANDOM FIELD (CRF)" target="PART-OF-SPEECH (POS)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PREFERENCE ALIGNMENT" target="SAFETY TRAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PREFERENCE ALIGNMENT" target="RLHF (REINFORCEMENT LEARNING FROM HUMAN FEEDBACK)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PREFERENCE ALIGNMENT" target="DPO (DIRECT POLICY OPTIMIZATION)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="F1 MEASURE" target="BERTSCORE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT ENGINEERING" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROMPT ENGINEERING" target="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEMPLATE" target="TEMPLATE FILLING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEMPLATE" target="SCRIPT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEMPLATE" target="ACTIVITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEMPLATE" target="ENTITIES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEMPLATE" target="AMOUNT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEMPLATE" target="SUPER NATURAL INSTRUCTIONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEMPLATE" target="INSTRUCTION-TUNING DATA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEMONSTRATIONS" target="FEW-SHOT PROMPTING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEMONSTRATIONS" target="DSPY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEMONSTRATIONS" target="TASK PERFORMANCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEW-SHOT PROMPTING" target="ZERO-SHOT PROMPTING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEW-SHOT PROMPTING" target="ZERO-SHOT SETTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DANGEROUSLY IN LOVE" target="BEYONCÉ">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DANGEROUSLY IN LOVE" target="GRAMMY AWARDS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DANGEROUSLY IN LOVE" target="BILLBOARD HOT 100">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SQUAD 2.0 DATASET" target="NATURAL INSTRUCTIONS DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TASK PERFORMANCE" target="MULTIPLE-CHOICE QUESTION ANSWERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TASK PERFORMANCE" target="ROUGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INDUCTION HEADS" target="LLAMA-3-8B">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INDUCTION HEADS" target="INTERNLM2-20B">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INDUCTION HEADS" target="NEEDLE-IN-THE-HAYSTACK TASK">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INDUCTION HEADS" target="ABLATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHRF" target="BLEU">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHRF" target="F-SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHRF" target="BERTSCORE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CHRF" target="PIONEERING WORK OF MILLER AND BEEBE-CENTER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CHRF" target="PAIRED BOOTSTRAP TEST">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHRF" target="RANDOMIZATION TEST">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PREFIX MATCHING MECHANISM" target="COPYING MECHANISM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GEHMAN ET AL. (2020)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="CHENG ET AL. (2023)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="BROWN ET AL. (2020)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="SHENG ET AL. (2019)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OLSSON ET AL. (2022)" target="CROSBIE AND SHUTOVA (2022)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANNOTATOR SKEW" target="AYA DATASET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AYA DATASET" target="MALAGASY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AYA DATASET" target="KURDISH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AYA DATASET" target="SINDHI">
      <data key="d0">6.0</data>
    </edge>
    <edge source="AYA DATASET" target="ANNOTATORS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AYA DATASET" target="MULTILINGUAL INSTRUCTION TUNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SQUAD DATASET" target="SUPER NATURAL INSTRUCTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPER NATURAL INSTRUCTIONS" target="TASK CLUSTERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEW-SHOT LEARNING" target="EXTRACTIVE QUESTION ANSWERING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FEW-SHOT LEARNING" target="TRAINING DATA EXTRACTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEW-SHOT LEARNING" target="RETRIEVAL AUGMENTED LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EXTRACTIVE QUESTION ANSWERING" target="TASK TEMPLATES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANNOTATORS" target="AMT CROWDSOURCING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANNOTATORS" target="INTER-ANNOTATOR AGREEMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INSTRUCTION-TUNING DATASET" target="CROWDWORKER ANNOTATION GUIDELINE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INSTRUCTION-TUNING DATASET" target="LEAVE-ONE-OUT APPROACH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="ANSWER-ONLY PROMPTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="TEMPORAL SEQUENCES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="FEW-SHOT EXEMPLARS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="MODEL SCALE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANSWER-ONLY PROMPTING" target="MULTIPLE-CHOICE TASKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EXACT MATCH (EM)" target="MMLU">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROMPT OPTIMIZATION" target="CANDIDATE SCORING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT OPTIMIZATION" target="PROMPT EXPANSION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PROMPT OPTIMIZATION" target="ITERATIVE IMPROVEMENT SEARCH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CANDIDATE SCORING" target="EXECUTION ACCURACY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT EXPANSION" target="PARAPHRASING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROMPT EXPANSION" target="UNINFORMED SEARCH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROMPT EXPANSION" target="CRITIQUE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ITERATIVE IMPROVEMENT SEARCH" target="EARLY STOPPING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TASK DESCRIPTIONS" target="OPTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MMLU" target="CLOSED BOOK QA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENCODER-DECODER NETWORK" target="INTERLINGUA APPROACHES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="POST-EDITING" target="PHRASE-BASED TRANSLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COMPUTER-AIDED TRANSLATION (CAT)" target="LOCALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LINGUISTIC TYPOLOGY" target="WORD ORDER TYPOLOGY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINGUISTIC TYPOLOGY" target="WORLD ATLAS OF LANGUAGE STRUCTURES (WALS)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LINGUISTIC TYPOLOGY" target="ANALYTICAL LANGUAGE">
      <data key="d0">5.0</data>
    </edge>
    <edge source="WORD ORDER TYPOLOGY" target="SVO">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD ORDER TYPOLOGY" target="SOV">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD ORDER TYPOLOGY" target="VSO">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD ORDER TYPOLOGY" target="STRUCTURAL REORDERINGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICAL DIVERGENCES" target="LEXICAL GAP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VERB-FRAMED LANGUAGES" target="SATELLITE-FRAMED LANGUAGES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MORPHOLOGICAL TYPOLOGY" target="ISOLATING LANGUAGES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHOLOGICAL TYPOLOGY" target="POLYSYNTHETIC LANGUAGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHOLOGICAL TYPOLOGY" target="AGGLUTINATIVE LANGUAGES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHOLOGICAL TYPOLOGY" target="FUSION LANGUAGES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHOLOGICAL TYPOLOGY" target="SUBWORD MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POLYSYNTHETIC LANGUAGE" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="REFERENTIAL DENSITY" target="PRO-DROP LANGUAGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REFERENTIAL DENSITY" target="COLD LANGUAGES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REFERENTIAL DENSITY" target="HOT LANGUAGES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRO-DROP LANGUAGE" target="NON-PRO-DROP LANGUAGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HOT MEDIA" target="COLD MEDIA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARALLEL CORPUS" target="SENTENCE ALIGNMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARALLEL CORPUS" target="EUROPARL CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARALLEL CORPUS" target="UNITED NATIONS PARALLEL CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARALLEL CORPUS" target="OPENSUBTITLES CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARALLEL CORPUS" target="PARACRAWL CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE ALIGNMENT" target="ALIGNMENT ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTENCE ALIGNMENT" target="CORPUS CLEANUP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE ALIGNMENT" target="WORD EMBEDDING METHODS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SOURCE LANGUAGE" target="TARGET LANGUAGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MINIMUM BAYES RISK DECODING" target="EVALUATION METRICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINIMUM BAYES RISK DECODING" target="CANDIDATE TRANSLATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINIMUM BAYES RISK DECODING" target="SEQUENCE TO SEQUENCE LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVALUATION METRICS" target="BLEU">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BLEU" target="SACREBLEU">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BLEU" target="MINIMUM ERROR RATE TRAINING (MERT)">
      <data key="d0">16.0</data>
    </edge>
    <edge source="BLEU" target="NIST">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BLEU" target="TASK ERROR RATE (TER)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BLEU" target="METEOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BLEU" target="CHR-F">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BLEU" target="STATISTICAL MACHINE TRANSLATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEWSTATE" target="ADDTOBEAM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BACKTRANSLATION" target="DATA AUGMENTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BACKTRANSLATION" target="MONOLINGUAL CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BACKTRANSLATION" target="GREEDY INFERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARALLEL CORPORA" target="PARACRAWL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARALLEL CORPORA" target="LARGE PARALLEL CORPORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOW-RESOURCE LANGUAGES" target="SOCIO-TECHNICAL ISSUES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SOCIO-TECHNICAL ISSUES" target="PARTICIPATORY DESIGN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC EVALUATION" target="CHR-F">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BERTSCORE" target="EMBEDDING SIMILARITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TASK ERROR RATE (TER)" target="SLOT ERROR RATE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TASK ERROR RATE (TER)" target="EFFICIENCY COSTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COMET" target="BLEURT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COMET" target="MACHINE TRANSLATION EVALUATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BLEURT" target="NEURAL MACHINE TRANSLATION OF RARE WORDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PAIRWISE COSINE SIMILARITY" target="MAXIMUM SIMILARITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="IDF WEIGHTS" target="IMPORTANCE WEIGHTING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="IMPORTANCE WEIGHTING" target="WEIGHTING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRANSFORMER ENCODER" target="NONLINEAR TRANSFORMATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFER APPROACHES" target="DIRECT TRANSLATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSFER APPROACHES" target="INTERLINGUA APPROACHES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSFER APPROACHES" target="VAUQUOIS TRIANGLE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIRECT TRANSLATION" target="VAUQUOIS TRIANGLE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="INTERLINGUA APPROACHES" target="VAUQUOIS TRIANGLE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL MT" target="IBM MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL MT" target="MAXENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL MT" target="PHRASE-BASED TRANSLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL MT" target="HANSARD CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="IBM MODELS" target="CANDIDE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="IBM MODELS" target="NOISY CHANNEL MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PHRASE-BASED TRANSLATION" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MINIMUM ERROR RATE TRAINING (MERT)" target="ENHANCED GOOD-TURING AND DELETED ESTIMATION METHODS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MINIMUM ERROR RATE TRAINING (MERT)" target="DISCRIMINATIVE TRAINING AND MAXIMUM ENTROPY MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NIST" target="WORD ERROR (MAPSSWE) TEST">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GIZA" target="MOSES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSDUCTION GRAMMARS" target="INVERSION TRANSDUCTION GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSDUCTION GRAMMARS" target="SYNCHRONOUS CONTEXT-FREE GRAMMARS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL ENCODER-DECODER" target="TRANSFORMER ENCODER-DECODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TERM WEIGHTING" target="BM25">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BM25" target="TF-IDF COSINE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BM25" target="BI-ENCODER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BM25" target="DENSE PASSAGE RETRIEVAL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="QA DATASET" target="READING COMPREHENSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOCUMENT VECTOR LENGTH" target="TF-IDF COSINE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TF-IDF COSINE" target="INVERTED INDEX">
      <data key="d0">1.0</data>
    </edge>
    <edge source="STOP LIST" target="INVERTED INDEX">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DOCUMENT 1" target="DOCUMENT 2">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRECISION-RECALL CURVE" target="INTERPOLATED PRECISION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MEAN AVERAGE PRECISION (MAP)" target="RANKED RETRIEVAL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INTERPOLATED PRECISION" target="RANKED RETRIEVAL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BI-ENCODER" target="NEURAL GRAPH-BASED LINKING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LINEAR LAYER" target="COLBERT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COLBERT" target="MAXSIM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RAG (RETRIEVAL-AUGMENTED GENERATION)" target="RETRIEVER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RAG (RETRIEVAL-AUGMENTED GENERATION)" target="READER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RAG (RETRIEVAL-AUGMENTED GENERATION)" target="FAISS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RAG (RETRIEVAL-AUGMENTED GENERATION)" target="MS MARCO">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RAG (RETRIEVAL-AUGMENTED GENERATION)" target="MULTI-HOP ARCHITECTURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RAG (RETRIEVAL-AUGMENTED GENERATION)" target="RETRIEVER/READER ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FAISS" target="NEAREST NEIGHBOR SEARCH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MS MARCO" target="READING COMPREHENSION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MS MARCO" target="MICROSOFT BING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MS MARCO" target="MACHINE READING COMPREHENSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL QUESTIONS" target="READING COMPREHENSION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL QUESTIONS" target="F1 SCORE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL QUESTIONS" target="GOOGLE SEARCH ENGINE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTRIBUTE-VALUE MATRIX" target="ZELLIG HARRIS'S TDAP PROJECT">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LUNAR SYSTEM" target="GEOQUERY DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LUNAR SYSTEM" target="PREDICATE CALCULUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GEOQUERY DATASET" target="NEURAL MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL MODELS" target="ENTITY-BASED MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL MODELS" target="CONTEXTUAL WORD EMBEDDINGS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL MODELS" target="COHERENCE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TREC" target="DEEPQA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TREC" target="INFORMATION-RETRIEVAL PARADIGM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEEPQA" target="READING COMPREHENSION TESTS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="FRAME" target="SLOT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME" target="SLOT FILLING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FRAME" target="DOMAIN ONTOLOGY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FRAME" target="WINDOWING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME" target="FRAME NET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME" target="FRAME ELEMENTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME" target="LEXICAL UNITS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME" target="FRAMENET">
      <data key="d0">36.0</data>
    </edge>
    <edge source="FRAME" target="CASE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INSTITUTIONAL REVIEW BOARD (IRB)" target="HUMAN CONVERSATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HUMAN CONVERSATION" target="TURN-TAKING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HUMAN CONVERSATION" target="SPEECH ACTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HUMAN CONVERSATION" target="GROUNDING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HUMAN CONVERSATION" target="DIALOGUE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HUMAN CONVERSATION" target="GRICEAN PRINCIPLE OF RELEVANCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HUMAN CONVERSATION" target="CONVERSATION ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TURN-TAKING" target="DIALOGUE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH ACTS" target="DIALOGUE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GROUNDING" target="DIALOGUE STRUCTURE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DIALOGUE STRUCTURE" target="ADJACENCY PAIRS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE STRUCTURE" target="SIDE SEQUENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE STRUCTURE" target="CLARIFICATION QUESTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DIALOGUE STRUCTURE" target="ARGUMENTATION MINING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SIDE SEQUENCE" target="CLARIFICATION QUESTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REQUEST" target="RESPONSE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REQUEST" target="PRESEQUENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INITIATIVE" target="MIXED INITIATIVE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SYSTEM-INITIATIVE" target="USER-INITIATIVE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="IMPLICATURE" target="MAXIM OF RELEVANCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMPLICATURE" target="CONVERSATIONAL IMPLICATURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SLOT FILLING" target="SEQUENCE LABELER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOMAIN CLASSIFICATION" target="INTENT DETERMINATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE POLICY" target="CONTENT PLANNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE STATE TRACKING" target="DIALOGUE-STATE MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE STATE TRACKING" target="TASK-ORIENTED DIALOGUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="USER CORRECTION ACTS" target="HYPERARTICULATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOMAIN" target="INTENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ONTOLOGY" target="SYNONYMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ONTOLOGY" target="INSTANCE-OF RELATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SYNONYMS" target="SEMI-SUPERVISED METHODS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMPLICIT CONFIRMATION" target="EXPLICIT CONFIRMATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EXPLICIT CONFIRMATION" target="ASR SYSTEMS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ASR SYSTEMS" target="REJECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ASR SYSTEMS" target="CONFIDENCE LEVELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ASR SYSTEMS" target="TRIGRAM LMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE GENERATION" target="SENTENCE REALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE REALIZATION" target="DELEXICALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTENCE REALIZATION" target="DIALOGUE ACT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DELEXICALIZATION" target="RELEXICALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE ACT" target="CONTENT PLANNER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING CHATBOTS" target="TOXICITY CLASSIFIERS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRAINING CHATBOTS" target="TOPICAL-CHAT DATASET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING CHATBOTS" target="EMPATHETIC DIALOGUES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING CHATBOTS" target="SAFERDIALOGUES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRAINING CHATBOTS" target="PSEUDO-CONVERSATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPARROW CHATBOT" target="SEARCH QUERY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEARCH QUERY" target="SEARCH RESULTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="MDP DIALOGUE SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="POMDP MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="NEURAL ARCHITECTURES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="DEEP REINFORCEMENT LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="ISU DIALOGUE SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="DIALOGUE STRATEGY SELECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OBSERVER EVALUATION" target="ACUTE-EVAL METRIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WIZARD-OF-OZ SYSTEM" target="DIALOGUE SYSTEM DESIGN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM DESIGN" target="VALUE SENSITIVE DESIGN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM DESIGN" target="ETHICAL ISSUES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM DESIGN" target="HUMAN-COMPUTER INTERACTION (HCI)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE SYSTEM DESIGN" target="VOICE USER INTERFACE DESIGN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VALUE SENSITIVE DESIGN" target="PARTICIPATORY RESEARCH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VALUE SENSITIVE DESIGN" target="DATASHEETS FOR DATASETS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HUMAN-COMPUTER INTERACTION (HCI)" target="COGNITIVE SCIENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE-STATE MODEL" target="REJECTION AND CONFIRMATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TASK-ORIENTED DIALOGUE" target="DIALOGUE AGENTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL REINFORCEMENT LEARNING MODELS" target="CHATBOT SYSTEMS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="GUS ARCHITECTURE" target="DIGITAL ASSISTANTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CORPUS-BASED CHATBOT ARCHITECTURES" target="SEQUENCE-TO-SEQUENCE MODELS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="AFFECT IN DIALOGUE" target="AFFECTIVE COMPUTING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AFFECTIVE COMPUTING" target="INDIRECT SPEECH ACTS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CTC LOSS FUNCTION" target="RNN-TRANSDUCER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="READ SPEECH" target="AUDIO BOOKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONVERSATIONAL SPEECH" target="BUSINESS MEETING TRANSCRIPTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHANNEL AND NOISE" target="HEAD-MOUNTED MICROPHONES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CHANNEL AND NOISE" target="DISTANT MICROPHONE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ACCENT OR SPEAKER-CLASS CHARACTERISTICS" target="REGIONAL DIALECTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACCENT OR SPEAKER-CLASS CHARACTERISTICS" target="ETHNIC DIALECTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACCENT OR SPEAKER-CLASS CHARACTERISTICS" target="CHILDREN'S SPEECH">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LIBRISPEECH" target="TRANSCRIPTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DICTATION" target="PARADISE LOST">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPEECH SYNTHESIZER" target="VOCAL TRACT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CUE PHRASES" target="PROSODY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROSODY" target="DIPHONES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ALS" target="NEUROLOGICAL DISORDERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MECHANICAL TURK" target="ARTIFICIAL INTELLIGENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ARTIFICIAL INTELLIGENCE" target="WATSON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ARTIFICIAL INTELLIGENCE" target="STRIPS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ARTIFICIAL INTELLIGENCE" target="ENGLISH PREPOSITIONS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ARTIFICIAL INTELLIGENCE" target="AAAI">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ARTIFICIAL INTELLIGENCE" target="DISTRIBUTIONALLY ROBUST NEURAL NETWORKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SWITCHBOARD" target="TRANSCRIPTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SWITCHBOARD" target="TELEPHONE SPEECH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CALLHOME" target="TRANSCRIPTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CALLHOME" target="TELEPHONE SPEECH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CALLHOME" target="CONNECTIONIST SPEECH RECOGNITION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CORAAL" target="TRANSCRIPTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHIME CHALLENGE" target="DINNER PARTY SPEECH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AISHELL-1" target="CONNECTIONIST SPEECH RECOGNITION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PCM (PULSE CODE MODULATION)" target="M-LAW COMPRESSION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AIR PRESSURE CHANGES" target="ANALOG-TO-DIGITAL CONVERSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINEAR PCM" target="M-LAW">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINEAR PCM" target="PULSE CODE MODULATION (PCM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAV FORMAT" target="RIFF FORMAT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WINDOWING" target="SPECTRAL FEATURES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RECTANGULAR WINDOW" target="HAMMING WINDOW">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCRETE FOURIER TRANSFORM (DFT)" target="FAST FOURIER TRANSFORM (FFT)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCRETE FOURIER TRANSFORM (DFT)" target="FOURIER ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FOURIER ANALYSIS" target="EULER'S FORMULA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MEL SCALE" target="MEL FILTER BANK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MEL SCALE" target="HUMAN AUDITORY PERCEPTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HUMAN AUDITORY PERCEPTION" target="FORMANTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATIONARY SIGNAL" target="NON-STATIONARY SIGNAL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="STOP BURSTS" target="FRICATIVE NOISE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ACOUSTIC FRAMES" target="SUBSAMPLING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUBSAMPLING" target="LOW FRAME RATE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RNN-T" target="ATTENTION-BASED MODELS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FORWARD-BACKWARD ALGORITHM" target="LINEAR-CHAIN CRF">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FORWARD-BACKWARD ALGORITHM" target="HIDDEN MARKOV MODEL (HMM)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FORWARD-BACKWARD ALGORITHM" target="CRF TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ERROR (MAPSSWE) TEST" target="SEGMENTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ERROR (MAPSSWE) TEST" target="Z VARIABLES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ERROR (MAPSSWE) TEST" target="MCNEMAR'S TEST">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS) SYSTEMS" target="LJ SPEECH CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS) SYSTEMS" target="VOCODING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS) SYSTEMS" target="SPEAKER-DEPENDENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS) SYSTEMS" target="MEL SPECTROGRAM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH (TTS) SYSTEMS" target="TEXT NORMALIZATION PREPROCESSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MEL SPECTROGRAM" target="VOCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MEL SPECTROGRAM" target="TACOTRON2">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VOCODER" target="SPECTROGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TACOTRON2" target="WAVENET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TACOTRON2" target="LOCATION-BASED ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TACOTRON2" target="CONVOLUTIONAL LAYERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TACOTRON2" target="PRE-NET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TACOTRON2" target="POST-NET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TACOTRON2" target="STOP TOKEN">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TACOTRON2" target="SPECTROGRAM PREDICTION NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAVENET" target="DILATED CONVOLUTION LAYERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAVENET" target="MIXTURE OF LOGISTIC DISTRIBUTIONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WAVENET" target="TACOTRON 2">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WAVENET" target="DILATED CONVOLUTIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WAVENET" target="SOFTMAX DISTRIBUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAVENET" target="MU-LAW COMPRESSION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAVENET" target="GATED ACTIVATION FUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAVENET" target="SKIP CONNECTIONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WAVENET" target="RULE SYNTHESIS OF SPEECH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TACOTRON 2" target="MEAN OPINION SCORE (MOS)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MEAN OPINION SCORE (MOS)" target="AB TESTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DILATED CONVOLUTIONS" target="CAUSAL CONVOLUTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WAKE WORD DETECTION" target="VOICE-ENABLED ASSISTANT">
      <data key="d0">10.0</data>
    </edge>
    <edge source="SPEAKER DIARIZATION" target="SPEAKER RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEAKER DIARIZATION" target="VOICE ACTIVITY DETECTION (VAD)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEAKER RECOGNITION" target="LANGUAGE IDENTIFICATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LANGUAGE IDENTIFICATION" target="DIALECTAL VARIABILITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE IDENTIFICATION" target="STEMMING ALGORITHM">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LANGUAGE IDENTIFICATION" target="LANGID.PY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="GAUSSIAN MIXTURE MODELS (GMM)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="WSJ CORPUS">
      <data key="d0">15.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="TRANSITION PROBABILITY MATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="EMISSION PROBABILITIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="OBSERVATION LIKELIHOOD">
      <data key="d0">18.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="INITIAL PROBABILITY DISTRIBUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="A TRANSITION PROBABILITIES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="B EMISSION PROBABILITIES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="OUTPUT INDEPENDENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="TRANSITION PROBABILITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HIDDEN MARKOV MODEL (HMM)" target="BAYES' RULE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MOORE'S LAW" target="GPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GPUS" target="DEEP NEURAL NETWORKS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GPUS" target="BILLION-SCALE SIMILARITY SEARCH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="HMM/GMM SYSTEMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="RECTIFIED LINEAR UNITS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="LVCSR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="SEMI-SUPERVISED SEQUENCE LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="AUTOMATIC RECOGNITION OF SPOKEN DIGITS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="UNINTENDED BIAS IN TEXT CLASSIFICATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="DEEP BIAFFINE ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEEP NEURAL NETWORKS" target="REPLICABILITY ANALYSIS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="HMM/GMM SYSTEMS" target="HYBRID SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="UNSUPERVISED PRETRAINING" target="DEEP BELIEF NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOG MEL FEATURES" target="MFCCS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="LISTEN ATTEND AND SPELL" target="END-TO-END CONTINUOUS SPEECH RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="KALDI" target="ESPNET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FORMANT SYNTHESIS" target="HASKINS LABORATORIES PATTERN PLAYBACK MACHINE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ARTICULATORY SYNTHESIS" target="ARTICULATORY SYNTHESIZERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="KLATT FORMANT SYNTHESIZER" target="MITALK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="KLATTALK" target="DECTALK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIPHONIC SYNTHESIS" target="UNIT SELECTION SYNTHESIS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PHONEMES" target="DIPHONES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINGUISTIC STRUCTURE" target="PARSE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LINGUISTIC STRUCTURE" target="ENTITY RELATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LINGUISTIC STRUCTURE" target="EVENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LINGUISTIC STRUCTURE" target="COREFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT" target="TIME">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT" target="LINK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EVENT" target="TIME RELATION CLASSIFIERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="MENTION DETECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="ARRAU">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="ANCORA-CO">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="LITBANK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="BRIDGING REFERENCES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COREFERENCE" target="DISCOURSE DEIXIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE" target="SINGLETONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COREFERENCE" target="HOBBS ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="CENTERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="MUC CONFERENCES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE" target="ACE EVALUATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE" target="MENTION-RANKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COREFERENCE" target="METONYMY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COREFERENCE" target="RULE-BASED SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE" target="ENTITY GRID MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COREFERENCE" target="GRAMMATICAL ROLE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COREFERENCE" target="VAGUENESS AND REFERENTIAL AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OPEN CLASS" target="NOUN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OPEN CLASS" target="VERB">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OPEN CLASS" target="ADJECTIVE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OPEN CLASS" target="ADVERB">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NOUN" target="DETERMINER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NOUN" target="CHANGE OF POSITION ON A SCALE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VERB" target="PARTICLE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VERB" target="AUXILIARY VERB">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ADJECTIVE" target="ADVERB">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ADVERB" target="CHANGE OF POSITION ON A SCALE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CLOSED CLASS" target="PREPOSITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CLOSED CLASS" target="CONJUNCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONJUNCTION" target="COMPLEMENTIZER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUXILIARY VERB" target="MODAL VERB">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PENN TREEBANK TAGSET" target="PENN TREEBANK CORPORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PENN TREEBANK TAGSET" target="EXISTENTIAL THERE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PENN TREEBANK TAGSET" target="PROPER NOUN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCY (UD) TREEBANK" target="UNIVERSAL DEPENDENCY (UD) TAGSET">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DECODE" target="BAYES' RULE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BAYES' RULE" target="ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION PROBABILITY" target="BIGRAM HMM TAGGER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FEATURE FUNCTION" target="GLOBAL FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE FUNCTION" target="LOCAL FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="GRAMMATICAL RELATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="DEPENDENCY TREEBANKS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="UNIVERSAL DEPENDENCY RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="PRAGUE DEPENDENCY TREEBANK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="STANFORD DEPENDENCIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="GOOGLE'S UNIVERSAL PART-OF-SPEECH TAGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNIVERSAL DEPENDENCIES" target="INTERSET INTERLINGUA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HMM TAGGING" target="CRF TAGGING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HMM TAGGING" target="GENERATIVE APPROACH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HMM TAGGING" target="TAG-LABELED TRAINING CORPORA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CRF TAGGING" target="DISCRIMINATIVE APPROACH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TAG-LABELED TRAINING CORPORA" target="SUPERVISED TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED TAGGING" target="UNSUPERVISED ALGORITHMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOB CORPUS" target="CLAWS TAGGER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MXPOST" target="MAXIMUM ENTROPY MARKOV MODELS (MEMM)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TOKENIZER" target="POS-TAGGED TRAINING SET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="POS-TAGGED TRAINING SET" target="BIGRAM HMM TAGGER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIGRAM HMM TAGGER" target="ERROR RATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIGRAM HMM TAGGER" target="PART-OF-SPEECH-TAGGED CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BIGRAM HMM TAGGER" target="OBSERVATION PROBABILITIES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIO TAGGING SCHEME" target="NER SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSE TREE" target="GRAMMAR CHECKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSE TREE" target="FORMAL SEMANTIC ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSE TREE" target="NODE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSE TREE" target="SYNTACTIC PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARSE TREE" target="BRACKETED NOTATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARSE TREE" target="STRUCTURAL AMBIGUITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSE TREE" target="SPAN SCORES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSE TREE" target="HEAD-FINDING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FORMAL LANGUAGE" target="GRAMMATICAL SENTENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FORMAL LANGUAGE" target="UNGRAMMATICAL SENTENCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PRODUCTION RULE" target="NON-TERMINAL SYMBOL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRODUCTION RULE" target="TERMINAL SYMBOL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRODUCTION RULE" target="NON-TERMINAL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRODUCTION RULE" target="TERMINAL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="START SYMBOL" target="SENTENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SENTENCE" target="NOUN PHRASE (NP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE" target="VERB PHRASE (VP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE" target="DEPENDENCY TREE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VERB PHRASE (VP)" target="PREPOSITIONAL PHRASE (PP)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PREPOSITIONAL PHRASE (PP)" target="ATIS CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PENN TREEBANK" target="PROP BANK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PENN TREEBANK" target="ANNOTATED CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHOMSKY NORMAL FORM (CNF)" target="CHOMSKY-ADJUNCTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CHOMSKY NORMAL FORM (CNF)" target="BINARY BRANCHING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CHOMSKY NORMAL FORM (CNF)" target="UNIT PRODUCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHOMSKY NORMAL FORM (CNF)" target="DUMMY NON-TERMINAL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHOMSKY NORMAL FORM (CNF)" target="LEXICAL RULE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STRUCTURAL AMBIGUITY" target="ATTACHMENT AMBIGUITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STRUCTURAL AMBIGUITY" target="COORDINATION AMBIGUITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRAMMAR" target="WORD CLASSES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GRAMMAR" target="ENGLISH PREPOSITIONS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NEURAL CKY" target="SPAN-BASED CONSTITUENCY PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARSER" target="STACK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSER" target="BUFFER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSER" target="ORACLE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARSER" target="TRANSITION OPERATOR">
      <data key="d0">18.0</data>
    </edge>
    <edge source="PARSER" target="TRAINING ORACLE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARSER" target="REFERENCE PARSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSER" target="LEFT ARC">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARSER" target="RIGHT ARC">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARSER" target="SHIFT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARSER" target="CONFIGURATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSER" target="FEATURE-BASED CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARSER" target="NEURAL CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARSER" target="ARC EAGER">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PARSER" target="BIAFFINE FUNCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PARSER" target="PARSEVAL METRIC">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SPAN-BASED CONSTITUENCY PARSING" target="MLP (MULTI-LAYER PERCEPTRON)">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SPAN-BASED CONSTITUENCY PARSING" target="CONSTITUENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPAN SCORES" target="MARGIN-BASED TRAINING ALGORITHM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HEAD-FINDING" target="LEXICAL HEAD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HEAD-FINDING" target="HEAD PERCOLATION TABLE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSEVAL METRIC" target="GOLD STANDARD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PARSEVAL METRIC" target="CROSSING BRACKETS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL CONSTITUENCY PARSERS" target="MINIMUM SPANNING TREES">
      <data key="d0">5.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING PARSING" target="WELL-FORMED SUBSTRING TABLE (WFST)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING PARSING" target="EARLEY ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DYNAMIC PROGRAMMING PARSING" target="MEMOIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LABELED RECALL" target="LABELED PRECISION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PARTIAL PARSING" target="CHUNKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY GRAMMAR" target="HEAD-DEPENDENT RELATIONSHIP">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY GRAMMAR" target="TRANSITION-BASED PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY GRAMMAR" target="GRAPH-BASED PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILISTIC CONTEXT-FREE GRAMMARS" target="NEURAL PARSING ALGORITHMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROBABILISTIC CONTEXT-FREE GRAMMARS" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL PARSING ALGORITHMS" target="RECURSIVE NEURAL ARCHITECTURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL PARSING ALGORITHMS" target="SPAN-BASED SELF-ATTENTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOVERY PROCEDURE" target="IMMEDIATE-CONSTITUENT ANALYSIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="IMMEDIATE-CONSTITUENT ANALYSIS" target="DISTRIBUTIONAL SIMILARITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMMEDIATE-CONSTITUENT ANALYSIS" target="HEAD-DRIVEN PHRASE STRUCTURE GRAMMAR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HEAD-DEPENDENT RELATIONSHIP" target="GRAMMATICAL RELATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROJECTIVITY" target="NON-PROJECTIVE TREES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION-BASED PARSING" target="SHIFT-REDUCE PARSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TRANSITION-BASED PARSING" target="STACK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION-BASED PARSING" target="INPUT BUFFER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION-BASED PARSING" target="CONFIGURATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VERTEX" target="EDGE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SHIFT-REDUCE PARSING" target="RST PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SHIFT-REDUCE PARSING" target="YU ET AL. (2018)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ROOT NODE" target="DEPENDENCY TREE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY TREE" target="ROOT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STACK" target="LEFT ARC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STACK" target="RIGHT ARC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STACK" target="TRANSITION OPERATOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STACK" target="CONFIGURATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LEFT ARC" target="ARC-EAGER SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RIGHT ARC" target="ARC-EAGER SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TRANSITION OPERATOR" target="BUFFER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BUFFER" target="SHIFT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ORACLE" target="TRAINING ORACLE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CONFIGURATION" target="WORD BUFFER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ROOT" target="MAXIMUM SPANNING TREE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="SUPPORT VECTOR MACHINES (SVM)">
      <data key="d0">30.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="SUPERVISED LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="MENTION-RANKING MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="FEATURES OF ANAPHOR OR ANTECEDENT MENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="FEATURES OF ANTECEDENT ENTITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="FEATURES OF PAIR OF MENTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="FEATURES OF PAIR OF ENTITIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED CLASSIFIER" target="RANDOM FOREST">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL CLASSIFIER" target="MAXIMUM SPANNING TREE">
      <data key="d0">5.0</data>
    </edge>
    <edge source="NEURAL CLASSIFIER" target="DISTANT SUPERVISION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPPORT VECTOR MACHINES (SVM)" target="STATISTICAL DEPENDENCY ANALYSIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ARC-STANDARD APPROACH" target="ARC-EAGER SYSTEM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ARC-EAGER SYSTEM" target="REDUCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM SPANNING TREE" target="DEPENDENCY PARSE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MAXIMUM SPANNING TREE" target="GRAPH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MAXIMUM SPANNING TREE" target="CHU-LIU EDMONDS ALGORITHM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DEPENDENCY PARSE" target="DIRECTED GRAPH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSE" target="CONSTITUENCY PARSE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="GRAPH" target="SPANNING TREE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CHU-LIU EDMONDS ALGORITHM" target="CYCLE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDGE" target="FEATURE-BASED ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDGE" target="NEURAL ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FEATURE-BASED ALGORITHM" target="EDGE SCORE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL ALGORITHM" target="BIAFFINE PARSER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INFERENCE-BASED LEARNING" target="PERCEPTRON LEARNING RULE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDGE-SCORER" target="LABEL-SCORER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LABELED ATTACHMENT SCORE (LAS)" target="UNLABELED ATTACHMENT SCORE (UAS)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LABELED ATTACHMENT SCORE (LAS)" target="LABEL ACCURACY SCORE (LS)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPLATE FILLING" target="ROLE-FILLER EXTRACTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEMPLATE FILLING" target="FASTUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEMPLATE FILLING" target="MUC-5">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UMLS" target="RDF">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DBPEDIA" target="FREEBASE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DBPEDIA" target="DISTANT SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FREEBASE" target="DISTANT SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FREEBASE" target="KNOWLEDGE BASE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AIRLINE ANNOUNCEMENTS" target="STOCK PRICES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FARE INCREASE" target="UNITED AIRLINES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FARE INCREASE" target="AMERICAN AIRLINES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="UNITED AIRLINES" target="UAL CORP.">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNITED AIRLINES" target="CHICAGO">
      <data key="d0">7.0</data>
    </edge>
    <edge source="UNITED AIRLINES" target="DALLAS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="UNITED AIRLINES" target="DENVER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="UNITED AIRLINES" target="SAN FRANCISCO">
      <data key="d0">1.0</data>
    </edge>
    <edge source="AMERICAN AIRLINES" target="AMR CORP.">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AMERICAN AIRLINES" target="TIM WAGNER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TACRED DATASET" target="TAC KBP CHALLENGES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TACRED DATASET" target="RELATION TRIPLES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TACRED DATASET" target="RELATION TYPES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TACRED DATASET" target="NO RELATION TAG">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED LEARNING" target="NEGATIVE DATA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPERVISED LEARNING" target="IOB SEQUENCE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED LEARNING" target="SAID EVENTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPERVISED LEARNING" target="ONLINE REVIEWS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SUPERVISED LEARNING" target="SEMI-SUPERVISED METHODS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPERVISED LEARNING" target="ELQ LINKING ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL SUPERVISED RELATION CLASSIFIERS" target="TRANSFORMER-ENCODER ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMI-SUPERVISED LEARNING" target="GAUSSIAN FIELDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BOOTSTRAPPING" target="SEED PATTERNS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BOOTSTRAPPING" target="SEED TUPLES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BOOTSTRAPPING" target="PATTERNS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BOOTSTRAPPING" target="TUPLES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BOOTSTRAPPING" target="POS-TAGGERS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PATTERNS" target="DISTANT SUPERVISION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONFIDENCE VALUES" target="SEMANTIC DRIFT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONFIDENCE VALUES" target="NOISY-OR TECHNIQUE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SEMANTIC DRIFT" target="SEED-BASED SYSTEMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTANT SUPERVISION" target="SUPERVISED CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTANT SUPERVISION" target="NAMED ENTITY TAGGERS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISTANT SUPERVISION" target="DATABASE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTANT SUPERVISION" target="PLACE-OF-BIRTH RELATIONSHIP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTANT SUPERVISION" target="MISSING DATA MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED CLASSIFIER" target="FEATURE-BASED CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED CLASSIFIER" target="NO-RELATION LABEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="UNSUPERVISED RELATION EXTRACTION" target="OPEN INFORMATION EXTRACTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="UNSUPERVISED RELATION EXTRACTION" target="REVERB">
      <data key="d0">9.0</data>
    </edge>
    <edge source="UNSUPERVISED RELATION EXTRACTION" target="KNOWLEDGE GRAPHS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="OPEN INFORMATION EXTRACTION" target="ZERO-SHOT ENTITY LINKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REVERB" target="CONSTRAINTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REVERB" target="LOGISTIC REGRESSION CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HYPERNYM" target="HYPONYM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HYPERNYM" target="WORDNET SYNSETS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEMPORAL LOGIC" target="INTERVAL ALGEBRA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INTERVAL ALGEBRA" target="ALLEN RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INTERVAL ALGEBRA" target="TEMPORAL REPRESENTATION SYSTEMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="REFERENCE POINT" target="ASPECT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ASPECT" target="STATES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ASPECT" target="ACTIVITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ASPECT" target="ACCOMPLISHMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ASPECT" target="ACHIEVEMENT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ACTIVITY" target="ACCOMPLISHMENT">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ACTIVITY" target="PRODUCTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ACTIVITY" target="START DATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACCOMPLISHMENT" target="TELIC EVENTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACCOMPLISHMENT" target="ACHIEVEMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ACHIEVEMENT" target="TELIC EVENTS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PAST" target="REICHENBACH'S APPROACH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REICHENBACH'S APPROACH" target="PRESENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REICHENBACH'S APPROACH" target="FUTURE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TIMEBANK" target="TIMEML">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TIMEBANK" target="TIME RELATION CLASSIFIERS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TIMEBANK" target="TEMPORAL INFORMATION EXTRACTION">
      <data key="d0">14.0</data>
    </edge>
    <edge source="TIMEML" target="TIME RELATION CLASSIFIERS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TIME" target="LINK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINK" target="TLINK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LINK" target="ALINK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LINK" target="SLINK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEMPORAL NORMALIZATION" target="ISO 8601">
      <data key="d0">1.0</data>
    </edge>
    <edge source="TEMPORAL NORMALIZATION" target="TEMPORAL ANCHOR">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEMPORAL NORMALIZATION" target="CLEAR TK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DELTA AIR LINES" target="EARNINGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EARNINGS" target="FISCAL FIRST QUARTER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PACIFIC FIRST FINANCIAL CORP." target="ACQUISITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACQUISITION" target="ROYAL TRUSTCO LTD.">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACQUISITION" target="REGULATORY APPROVAL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ACQUISITION" target="TRANSACTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEEKEND" target="ISO WEEK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WEEKEND" target="DURATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WEEKEND" target="ANCHOR TIMEID">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DURATION" target="ISO8601">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DURATION" target="ATTRIBUTE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TEMPORAL ANCHOR" target="TEMPORAL ARITHMETIC">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TIME RELATION CLASSIFIERS" target="TARSQI">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TIME RELATION CLASSIFIERS" target="CAEVO">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TIME RELATION CLASSIFIERS" target="CATENA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TARSQI" target="TEMPORAL ANNOTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FASTUS" target="FINITE-STATE TRANSDUCERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRODUCTION" target="PRODUCT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TIE-UP" target="JOINT VENTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRODUCT" target="ESTABLISHED BRANDS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="THEMATIC ROLE" target="PĀṆINI">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THEMATIC ROLE" target="DIATHESIS ALTERNATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THEMATIC ROLE" target="LINGUISTIC REALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THEMATIC ROLE" target="THEMATIC GRID">
      <data key="d0">16.0</data>
    </edge>
    <edge source="THEMATIC ROLE" target="SELECTIONAL RESTRICTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SELECTIONAL RESTRICTIONS" target="WORDNET SYNSETS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SELECTIONAL RESTRICTIONS" target="EDIBLE THING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL RESTRICTIONS" target="SELECTIONAL PREFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SELECTIONAL RESTRICTIONS" target="SELECTIONAL PREFERENCE MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL RESTRICTIONS" target="VERB SEMANTICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PĀṆINI" target="SANSKRIT GRAMMAR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIATHESIS ALTERNATIONS" target="VERBNET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FRAMENET" target="FRAME SEMANTICS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAMENET" target="SEMANTICALLY ANNOTATED LEXICON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SURFACE FORMS" target="SHALLOW SEMANTIC REPRESENTATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SHELLY" target="KNIFE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SHELLY" target="FORK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="KNIFE" target="BANANA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FORK" target="BANANA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AGENT" target="PROTO-AGENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AGENT" target="CAUSE CHANGE OF POSITION ON A SCALE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROTO-AGENT" target="PROTO-PATIENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROP BANK" target="NOM BANK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROP BANK" target="ARG0">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROP BANK" target="ARG1">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROP BANK" target="ARG2">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROP BANK" target="ARG3">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROP BANK" target="ARG4">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROP BANK" target="ARGM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROP BANK" target="PENN CHINESE TREEBANK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROP BANK" target="VERB-SPECIFIC ROLES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROP BANK" target="LEXICAL RESOURCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICAL RESOURCES" target="FRAME NET">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FRAME NET" target="FRAME-SPECIFIC ROLES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FRAME ELEMENTS" target="CHANGE POSITION ON A SCALE FRAME">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ATTRIBUTE" target="ITEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ATTRIBUTE" target="VALUE RANGE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ITEM" target="DIFFERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ITEM" target="FINAL STATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ITEM" target="FINAL VALUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ITEM" target="INITIAL STATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ITEM" target="INITIAL VALUE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ITEM" target="GROUP">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CAUSE CHANGE OF POSITION ON A SCALE" target="CHANGE OF POSITION ON A SCALE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHANGE OF POSITION ON A SCALE" target="VERBS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VERBS" target="CONNOTATION FRAMES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL ALGORITHM FOR SRL" target="CRF LAYER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ARGUMENT" target="PREDICATE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PREDICATE" target="CONNOTATION FRAMES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE" target="PSEUDOWORD">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE" target="MAGNITUDE ESTIMATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE" target="PSEUDO-WORDS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE" target="SEMANTIC ROLE CLASSIFICATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE" target="LEXICAL SEMANTIC RELATEDNESS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE" target="LATENT VARIABLE MODELS OF SELECTIONAL PREFERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PSEUDOWORD" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">5.0</data>
    </edge>
    <edge source="SELECTIONAL ASSOCIATION" target="SELECTIONAL PREFERENCE STRENGTH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SELECTIONAL ASSOCIATION" target="CONDITIONAL PROBABILITY MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE STRENGTH" target="KULLBACK-LEIBLER DIVERGENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PRIMITIVE DECOMPOSITION" target="CONCEPTUAL DEPENDENCY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PRIMITIVE DECOMPOSITION" target="FINITE LISTS OF THEMATIC ROLES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="AFFECT LEXICONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="FRAME SEMANTIC LEXICONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="BECHDEL TEST">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="POWER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="AGENCY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="AMT CROWDSOURCING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNOTATION FRAMES" target="CIRCUMPLEX MODEL OF AFFECT">
      <data key="d0">6.0</data>
    </edge>
    <edge source="NOMBANK" target="EMNLP">
      <data key="d0">5.0</data>
    </edge>
    <edge source="SCHERER TYPOLOGY" target="EMOTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCHERER TYPOLOGY" target="MOOD">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCHERER TYPOLOGY" target="INTERPERSONAL STANCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCHERER TYPOLOGY" target="ATTITUDE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCHERER TYPOLOGY" target="PERSONALITY TRAITS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMOTION" target="APPRAISAL THEORY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMOTION" target="TUTORIAL SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMOTION" target="HELP LINE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMOTION" target="BLOG POSTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMOTION" target="TWEETS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMOTION" target="NOVELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMOTION" target="AFFECTIVE STATES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="EMOTION" target="DIMENSIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="APPRAISAL THEORY" target="APPRAISAL VARIABLES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="AFFECTIVE LEXICONS" target="GENERAL INQUIRER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFFECTIVE LEXICONS" target="MPQA SUBJECTIVITY LEXICON">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFFECTIVE LEXICONS" target="POLARITY LEXICON">
      <data key="d0">1.0</data>
    </edge>
    <edge source="AFFECTIVE LEXICONS" target="HUMAN LABELING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFFECTIVE LEXICONS" target="SEMI-SUPERVISED">
      <data key="d0">7.0</data>
    </edge>
    <edge source="AFFECTIVE LEXICONS" target="SUPERVISED">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VALENCE-AROUSAL-DOMINANCE MODEL" target="RUSSELL'S MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENERAL INQUIRER" target="MPQA SUBJECTIVITY LEXICON">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GENERAL INQUIRER" target="POLARITY LEXICON">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GENERAL INQUIRER" target="LIWC">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GENERAL INQUIRER" target="STOCHASTIC APPROACH">
      <data key="d0">5.0</data>
    </edge>
    <edge source="POLARITY LEXICON" target="SENTIMENT AND TOPIC CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HUMAN LABELING" target="NRC WORD-EMOTION ASSOCIATION LEXICON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BASIC EMOTIONS" target="PLUTCHIK WHEEL OF EMOTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BASIC EMOTIONS" target="EKMAN'S SIX EMOTIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BASIC EMOTIONS" target="P. EKMAN">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NRC VAD LEXICON" target="NRC WORD-EMOTION ASSOCIATION LEXICON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NRC VAD LEXICON" target="BEST-WORST SCALING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NRC VAD LEXICON" target="AFFECTIVE DIMENSIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NRC VAD LEXICON" target="SPLIT-HALF RELIABILITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NRC VAD LEXICON" target="VALENCE/AROUSAL/DOMINANCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NRC WORD-EMOTION ASSOCIATION LEXICON" target="NRC EMOTION/AFFECT INTENSITY LEXICON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NRC WORD-EMOTION ASSOCIATION LEXICON" target="CROWDSOURCING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NRC WORD-EMOTION ASSOCIATION LEXICON" target="EMOTION LEXICONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BEST-WORST SCALING" target="FREQUENCIES FOR UNSEEN BIGRAMS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BEST-WORST SCALING" target="PREFERENCE MEASUREMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CROWDSOURCING" target="TURK, MECHANICAL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMI-SUPERVISED INDUCTION" target="SEMANTIC AXIS METHODS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMI-SUPERVISED INDUCTION" target="SEED WORDS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMI-SUPERVISED INDUCTION" target="AXIS-BASED METHODS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMI-SUPERVISED INDUCTION" target="GRAPH-BASED METHODS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SEMANTIC AXIS METHODS" target="TURNING AND LITTMAN ALGORITHM">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SEED WORDS" target="AFFECT DICTIONARY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEED WORDS" target="SENTPROP ALGORITHM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTPROP ALGORITHM" target="RANDOM WALK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SYNSET" target="SENTIWORDNET">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ONLINE REVIEWS" target="REVIEW SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMI-SUPERVISED METHODS" target="ANTONYMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POTTS SCORE" target="WORD SENTIMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POTTS SCORE" target="POTTS DIAGRAM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD SENTIMENT" target="IMDB">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD SENTIMENT" target="YELP">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD SENTIMENT" target="GOODREADS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD SENTIMENT" target="AMAZON">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COORDINATION" target="SEED SETS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEED SETS" target="THESAURUS STRUCTURE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEED SETS" target="EMBEDDING COSINE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="POTTS DIAGRAMS" target="SCALAR ADJECTIVES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POTTS DIAGRAMS" target="EMPHATIC ADVERBS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="POTTS DIAGRAMS" target="ATTENUATING ADVERBS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCALAR ADJECTIVES" target="SENTIMENT COMPOSITIONALITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMPHATIC ADVERBS" target="SENTIMENT COMPOSITIONALITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ATTENUATING ADVERBS" target="SENTIMENT COMPOSITIONALITY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOG ODDS RATIO INFORMATIVE DIRICHLET PRIOR" target="WORD POLARITY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LOG ODDS RATIO INFORMATIVE DIRICHLET PRIOR" target="LOG LIKELIHOOD RATIO">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LOG ODDS RATIO INFORMATIVE DIRICHLET PRIOR" target="BACKGROUND CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD POLARITY" target="SUPERVISED LEARNING OF WORD SENTIMENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BACKGROUND CORPUS" target="DIRICHLET INTUITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BACKGROUND CORPUS" target="LOG ODDS RATIO">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LIKELIHOOD P(W|C)" target="POSTERIOR P(C|W)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FREQUENCY DIFFERENCE" target="RATIO OF FREQUENCIES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOG ODDS RATIO" target="MONROE ET AL. METHOD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MONROE ET AL. METHOD" target="YELP DATASET">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SUPERVISED CLASSIFICATION" target="AFFECT RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AFFECT RECOGNITION" target="ENTITY-CENTRIC AFFECT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ENTITY-CENTRIC AFFECT" target="FIELD AND TSVETKOV METHOD">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SCHWARTZ ET AL. STUDY" target="PMI (POINTWISE MUTUAL INFORMATION)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AFFECT LEXICONS" target="ENTITY-CENTRIC METHOD">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY-CENTRIC METHOD" target="CORE REFERENCE RESOLUTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTITY-CENTRIC METHOD" target="THE DARK KNIGHT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTITY-CENTRIC METHOD" target="ASP">
      <data key="d0">1.0</data>
    </edge>
    <edge source="VALENCE/AROUSAL/DOMINANCE" target="AGENCY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VALENCE/AROUSAL/DOMINANCE" target="POWER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CORE REFERENCE RESOLUTION" target="GOLD COREFERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CORE REFERENCE RESOLUTION" target="ALGORITHMS FOR SCORING COREFERENCE CHAINS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CORE REFERENCE RESOLUTION" target="UNIVERSAL STANFORD DEPENDENCIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CORE REFERENCE RESOLUTION" target="PENN DISCOURSE TREEBANK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CORE REFERENCE RESOLUTION" target="DECISION TREES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CORE REFERENCE RESOLUTION" target="GENDERED AMBIGUOUS PRONOUNS (GAP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THE DARK KNIGHT" target="PLOT SUMMARY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="THE DARK KNIGHT" target="CHARACTER ARCHETYPES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="BECHDEL TEST" target="MOVIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MENTIONS" target="REFERENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MENTIONS" target="DISCOURSE ENTITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="INTER-ANNOTATOR AGREEMENT" target="KRIPPENDORFF'S ALPHA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="DISCOURSE DEIXIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="INDEFINITE NOUN PHRASES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="DEFINITE NOUN PHRASES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="HEARER'S SET OF BELIEFS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="DEFINITE NPS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="PRONOUNS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="ZERO ANAPHORA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="NAMES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="INFORMATION STATUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="BRIDGING INFERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="NON-REFERRING EXPRESSIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="ENTITY-BASED MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE MODEL" target="ENTITY-CENTRIC FOUNDATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WINOGRAD SCHEMA" target="WINOGRAD SCHEMA CHALLENGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WINOGRAD SCHEMA" target="COREERENCE RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WINOGRAD SCHEMA" target="KNOWREF">
      <data key="d0">1.0</data>
    </edge>
    <edge source="WINOGRAD SCHEMA" target="WORLD KNOWLEDGE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WINOGRAD SCHEMA" target="COMMON-SENSE REASONING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE DEIXIS" target="DISCOURSE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEFINITE NOUN PHRASES" target="SEMANTICS OF DEFINITE AND INDEFINITE NOUN PHRASES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANAPHORA" target="ANTECEDENT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANAPHORA" target="PRONOUNS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ANAPHORA" target="DISCOURSE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANTECEDENT" target="COREFERENCE LINK">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PRONOUNS" target="CATAPHORA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRONOUNS" target="QUANTIFIED CONTEXTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRONOUNS" target="CLITICS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PRONOUNS" target="DEMONSTRATIVE PRONOUNS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PRONOUNS" target="EMMA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DEFINITE NPS" target="NEW YORK TIMES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ZERO ANAPHORA" target="CHINESE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ZERO ANAPHORA" target="JAPANESE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ZERO ANAPHORA" target="ITALIAN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ZERO ANAPHORA" target="JOHN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INFORMATION STATUS" target="DISCOURSE-NEW">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION STATUS" target="DISCOURSE-OLD">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION STATUS" target="GIVEN-NEW DIMENSION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INFORMATION STATUS" target="VICTORIA CHEN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NON-REFERRING EXPRESSIONS" target="APPOSITIVES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="NON-REFERRING EXPRESSIONS" target="PREDICATIVE NPS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="NON-REFERRING EXPRESSIONS" target="EXPLETIVES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CATAPHORA" target="DOROTHY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="QUANTIFIED CONTEXTS" target="EVERY DANCER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CLITICS" target="ANCORA">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CLITICS" target="SPANISH">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DEMONSTRATIVE PRONOUNS" target="THOREAU'S WALDEN">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DOROTHY" target="EMERALD CITY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="EVERY DANCER" target="HER LEFT ARM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="JOHN" target="GIOVANNI">
      <data key="d0">6.0</data>
    </edge>
    <edge source="JOHN" target="INCOHERENT DISCOURSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GIVEN-NEW DIMENSION" target="ACCESSIBLE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="VICTORIA CHEN" target="MEGABUCKS BANKING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="APPOSITIVES" target="UNITED">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PREDICATIVE NPS" target="SHANGHAI">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EXPLETIVES" target="GENERICS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="EXPLETIVES" target="PLEONASTIC IT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="UNITED" target="UAL">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SHANGHAI" target="CHINA'S BIGGEST CITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NUMBER AGREEMENT" target="PERSON AGREEMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NUMBER AGREEMENT" target="SINGULAR THEY">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PERSON AGREEMENT" target="GENDER OR NOUN CLASS AGREEMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BINDING THEORY CONSTRAINTS" target="RECENCY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="RECENCY" target="GRAMMATICAL ROLE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GRAMMATICAL ROLE" target="ENTITY GRID MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ONTOLOGICAL DATASETS" target="SINGLETONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MUC, B3, AND CEAF E" target="CONLL F1 SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="ANAPHORICITY CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="REFERENTIALITY CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="PLEONASTIC PRONOUNS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="ANAPHORICITY DETECTOR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="DISCOURSE-NEW CLASSIFIER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="END-TO-END MODEL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MENTION DETECTION" target="MENTION DISAMBIGUATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ANAPHORIC CONTEXTS" target="N-GRAM CONTEXTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION-PAIR ARCHITECTURE" target="HAND-BUILT FEATURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION-PAIR ARCHITECTURE" target="CLOSEST-FIRST CLUSTERING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION-PAIR ARCHITECTURE" target="BEST-FIRST CLUSTERING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION-RANK ARCHITECTURE" target="NEURAL REPRESENTATION LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MENTION-RANK ARCHITECTURE" target="TRANSITIVE CLOSURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MENTION-RANK ARCHITECTURE" target="RANKING MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MENTION-RANK ARCHITECTURE" target="LATENT ANTECEDENTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY-BASED MODEL" target="MENTION-PAIR CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED NEURAL MACHINE LEARNING" target="SUPERVISED ANAPHORICITY CLASSIFIER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SUPERVISED ANAPHORICITY CLASSIFIER" target="ANAPHORICITY DETECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANAPHORICITY DETECTION" target="MENTION-RANKING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL MENTION-RANKING ALGORITHM" target="SPAN REPRESENTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL MENTION-RANKING ALGORITHM" target="COREFERENCE LINK">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NEURAL MENTION-RANKING ALGORITHM" target="E2E-COREF">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL MENTION-RANKING ALGORITHM" target="MENTION SCORE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MENTION SCORE" target="ANTECEDENT SCORE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="KNOWLEDGE BASE" target="WIKIDATA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="KNOWLEDGE BASE" target="MACHINE LEARNING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ANCHOR DICTIONARY" target="TAGME">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MENTION DISAMBIGUATION" target="RELATEDNESS/COHERENCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MENTION DISAMBIGUATION" target="RELATEDNESS SCORE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="VECTOR REPRESENTATION" target="SPAN">
      <data key="d0">8.0</data>
    </edge>
    <edge source="VECTOR REPRESENTATION" target="ELEMENT-WISE MULTIPLICATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="VECTOR REPRESENTATION" target="ATTENTION WEIGHTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANCHOR TEXT" target="IN-LINK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MUC METRIC" target="MUC CONFERENCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CANDIDATE ANNOTATION" target="RELATEDNESS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COHERENCE" target="LINK PROBABILITY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COHERENCE" target="DISCOURSE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE" target="RHETORICAL STRUCTURE THEORY (RST)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COHERENCE" target="PENN DISCOURSE TREEBANK (PDTB)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COHERENCE" target="CENTERING THEORY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COHERENCE" target="ENTITY GRID MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COHERENCE" target="COHERENCE MODELING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HYPOTHESIS CHAIN" target="REFERENCE CHAIN">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COREERENCE RESOLUTION" target="ONTOLOGICAL ENTITY LINKING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WINOBIAS" target="GENDER BIAS IN COREFERENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WINOBIAS" target="GENDERED AMBIGUOUS PRONOUNS (GAP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENDER BIAS IN COREFERENCE" target="GENDERED AMBIGUOUS PRONOUNS (GAP)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENDER BIAS IN COREFERENCE" target="GLOVE EMBEDDINGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING" target="PRONOMINAL ANAPHORA RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING" target="DISCOURSE PLANS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CENTERING" target="PROPERTY-SHARING CONSTRAINT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MENTION-RANKING" target="SINGLETON DETECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE" target="LOCAL COHERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE" target="GLOBAL COHERENCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE" target="ENTITY-BASED COHERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE" target="TOPICALLY COHERENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE" target="COHERENCE RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE" target="UTTERANCE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE" target="AUGMENTED CONTEXT FREE GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GLOBAL COHERENCE" target="ARGUMENTATION STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY-BASED COHERENCE" target="CENTERING THEORY">
      <data key="d0">16.0</data>
    </edge>
    <edge source="ENTITY-BASED COHERENCE" target="CENTERING THEORY (GROSZ ET AL., 1995)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENTITY-BASED COHERENCE" target="GRID MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTITY-BASED COHERENCE" target="FUNCTIONAL LINGUISTICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ENTITY-BASED COHERENCE" target="PSYCHOLOGY OF DISCOURSE PROCESSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="ENTITY GRID">
      <data key="d0">16.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="ENTITY GRID MODEL (BARZILAY AND LAPATA, 2008)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="ENTITY GRID MODEL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="BACKWARD-LOOKING CENTER">
      <data key="d0">16.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="FORWARD-LOOKING CENTERS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="CENTERING TRANSITIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="BRENNAN ET AL. (1987)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="FOCUS OF ATTENTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="DISCOURSE FOCI">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="COHERENCE IN SCHIZOPHRENIA">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CENTERING THEORY" target="ANAPHORA RESOLUTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TOPICALLY COHERENT" target="LEXICAL COHESION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LEXICAL COHESION" target="LEXICAL CHAINS">
      <data key="d0">16.0</data>
    </edge>
    <edge source="LEXICAL COHESION" target="TEXTTILING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICAL COHESION" target="LSA COHERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="RHETORICAL STRUCTURE THEORY (RST)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="RHETORICAL STRUCTURE THEORY (MANN AND THOMPSON, 1987)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="REASON">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="ELABORATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="EVIDENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="ATTRIBUTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="LIST">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="RST RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="COHERENCE RELATIONS" target="DISCOURSE PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="NUCLEUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="SATELLITE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="RST TREEBANK MANUAL (CARLSON AND MARCU, 2001)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="REFERENCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="DISCOURSE TAGGING MANUAL">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="DISCOURSE STRUCTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="RHETORICAL PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="RHETORICAL STRUCTURE THEORY (RST)" target="SHALLOW DISCOURSE PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EVIDENCE" target="MICROSOFT CORP.">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY GRID" target="LOCAL ENTITY TRANSITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NUCLEUS" target="RST RELATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SATELLITE" target="RST RELATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CITIZEN KANE" target="CHARLES FOSTER KANE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CITIZEN KANE" target="FLASHBACKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANDY" target="COREFERENCE CHAPTER">
      <data key="d0">6.0</data>
    </edge>
    <edge source="HOBBS (1979)" target="INCOHERENT DISCOURSE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="INCOHERENT DISCOURSE" target="JENNY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="JANE" target="COHERENT DISCOURSE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST RELATIONS" target="EDU (ELEMENTARY DISCOURSE UNIT)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST RELATIONS" target="RST DISCOURSE TREEBANK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="CARLSON ET AL. (2001)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="BRAUD ET AL. (2017)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="NEURAL SEQUENCE MODELS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="AMERICAN TELEPHONE &amp; TELEGRAPH CO.">
      <data key="d0">5.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="CARLSON ET AL. (2003)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="RST DISCOURSE PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="SHIFT-REDUCE PARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST DISCOURSE TREEBANK" target="NEURAL RST MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE PARSING" target="EDU SEGMENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE PARSING" target="XUE ET AL. (2016)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE PARSING" target="PART-OF-SPEECH TAGGER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE PARSING" target="MULTILINGUAL PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE PARSING" target="DEPENDENCY-BASED EVALUATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE PARSING" target="SEMANTIC RELATEDNESS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BRAUD ET AL. (2017)" target="RST PARSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PENN DISCOURSE TREEBANK (PDTB)" target="DISCOURSE CONNECTIVES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PENN DISCOURSE TREEBANK (PDTB)" target="MILTSKAKI ET AL. (2004)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PENN DISCOURSE TREEBANK (PDTB)" target="PRASAD ET AL. (2008, 2014)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE CONNECTIVES" target="PDTB DISCOURSE PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDU SEGMENTATION" target="LUKASIK ET AL. (2020)">
      <data key="d0">15.0</data>
    </edge>
    <edge source="EDU SEGMENTATION" target="NEURAL SEQUENCE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCIENTIFIC AMERICAN" target="MARCU (2000A)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ZHOU AND XUE (2015)" target="CHINESE DISCOURSE TREEBANK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="RST PARSING" target="NEURAL SYNTACTIC PARSERS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RST PARSING" target="IMPLICIT SYNTAX FEATURES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST PARSING" target="ATTR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="RST PARSING" target="ELAB">
      <data key="d0">6.0</data>
    </edge>
    <edge source="RST PARSING" target="BRAUD ET AL. (2016)">
      <data key="d0">6.0</data>
    </edge>
    <edge source="IMPLICIT SYNTAX FEATURES" target="BI-AFFINE DEPENDENCY PARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMPLICIT SYNTAX FEATURES" target="ZHANG ET AL. (2017)">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TRANSITION-BASED NEURAL MODEL" target="DYNAMIC ORACLE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EDU REPRESENTATION" target="BI-LSTM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RST DISCOURSE PARSING" target="PDTB DISCOURSE PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="RST DISCOURSE PARSING" target="RST-PAREVAL METRICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PDTB DISCOURSE PARSING" target="BERT EMBEDDINGS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ENTITY GRID MODEL" target="BARZILAY AND LAPATA (2008)">
      <data key="d0">9.0</data>
    </edge>
    <edge source="FORWARD-LOOKING CENTERS" target="PREFERRED CENTER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="JUSTICE DEPARTMENT" target="ANTI-TRUST TRIAL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ANTI-TRUST TRIAL" target="MICROSOFT CORP.">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="COMPETITORS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="MARKETS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="THE CASE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="NETSCAPE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="TACTICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="INCREASED EARNINGS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MICROSOFT CORP." target="TRIAL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="THE GOVERNMENT" target="CIVIL SUIT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONSPIRACY" target="COMPETITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COLLUSION" target="SHERMAN ACT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE LEARNING" target="PATTERN RECOGNITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE LEARNING" target="NEURAL NETWORK ARCHITECTURE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE LEARNING" target="TRANSFORMER CIRCUITS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACHINE LEARNING" target="JMLR">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE LEARNING" target="INFORMATION SYSTEMS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE LEARNING" target="DATA VISUALIZATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="COHERENCE MODELS" target="HUMAN-LABELED COHERENCE SCORES">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COHERENCE MODELS" target="DISCOURSE GENERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL COHERENCE MODEL" target="LOCAL COHERENCE DISCRIMINATOR (LCD)">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL COHERENCE MODEL" target="UNSUPERVISED SEMANTIC ROLE LABELING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOCAL COHERENCE DISCRIMINATOR (LCD)" target="MARGIN LOSS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LOCAL COHERENCE DISCRIMINATOR (LCD)" target="SENTENCE ENCODER">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LOCAL COHERENCE DISCRIMINATOR (LCD)" target="COHERENCE SCORE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SENTENCE ORDER DISCRIMINATION" target="PERMUTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXTTILING" target="GRAPH-BASED LOCAL COHERENCE MODELING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MARGIN LOSS" target="LCD MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTENCE ENCODER" target="GENERATIVE COHERENCE MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HUMAN RATINGS" target="ESSAY GRADING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TOPICAL COHERENCE" target="SEMANTIC FIELD COHERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GENERATIVE COHERENCE MODEL" target="DISCRIMINATIVE TRAINING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCRIMINATIVE TRAINING" target="DISCRIMINATION TASK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCRIMINATIVE TRAINING" target="PARAGRAPH RECONSTRUCTION TASK">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ARGUMENTATION STRUCTURE" target="ARGUMENTATION MINING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ARGUMENTATION STRUCTURE" target="DISCOURSE CONNECTORS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="ARGUMENTATION STRUCTURE" target="ARGUMENTATION SCHEMES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ARGUMENTATION STRUCTURE" target="PERSUASION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CLAIMS" target="PREMISES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CLAIMS" target="SUPPORT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CLAIMS" target="ATTACK">
      <data key="d0">1.0</data>
    </edge>
    <edge source="CLAIMS" target="PERSUASIVE ESSAYS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PREMISES" target="PERSUASIVE ESSAYS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PERSUASIVE ESSAYS" target="ARGUMENTATIVE DISCOURSE STRUCTURES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROPP'S MODEL" target="DRAMATIS PERSONAE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROPP'S MODEL" target="FUNCTIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCIENTIFIC DISCOURSE" target="ARGUMENTATIVE ZONING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="GRID MODEL" target="CONVOLUTIONAL MODEL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FOCUS OF ATTENTION" target="GLOBAL FOCUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FOCUS OF ATTENTION" target="IMMEDIATE FOCUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE PROCESSING" target="DISCOURSE ACT RECOGNITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="ANNOTATION FOR AND ROBUST PARSING OF DISCOURSE STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="DISCOURSE PARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="DISCOURSE ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="DISCOURSE SEGMENTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="DISCOURSE ANAPHORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="CENTERING IN DISCOURSE">
      <data key="d0">16.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="CONTEXT CHANGE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE STRUCTURE" target="MULTILINGUAL SHALLOW DISCOURSE PARSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="HOW TO DO THINGS WITH WORDS" target="SPEECH ACT THEORY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CHARACTERIZING AND PREDICTING VOICE QUERY REFORMULATION" target="VOICE QUERY REFORMULATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE" target="NEURAL MACHINE TRANSLATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="END-TO-END ATTENTION-BASED LARGE VOCABULARY SPEECH RECOGNITION" target="LARGE-VOCABULARY SPEECH RECOGNITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LARGE-VOCABULARY SPEECH RECOGNITION" target="SPEECH-TO-TEXT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LARGE-VOCABULARY SPEECH RECOGNITION" target="CONTEXT-DEPENDENT PRE-TRAINED DEEP NEURAL NETWORKS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THE PRESENT STATUS OF AUTOMATIC TRANSLATION OF LANGUAGES" target="AUTOMATIC TRANSLATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUTOMATIC TRANSLATION" target="MÉTÉO">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LATENT SEMANTIC INFORMATION" target="STATISTICAL LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL LANGUAGE MODELING" target="SEMANTIC PREDICTORS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE TECHNOLOGY" target="MOBILE DEVICES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST SPEECH RECOGNITION" target="HYBRID APPROACH">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONNECTIONIST SPEECH RECOGNITION" target="AMERICAN ENGLISH SPEECH">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CROSS-LINGUAL RST DISCOURSE PARSING" target="DISCOURSE-TAGGED CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE-TAGGED CORPUS" target="MULTILINGUAL DEPENDENCY PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CENTERING APPROACH" target="DISCOURSE TAGGING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PATTERN EXTRACTION" target="SEMANTIC REPRESENTATIONS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC REPRESENTATIONS" target="CONCRETENESS RATINGS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC REPRESENTATIONS" target="WEB PATTERN EXTRACTION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SELECTIONAL PREFERENCE ACQUISITION" target="WORDNET-BASED MEASURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORDNET-BASED MEASURES" target="SEMANTIC BIASES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="STATISTICAL MACHINE TRANSLATION" target="GOOGLE'S NEURAL MACHINE TRANSLATION SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ERROR-SENSITIVE RESPONSE GENERATION" target="AI IN CAI">
      <data key="d0">5.0</data>
    </edge>
    <edge source="AI IN CAI" target="COMPUTER-ASSISTED INSTRUCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOMAIN-SPECIFIC KNOWLEDGE ACQUISITION" target="NOUN PHRASE COREFERENCE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="LEXICAL SEMANTIC RELATEDNESS" target="HUMAN-LIKE BIASES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONCRETENESS" target="WORD CO-OCCURRENCE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MANDARIN SPEECH CORPUS" target="SPOKEN LANGUAGE DIALOGUE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REFERENCE" target="PHRASE-STRUCTURE GRAMMAR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="CONLL-2005 SHARED TASK" target="ILLINOIS-COREF">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ILLINOIS-COREF" target="LINGUISTICALLY AWARE COREFERENCE EVALUATION METRICS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NAVYTIME" target="MULTI-PASS ARCHITECTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NAVYTIME" target="EVENT AND TIME ORDERING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PSEUDO-WORDS" target="TEMPLATE-BASED INFORMATION EXTRACTION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MÉTÉO" target="SUTIME">
      <data key="d0">6.0</data>
    </edge>
    <edge source="KNOWLEDGE-BASED WORD SENSE DISAMBIGUATION" target="UNSUPERVISED POS INDUCTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="STATISTICAL PARSING" target="MULTILINGUAL DEPENDENCY-BASED SYNTACTIC AND SEMANTIC PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICAL PARSING" target="NEURAL NETWORK STATISTICAL PARSER">
      <data key="d0">16.0</data>
    </edge>
    <edge source="MULTILINGUAL DEPENDENCY-BASED SYNTACTIC AND SEMANTIC PARSING" target="SYNTACTIC AND SEMANTIC PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="READING WIKIPEDIA TO ANSWER OPEN-DOMAIN QUESTIONS" target="FAST AND ACCURATE DEPENDENCY PARSER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FAST AND ACCURATE DEPENDENCY PARSER" target="DEPENDENCY PARSER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INCREMENTAL TEXT STRUCTURING" target="SMOOTHING TECHNIQUES FOR LANGUAGE MODELING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ADVERSARIAL MULTI-CRITERIA LEARNING" target="LONG SHORT-TERM MEMORY-NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LONG SHORT-TERM MEMORY-NETWORKS" target="MACHINE READING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MARKED PERSONAS" target="DEEP REINFORCEMENT LEARNING FROM HUMAN PREFERENCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HIERARCHICAL PHRASE-BASED MODEL" target="RNN ENCODER-DECODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MESSAGE UNDERSTANDING SYSTEMS" target="DISCOURSE ACT RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SYSTEMT" target="RULE-BASED INFORMATION EXTRACTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="THREE MODELS FOR THE DESCRIPTION OF LANGUAGE" target="LOGICAL STRUCTURE OF LINGUISTIC THEORY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="THREE MODELS FOR THE DESCRIPTION OF LANGUAGE" target="LECTURES ON GOVERNMENT AND BINDING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SYNTACTIC STRUCTURES" target="FORMAL PROPERTIES OF GRAMMARS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="STOCHASTIC PARTS PROGRAM" target="NOUN PHRASE PARSER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="WORD ASSOCIATION NORMS" target="LEXICOGRAPHY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFLUENCE: THE PSYCHOLOGY OF PERSUASION" target="USING LANGUAGE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="FISHER CORPUS" target="SPEECH-TO-TEXT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LANGUAGE ACQUISITION" target="SEMANTICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LANGUAGE ACQUISITION" target="PRAGMATICS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GIVENNESS" target="CONTRASTIVENESS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEFINITENESS" target="SUBJECTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TOPICS" target="POINT OF VIEW">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTICS" target="CONTEXTUAL WORD SIMILARITY">
      <data key="d0">1.0</data>
    </edge>
    <edge source="SEMANTICS" target="PHILOSOPHICAL INVESTIGATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTICS" target="VÖLKERPSYCHOLOGIE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PRAGMATICS" target="ASSERTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE STRATEGIES" target="SENTIMENT PARSING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SENTIMENT PARSING" target="HATE SPEECH DETECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HATE SPEECH DETECTION" target="CONTENT MODERATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HATE SPEECH DETECTION" target="RACIAL BIAS IN HATE SPEECH DETECTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTENT MODERATION" target="GENDER BIAS IN DIALOGUE GENERATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WIKIPEDIA CORPUS" target="CORPUS OF CONTEMPORARY AMERICAN ENGLISH">
      <data key="d0">6.0</data>
    </edge>
    <edge source="HMM WORD AND PHRASE ALIGNMENT" target="MACHINE TRANSLATION DIVERGENCES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE PARSER" target="ARGUMENT MINING">
      <data key="d0">14.0</data>
    </edge>
    <edge source="DISCOURSE PARSER" target="NATURAL LANGUAGE ENGINEERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE PARSER" target="END-TO-END MEMORY NETWORKS">
      <data key="d0">5.0</data>
    </edge>
    <edge source="WORLD ATLAS OF LANGUAGE STRUCTURES ONLINE" target="MAX PLANCK INSTITUTE FOR EVOLUTIONARY ANTHROPOLOGY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SANTA BARBARA CORPUS OF SPOKEN AMERICAN ENGLISH" target="LINGUISTIC DATA CONSORTIUM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONTEXT-FREE PARSING ALGORITHM" target="J. EARLEY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="KESTREL TTS" target="NATURAL LANGUAGE ENGINEERING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OPTIMUM BRANCHINGS" target="GRAPH THEORY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STATISTICS" target="STATISTICAL INVESTIGATION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="HERDAN’S LAW" target="WORD FREQUENCIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCHIZOPHRENIA" target="MENTAL DISORDER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCHIZOPHRENIA" target="AUTOMATIC DETECTION OF INCOHERENT SPEECH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSMISSION OF INFORMATION" target="COMMUNICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GLOTTAL FLOW" target="PHONETICS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EMPATH" target="TEXT ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONCEPTUAL BLENDING" target="COGNITIVE THEORY">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BOTS" target="AUTOMATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CASE" target="IMPLICIT ARGUMENTS">
      <data key="d0">1.0</data>
    </edge>
    <edge source="IMPLICIT ARGUMENTS" target="NOMINAL PREDICATES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SEARCH IN CONTEXT" target="TEXTUAL COHERENCE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TEXTUAL COHERENCE" target="PROPP’S FUNCTIONS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="VOCABULARY PROBLEM" target="HUMAN-SYSTEM COMMUNICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MINIMUM SPANNING TREES" target="ALGORITHMS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CLAWS WORD-TAGGING SYSTEM" target="CORPUS ANNOTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBLEM SOLVING" target="THEOREM PROVING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINGUISTIC THEORY" target="SEMANTIC ANALYSIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS" target="DEPENDENCY-BASED SEMANTIC ROLE LABELING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EMNLP" target="RECURRENT CONTINUOUS TRANSLATION MODELS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEQUENCE TRANSDUCTION" target="ON-LINE HANDWRITING RECOGNITION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="BIDIRECTIONAL LSTM" target="BIDIRECTIONAL LSTM MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SYNTAX" target="GRAMMATICAL TAGGING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SYMBOL GROUNDING" target="IMPLICIT COGNITION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DIALOGUE AGENTS" target="TOPICAL-CHAT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE AGENTS" target="HUMAN JUDGEMENTS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="HUMAN JUDGEMENTS" target="USER-DERIVED INTERFACE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CROSS-LINGUISTIC VARIATION" target="UNIVERSAL GRAMMAR">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MORPHOLOGICAL RELATIONS" target="SEMANTIC RELATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HIGH-DIMENSIONAL THEORIES" target="EMBODIED THEORIES">
      <data key="d0">5.0</data>
    </edge>
    <edge source="DISCOURSE PLANS" target="GRAPH-BASED LOCAL COHERENCE MODELING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISCOURSE PLANS" target="COHESION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="LEXICAL RELATIONS" target="WORDNET RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LEXICAL RELATIONS" target="DISTRIBUTIONAL STRUCTURE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OCCAM'S RAZOR" target="TRANSFORMER-BASED DEPENDENCY PARSING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DOMAIN ADAPTATION" target="DOMAIN-SPECIFIC SENTIMENT LEXICONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DOMAIN ADAPTATION" target="FAIRNESS WITHOUT DEMOGRAPHICS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="VARIABLE AND FEATURE SELECTION" target="ELEMENTS OF STATISTICAL LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VARIABLE AND FEATURE SELECTION" target="BAYESIAN APPROACH TO FILTERING JUNK E-MAIL">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BAYESIAN APPROACH TO FILTERING JUNK E-MAIL" target="BAYESIAN FILTERING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="POLYSEME SENSE SIMILARITY" target="WORD EMOTION MODELING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="WORD EMOTION MODELING" target="DIACHRONIC WORD EMBEDDINGS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="WORD EMOTION MODELING" target="SEMANTIC ORIENTATION OF ADJECTIVES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SYNTACTICALLY ANNOTATED CORPUS" target="MORPHOLOGICAL TAGGING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SYNTACTICALLY ANNOTATED CORPUS" target="DESCRIPTION BASED PARSING">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MORPHOLOGICAL TAGGING" target="STATISTICAL MORPHOLOGICAL DISAMBIGUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEQUENCE MODELING WITH CTC" target="LARGE VOCABULARY CONTINUOUS SPEECH RECOGNITION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BAYESIAN FILTERING" target="DECEPTION DETECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURAL EMBEDDING SPACES" target="CONNECTIONIST NETWORK">
      <data key="d0">14.0</data>
    </edge>
    <edge source="DATA-DRIVEN DIALOGUE SYSTEMS" target="ETHICAL CHALLENGES">
      <data key="d0">16.0</data>
    </edge>
    <edge source="CANONICAL VERBS" target="LANGUAGE PROCESSING">
      <data key="d0">12.0</data>
    </edge>
    <edge source="USER CORRECTIONS" target="SPOKEN DIALOGUE SYSTEM">
      <data key="d0">14.0</data>
    </edge>
    <edge source="SPOKEN DIALOGUE SYSTEM" target="EMAIL DIALOGUE AGENT">
      <data key="d0">18.0</data>
    </edge>
    <edge source="NEURAL TEXT DEGENERATION" target="INSTRUCTION INDUCTION">
      <data key="d0">10.0</data>
    </edge>
    <edge source="BIDIRECTIONAL LSTM-CRF MODELS" target="SEQUENCE TAGGING">
      <data key="d0">16.0</data>
    </edge>
    <edge source="INFORMATION EXTRACTION PATTERNS" target="CONCATENATIVE SPEECH SYNTHESIS">
      <data key="d0">10.0</data>
    </edge>
    <edge source="SOCIAL BIASES IN NLP MODELS" target="PRIVACY CONCERNS IN CHATBOT INTERACTIONS">
      <data key="d0">2.0</data>
    </edge>
    <edge source="PRIVACY CONCERNS" target="CHATBOT INTERACTIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NEURAL SEMANTIC PARSER" target="USER FEEDBACK">
      <data key="d0">7.0</data>
    </edge>
    <edge source="GENDER BIAS AMPLIFICATION" target="DISTRIBUTION BY POSTERIOR REGULARIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CO-OCCURRENCES OF ANTONYMOUS ADJECTIVES" target="SEMANTIC RELATIONSHIPS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="THEORY OF TRUTH AND SEMANTIC REPRESENTATION" target="FORMAL METHODS IN THE STUDY OF LANGUAGE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THEORY OF TRUTH AND SEMANTIC REPRESENTATION" target="SEMANTIC THEORY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="AUGMENTATIVE AND ALTERNATIVE COMMUNICATION DEVICES" target="COHERENCE IN ELLIPSIS AND ANAPHORA RESOLUTION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="COHERENCE IN ELLIPSIS AND ANAPHORA RESOLUTION" target="TEMPORAL RELATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SCALING LAWS FOR NEURAL LANGUAGE MODELS" target="NEAREST NEIGHBOR LANGUAGE MODELS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENERAL SYNTACTIC PROCESSOR" target="POWERFUL PARSER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CENTERING-BASED METRICS OF COHERENCE" target="CENTERING FOR PRONOUN INTERPRETATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TRANSFORMER VS RNN IN SPEECH APPLICATIONS" target="MULTILINGUAL CONSTITUENCY PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONSTRAINT GRAMMAR" target="UNSUPERVISED MULTILINGUAL SENTENCE BOUNDARY DETECTION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DISCOURSE REFERENTS" target="COHERENCE, REFERENCE, AND THE THEORY OF GRAMMAR">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COHERENCE, REFERENCE, AND THE THEORY OF GRAMMAR" target="MODEL OF TEXT COMPREHENSION AND PRODUCTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CONTEXT-FREE LANGUAGES" target="REPRESENTATION OF EVENTS IN NERVE NETS AND FINITE AUTOMATA">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT-FREE LANGUAGES" target="PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TEXT-TRANSLATION ALIGNMENT" target="PREDICATE-ARGUMENT FREQUENCIES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="TEMPORAL RELATIONS" target="TEMPORAL ANNOTATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILISTIC COREFERENCE" target="PROBABILISTIC RECONCILIATION OF COHERENCE-DRIVEN AND CENTERING-DRIVEN THEORIES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC VECTOR SPACE MODEL PARAMETERS" target="CLASS-BASED CONSTRUCTION OF A VERB LEXICON">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SKIP-GRAM WITH NEGATIVE SAMPLING" target="ADAM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SENTIMENT OF OPINIONS" target="GENDER AND RACE BIAS IN SENTIMENT ANALYSIS SYSTEMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DEPENDENCY PARSING USING BIDIRECTIONAL LSTM" target="CONSTITUENCY PARSING WITH A SELF-ATTENTIVE ENCODER">
      <data key="d0">9.0</data>
    </edge>
    <edge source="VOICE ONSET TIME, FRICTION, AND ASPIRATION" target="ARPA SPEECH UNDERSTANDING PROJECT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ARPA SPEECH UNDERSTANDING PROJECT" target="KLATTALK TEXT-TO-SPEECH CONVERSION SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL SEMANTIC MODELS" target="DISCOURSE RELATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL SEMANTIC MODELS" target="GOOGLE BOOKS NGRAM CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL SEMANTIC MODELS" target="ACL">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DISTRIBUTIONAL SEMANTIC MODELS" target="TACL">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE RELATIONS" target="TEMPORAL INTERPRETATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE RELATIONS" target="FUNCTIONALITY IN LANGUAGE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="DISCOURSE RELATIONS" target="PENN DISCOURSE TREEBANK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DISCOURSE RELATIONS" target="IMPLICIT DISCOURSE RELATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="INFORMATION STATE" target="DIALOGUE MANAGEMENT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DIALOGUE MANAGEMENT" target="CONVERSATIONAL ANALYSIS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DIALOGUE MANAGEMENT" target="DIALOGUE MOVE ENGINE TOOLKIT">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE MANAGEMENT" target="TALK INCAR SYSTEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DIALOGUE MANAGEMENT" target="OPTIMIZING DIALOGUE MANAGEMENT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="PENN DISCOURSE TREEBANK" target="LANGUAGE MODELS AS KNOWLEDGE BASES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PENN DISCOURSE TREEBANK" target="TIMEBANK CORPUS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="HUMAN-MACHINE INTERACTION" target="HOLISTIC EVALUATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="BACKPROPAGATION" target="DEEP REINFORCEMENT LEARNING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NON-NEGATIVE MATRIX FACTORIZATION" target="NEURIPS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="NEURIPS" target="NEURAL INFORMATION PROCESSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="ENGLISH VERB CLASSES" target="ARGUMENT REALIZATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CIRCUS SYSTEM" target="MUC-3">
      <data key="d0">8.0</data>
    </edge>
    <edge source="COMPOSITIONAL CHARACTER MODELS" target="OPEN VOCABULARY WORD REPRESENTATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SEMANTIC SPACES" target="VECTOR-SPACE REPRESENTATIONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING TOOLKIT" target="ANNOTATED CORPUS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="NATURAL LANGUAGE PROCESSING TOOLKIT" target="CORENLP">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH CORPUS" target="SPEECH RECOGNITION SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH CORPUS" target="MANDARIN TELEPHONE SPEECH CORPUS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPEECH RECOGNITION SYSTEM" target="HARPY SPEECH RECOGNITION SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="DATA COMMONS" target="SCIENTIFIC CREDIBILITY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DATA COMMONS" target="AI DATA COMMONS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SCIENTIFIC CREDIBILITY" target="SCIENTIFIC CREDIBILITY OF MACHINE TRANSLATION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SYNTACTIC RECOGNITION" target="SYNTACTIC PATTERNS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MECHANIZED ENCODING" target="ENCODING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURSIVE NEURAL NETWORKS" target="RECURRENT ERROR PROPAGATION NETWORK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="RECURSIVE NEURAL NETWORKS" target="CONTINUOUS SPEECH RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INCREMENTAL NON-PROJECTIVE DEPENDENCY PARSING" target="NON-PROJECTIVE DEPENDENCY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROJECTIVE DEPENDENCY PARSING" target="PSEUDO-PROJECTIVE DEPENDENCY PARSING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONLL 2007 SHARED TASK" target="MALTPARSER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="THE DESIGN OF EVERYDAY THINGS" target="BIBLIOGRAPHY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="OPINION MINING AND SENTIMENT ANALYSIS" target="THUMBS UP? SENTIMENT CLASSIFICATION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GOOGLE HOME VS ALEXA" target="DESIGNING VOICE USER INTERFACES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GOOGLE HOME VS ALEXA" target="VOICE USER INTERFACES">
      <data key="d0">9.0</data>
    </edge>
    <edge source="REDUCING GENDER BIAS IN ABUSIVE LANGUAGE DETECTION" target="IDENTIFYING APPROPRIATE SUPPORT FOR PROPOSITIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="REDUCING GENDER BIAS IN ABUSIVE LANGUAGE DETECTION" target="BBQ: A HAND-BUILT BIAS BENCHMARK">
      <data key="d0">8.0</data>
    </edge>
    <edge source="FROM ARGUMENT DIAGRAMS TO ARGUMENTATION MINING" target="AN ANNOTATED CORPUS OF ARGUMENTATIVE MICROTEXTS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LINGUISTIC INQUIRY AND WORD COUNT (LIWC) 2007" target="DEEP CONTEXTUALIZED WORD REPRESENTATIONS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEGMENTATION TECHNIQUES IN SPEECH SYNTHESIS" target="STOCHASTIC REPRESENTATION OF CONCEPTUAL STRUCTURE">
      <data key="d0">5.0</data>
    </edge>
    <edge source="THE EMOTIONS: FACTS, THEORIES, AND A NEW MODEL" target="PSYCHO-EVOLUTIONARY THEORY OF EMOTION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TIMEBANK CORPUS" target="SPECIFICATION LANGUAGE TIMEML">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENDER BIAS IN MACHINE TRANSLATION" target="GOOGLE TRANSLATE">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GOOGLE TRANSLATE" target="NEURAL COMPUTING AND APPLICATIONS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DARPA 1000-WORD RESOURCE MANAGEMENT DATABASE" target="CONTINUOUS SPEECH RECOGNITION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MORPHOLOGY OF THE FOLKTALE" target="V. PROPP">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SQUAD" target="MACHINE COMPREHENSION OF TEXT">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION EVALUATION" target="WORD REPRESENTATIONS">
      <data key="d0">5.0</data>
    </edge>
    <edge source="OPENAI" target="AI RESEARCH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="HARVARD UNIVERSITY PRESS" target="ACADEMIC PUBLICATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACADEMIC PUBLICATIONS" target="CAMBRIDGE UNIVERSITY PRESS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ACADEMIC PUBLICATIONS" target="MIT PRESS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LINGUA" target="LINGUISTICS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="LREC" target="LANGUAGE RESOURCES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MACMILLAN" target="EDUCATIONAL PUBLICATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="EXTRACTION PATTERNS" target="UNSUPERVISED MODELING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="UNSUPERVISED MODELING" target="TWITTER CONVERSATIONS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LANGUAGE MODEL PARAMETERS" target="ADAPTIVE STATISTICAL LANGUAGE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="OKAPI" target="SMART RETRIEVAL SYSTEM">
      <data key="d0">7.0</data>
    </edge>
    <edge source="OKAPI" target="TEXT RETRIEVAL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SMART RETRIEVAL SYSTEM" target="DENSE PASSAGE RETRIEVER">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC SIMILARITY MODEL" target="SEMANTICALLY ANNOTATED LEXICON">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SEMANTIC SIMILARITY MODEL" target="LEXICAL CO-OCCURRENCE">
      <data key="d0">9.0</data>
    </edge>
    <edge source="OPEN-DOMAIN CHATBOT" target="SPOKEN DIALOGUE MANAGEMENT">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SPOKEN DIALOGUE MANAGEMENT" target="TURN-TAKING SYSTEM">
      <data key="d0">9.0</data>
    </edge>
    <edge source="SPOKEN DIALOGUE MANAGEMENT" target="HIDDEN INFORMATION STATE MODEL">
      <data key="d0">9.0</data>
    </edge>
    <edge source="CIRCUMPLEX MODEL OF AFFECT" target="AFFECTIVE MODELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="IMPLICIT DISCOURSE RELATIONS" target="SYNTACTIC DEPENDENCIES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="SYNTACTIC DEPENDENCIES" target="INTONATIONAL DISAMBIGUATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="DECEPTION DETECTION" target="RACIAL BIAS IN HATE SPEECH DETECTION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROBABILISTIC GRAMMARS" target="GRAMMATICAL CODING SYSTEMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILISTIC GRAMMARS" target="VARIABLE RULES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="AUGMENTED CONTEXT FREE GRAMMAR" target="SCRIPTS, PLANS, AND KNOWLEDGE">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEQUENCING IN CONVERSATIONAL OPENINGS" target="PSYCHOLOGICAL MODELS OF EMOTION">
      <data key="d0">5.0</data>
    </edge>
    <edge source="SEQUENCING IN CONVERSATIONAL OPENINGS" target="CONVERSATIONAL OPENINGS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION: ANALYZING GENDER" target="SCIENTIFIC RESEARCH AND GENDER">
      <data key="d0">7.0</data>
    </edge>
    <edge source="MACHINE TRANSLATION: ANALYZING GENDER" target="GENDER ANALYSIS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="WORD ANALOGY TESTING CAVEAT" target="KNOWLEDGE-FREE INDUCTION OF MORPHOLOGY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BIDIRECTIONAL RECURRENT NEURAL NETWORKS" target="CONTEXT SPACE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTEXT SPACE" target="PROBABILISTIC APPROACHES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONTINUOUS SPACE LANGUAGE MODELS" target="CCMATRIX">
      <data key="d0">8.0</data>
    </edge>
    <edge source="CCMATRIX" target="PARALLEL DATA">
      <data key="d0">8.0</data>
    </edge>
    <edge source="LATENT VARIABLE MODELS OF SELECTIONAL PREFERENCE" target="SPMRL 2013 SHARED TASK">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SPMRL 2013 SHARED TASK" target="PARSING">
      <data key="d0">9.0</data>
    </edge>
    <edge source="BIDIRECTIONAL ATTENTION FLOW" target="NATURAL TTS SYNTHESIS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BIDIRECTIONAL ATTENTION FLOW" target="MACHINE COMPREHENSION">
      <data key="d0">9.0</data>
    </edge>
    <edge source="NATURAL TTS SYNTHESIS" target="TEXT-TO-SPEECH SYNTHESIS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MATHEMATICAL THEORY OF COMMUNICATION" target="PREDICTION AND ENTROPY OF PRINTED ENGLISH">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MATHEMATICAL THEORY OF COMMUNICATION" target="COMMUNICATION THEORY">
      <data key="d0">9.0</data>
    </edge>
    <edge source="TEXT-TO-SPEECH SYNTHESIS" target="CLOZE PROCEDURE">
      <data key="d0">4.0</data>
    </edge>
    <edge source="REPLUG" target="PROSODY AND DIALOG ACT CLASSIFICATION">
      <data key="d0">6.0</data>
    </edge>
    <edge source="DEFINITE ANAPHORA COMPREHENSION" target="SEMANTIC NETWORKS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="ETHNOLOGUE: LANGUAGES OF THE WORLD" target="OPTIMIZING DIALOGUE MANAGEMENT">
      <data key="d0">1.0</data>
    </edge>
    <edge source="NICOMACHEAN ETHICS" target="SEPTEM CIRCUMSTANTIAE">
      <data key="d0">7.0</data>
    </edge>
    <edge source="CONNECTIONISM" target="SYMBOLIC STRUCTURES">
      <data key="d0">7.0</data>
    </edge>
    <edge source="EXPLICIT WORD ERROR MINIMIZATION" target="DIALOGUE ACT MODELING">
      <data key="d0">6.0</data>
    </edge>
    <edge source="MULTILINGUAL AND CROSS-DOMAIN TEMPORAL TAGGING" target="FUNCTIONAL CENTERING">
      <data key="d0">4.0</data>
    </edge>
    <edge source="ENERGY AND POLICY CONSIDERATIONS FOR DEEP LEARNING" target="CHARACTERISTIC-RICH QUESTION SETS">
      <data key="d0">3.0</data>
    </edge>
    <edge source="MUC PROCEEDINGS" target="TAC2013 KNOWLEDGE BASE POPULATION">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PREDICATE-ARGUMENT STRUCTURES" target="RHETORICAL STRUCTURE THEORY PARSERS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="BIG-BENCH TASKS" target="CORRECTIONS IN SPOKEN DIALOGUE SYSTEMS">
      <data key="d0">4.0</data>
    </edge>
    <edge source="UNSUPERVISED SEMANTIC ROLE LABELLING" target="VECTOR IMAGES IN DOCUMENT RETRIEVAL">
      <data key="d0">3.0</data>
    </edge>
    <edge source="CORPUS-BASED TECHNIQUES IN SYNTHESIS SYSTEMS" target="LEXICALIZATION PATTERNS">
      <data key="d0">5.0</data>
    </edge>
    <edge source="INTERACTION DYNAMICS AND PERSUASION STRATEGIES" target="FRAME THEORY">
      <data key="d0">6.0</data>
    </edge>
    <edge source="PRONOUNCING DICTIONARY" target="HIDDEN MARKOV MODEL FOR PART-OF-SPEECH TAGGING">
      <data key="d0">5.0</data>
    </edge>
    <edge source="UNSUPERVISED INDUCTION OF SEMANTIC ROLES" target="BAYESIAN APPROACH TO UNSUPERVISED SEMANTIC ROLE INDUCTION">
      <data key="d0">1.0</data>
    </edge>
    <edge source="FEATURE-RICH PART-OF-SPEECH TAGGING" target="AFFECT, IMAGERY, CONSCIOUSNESS">
      <data key="d0">3.0</data>
    </edge>
    <edge source="FEATURE-RICH PART-OF-SPEECH TAGGING" target="LINGUISTIC RULES FOR TEXT-TO-SPEECH">
      <data key="d0">1.0</data>
    </edge>
    <edge source="COMMON-SENSE REASONING EVALUATION" target="WORD PREDICTION IN AAC">
      <data key="d0">4.0</data>
    </edge>
    <edge source="SEMANTIC ORIENTATION" target="CORPUS-BASED LEARNING OF ANALOGIES">
      <data key="d0">6.0</data>
    </edge>
    <edge source="SEMANTIC ORIENTATION" target="CORPUS-BASED LEARNING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="ANAPHORIC PHENOMENA" target="DISCOURSE ANAPHORA">
      <data key="d0">9.0</data>
    </edge>
    <edge source="MULTI-TASK BENCHMARK" target="GLUE">
      <data key="d0">1.0</data>
    </edge>
    <edge source="MULTILINGUAL SHALLOW DISCOURSE PARSING" target="CONLL 2016 SHARED TASK">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PROBABILISTIC MODELS" target="ZERO-FREQUENCY PROBLEM">
      <data key="d0">8.0</data>
    </edge>
    <edge source="PROBABILISTIC MODELS" target="ADAPTIVE SWITCHING CIRCUITS">
      <data key="d0">6.0</data>
    </edge>
    <edge source="ZERO-FREQUENCY PROBLEM" target="DATA MINING">
      <data key="d0">7.0</data>
    </edge>
    <edge source="TAY EXPERIMENT" target="DETOXIFYING LANGUAGE MODELS">
      <data key="d0">9.0</data>
    </edge>
    <edge source="PERSUASIVE STRATEGIES" target="CROWDFUNDING PLATFORMS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SPEECH USER INTERFACES" target="SPEECHACTS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="KNOWLEDGE BASE QUESTION ANSWERING" target="SEMANTIC PARSE LABELING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="DISCOURSE UNIT SEGMENTATION" target="CONNECTIVE DETECTION">
      <data key="d0">8.0</data>
    </edge>
    <edge source="INDUCTIVE LOGIC PROGRAMMING" target="DATABASE QUERY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="TAGSET CONVERSION" target="TAGSET DRIVERS">
      <data key="d0">7.0</data>
    </edge>
    <edge source="PROBABILISTIC CATEGORIAL GRAMMARS" target="LOGICAL FORM MAPPING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="GENDER BIAS IN WORD EMBEDDINGS" target="DEBIASING METHODS">
      <data key="d0">8.0</data>
    </edge>
    <edge source="MULTILINGUAL DEPENDENCY LEARNING" target="SEMANTIC DEPENDENCY PARSING">
      <data key="d0">8.0</data>
    </edge>
    <edge source="STORY-LIKE VISUAL EXPLANATIONS" target="BOOKS AND MOVIES">
      <data key="d0">8.0</data>
    </edge>
    <edge source="SYNTACTIC DISAMB(&quot;ENTITY&quot;" target="PER-WORD ENTROPY">
      <data key="d0">1.0</data>
    </edge>
  </graph>
</graphml>
